include,repo,title,name,language,compatibility,spark_version,latest_date,ts,dataset,download_url,file,upstream_deps,model_class,labels,reference_url,author,tags,license,edition,dimension,dataset_info,description,included_models,colab_url,case_sensitive,demo_url,scala_docs,scala_source
1,public/models,Danish Lemmatizer,lemma,da,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_da_2.5.5_2.4_1596054395311.zip,lemma_da_2.5.5_2.4_1596054395311.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Danish,pos_ud_ddt,da,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_ddt_da_2.5.5_2.4_1596053892919.zip,pos_ud_ddt_da_2.5.5_2.4_1596053892919.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,dane_ner_6B_100,da,2.6.0,2.4,30/08/2020,1.59881E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/dane_ner_6B_100_da_2.6.0_2.4_1598810267725.zip,dane_ner_6B_100_da_2.6.0_2.4_1598810267725.zip,glove_100d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,dane_ner_6B_300,da,2.6.0,2.4,30/08/2020,1.59881E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/dane_ner_6B_300_da_2.6.0_2.4_1598810268069.zip,dane_ner_6B_300_da_2.6.0_2.4_1598810268069.zip,glove_6B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,dane_ner_840B_100,da,2.6.0,2.4,30/08/2020,1.59881E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/dane_ner_840B_300_da_2.6.0_2.4_1598810268070.zip,dane_ner_840B_300_da_2.6.0_2.4_1598810268070.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,Dutch Lemmatizer,lemma,nl,2.5.0,2.4,03/05/2020,1.58853E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_nl_2.5.0_2.4_1588532720582.zip,lemma_nl_2.5.0_2.4_1588532720582.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Dutch,pos_ud_alpino,nl,2.5.0,2.4,03/05/2020,1.58855E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_alpino_nl_2.5.0_2.4_1588545949009.zip,pos_ud_alpino_nl_2.5.0_2.4_1588545949009.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,WikiNER 6B 100,wikiner_6B_100,nl,2.5.0,2.4,03/05/2020,1.58855E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_nl_2.5.0_2.4_1588546201140.zip,wikiner_6B_100_nl_2.5.0_2.4_1588546201140.zip,glove_100d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_NL.ipynb,0,https://demo.johnsnowlabs.com/public/NER_NL,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 6B 300,wikiner_6B_300,nl,2.5.0,2.4,03/05/2020,1.58855E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_nl_2.5.0_2.4_1588546201483.zip,wikiner_6B_300_nl_2.5.0_2.4_1588546201483.zip,glove_6B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_NL.ipynb,0,https://demo.johnsnowlabs.com/public/NER_NL,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,nl,2.5.0,2.4,03/05/2020,1.58855E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_nl_2.5.0_2.4_1588546201484.zip,wikiner_840B_300_nl_2.5.0_2.4_1588546201484.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_NL.ipynb,0,https://demo.johnsnowlabs.com/public/NER_NL,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,lemma_antbnc,en,2.0.2,2.4,28/04/2019,1.55648E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_antbnc_en_2.0.2_2.4_1556480454569.zip,lemma_antbnc_en_2.0.2_2.4_1556480454569.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,,pos_anc,en,2.0.2,2.4,30/04/2019,1.55666E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_anc_en_2.0.2_2.4_1556659930154.zip,pos_anc_en_2.0.2_2.4_1556659930154.zip,POS,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,pos_ud_ewt,en,2.2.2,2.4,07/10/2019,1.57046E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_ewt_en_2.2.2_2.4_1570464827452.zip,pos_ud_ewt_en_2.2.2_2.4_1570464827452.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,ner_crf,en,2.0.2,2.4,28/01/2020,1.58024E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/ner_crf_en_2.0.2_2.4_1580237286004.zip,ner_crf_en_2.0.2_2.4_1580237286004.zip,NER with GloVe,NerCrfModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,ner_dl,en,2.0.2,2.4,19/03/2020,1.58462E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/ner_dl_en_2.0.2_2.4_1584624950746.zip,ner_dl_en_2.0.2_2.4_1584624950746.zip,NER with GloVe,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,ner_dl_bert,en,2.0.2,2.4,08/09/2020,1.59955E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/ner_dl_bert_en_2.0.2_2.4_1599550979101.zip,ner_dl_bert_en_2.0.2_2.4_1599550979101.zip,NER with BERT,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,Onto 100,onto_100,en,2.1.0,2.4,22/01/2020,1.57973E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/onto_100_en_2.1.0_2.4_1579729071672.zip,onto_100_en_2.1.0_2.4_1579729071672.zip,OntoNotes with GloVe 100d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://catalog.ldc.upenn.edu/LDC2013T19](https://catalog.ldc.upenn.edu/LDC2013T19),"Onto is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. Onto was trained on the OntoNotes text corpus. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. Onto 100 is trained with GloVe 100d word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_EN.ipynb,0,https://demo.johnsnowlabs.com/public/NER_EN_18,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,Onto 300,onto_300,en,2.1.0,2.4,22/01/2020,1.57973E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/onto_300_en_2.1.0_2.4_1579729071854.zip,onto_300_en_2.1.0_2.4_1579729071854.zip,OntoNotes with GloVe 300d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from[https://catalog.ldc.upenn.edu/LDC2013T19](https://catalog.ldc.upenn.edu/LDC2013T19),"Onto is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. Onto was trained on the OntoNotes text corpus. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. Onto 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_EN.ipynb,0,https://demo.johnsnowlabs.com/public/NER_EN_18,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,ner_dl_sentence,en,2.0.2,2.4,28/01/2020,1.58025E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/ner_dl_sentence_en_2.0.2_2.4_1580252313303.zip,ner_dl_sentence_en_2.0.2_2.4_1580252313303.zip,,DeepSentenceDetector,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sbd/deep/DeepSentenceDetector.scala,John Snow Labs,sentence_detector,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.sbd.deep.DeepSentenceDetector,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sbd/deep/DeepSentenceDetector.scala
1,public/models,,spellcheck_sd,en,2.0.2,2.4,13/07/2019,1.56302E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/spellcheck_sd_en_2.0.2_2.4_1563019290368.zip,spellcheck_sd_en_2.0.2_2.4_1563019290368.zip,Spell Checker,SymmetricDeleteModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/symmetric,John Snow Labs,,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.spell.symmetric.SymmetricDeleteModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/symmetric
1,public/models,,spellcheck_norvig,en,2.0.2,2.4,13/07/2019,1.56302E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/spellcheck_norvig_en_2.0.2_2.4_1563017660080.zip,spellcheck_norvig_en_2.0.2_2.4_1563017660080.zip,Spell Checker,NorvigSweetingModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/norvig,John Snow Labs,,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/norvig
1,public/models,,spellcheck_dl,en,2.4.2,2.4,06/05/2020,1.58876E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/spellcheck_dl_en_2.4.2_2.4_1588756259065.zip,spellcheck_dl_en_2.4.2_2.4_1588756259065.zip,Spell Checker,ContextSpellCheckerModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/context,John Snow Labs,spell_checker,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.spell.context.ContextSpellCheckerModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/context
1,public/models,,sentiment_vivekn,en,2.0.2,2.4,30/04/2019,1.55666E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sentiment_vivekn_en_2.0.2_2.4_1556663184035.zip,sentiment_vivekn_en_2.0.2_2.4_1556663184035.zip,Sentiment,ViveknSentimentModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel.scala,John Snow Labs,sentiment,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentApproach,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel.scala
1,public/models,,dependency_conllu,en,2.0.2,2.4,25/06/2019,1.56144E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/dependency_conllu_en_2.0.2_2.4_1561435004077.zip,dependency_conllu_en_2.0.2_2.4_1561435004077.zip,Dependency,DependencyParser,,,John Snow Labs,,open source,public,,,,,,,,,
1,public/models,,dependency_typed_conllu,en,2.0.2,2.4,25/06/2019,1.56147E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/dependency_typed_conllu_en_2.0.2_2.4_1561473259215.zip,dependency_typed_conllu_en_2.0.2_2.4_1561473259215.zip,Dependency,TypedDependencyParser,,,John Snow Labs,,open source,public,,,,,,,,,
1,public/models,Stop Words Cleaner for English,stopwords,en,2.5.3,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_en_2.5.3_2.4_1594742439135.zip,stopwords_en_2.5.3_2.4_1594742439135.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,The model is imported from [https://github.com/WorldBrain/remove-stopwords](https://github.com/WorldBrain/remove-stopwords),"This model removes 'stop words' from text. Stop words are words so common that they can removed without significantly altering the meaning of a text. Removing stop words is useful when one wants to deal with only the most semantically important words in a text, and ignore words that are rarely semantically relevant, such as articles and prepositions.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/stop-words/StopWordsCleaner.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Glove 6B 100,glove_100d,en,2.0.0,2.4,22/01/2020,1.57969E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/glove_100d_en_2.0.0_2.4_1579690104032.zip,glove_100d_en_2.0.0_2.4_1579690104032.zip,GloVe,WordEmbeddingsModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.scala,John Snow Labs,embeddings,open source,public,100,The model is imported from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/),"GloVe (Global Vectors) is a model for distributed word representation. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity. It outperformed many common Word2vec models on the word analogy task. One benefit of GloVe is that it is the result of directly modeling relationships, instead of getting them as a side effect of training a language model.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_dl.ipynb,0,https://demo.johnsnowlabs.com/public/NER_EN/,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.WordEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.scala
1,public/models,,electra_small_uncased,en,2.6.0,2.4,26/08/2020,1.59849E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/electra_small_uncased_en_2.6.0_2.4_1598485458536.zip,electra_small_uncased_en_2.6.0_2.4_1598485458536.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,electra_base_uncased,en,2.6.0,2.4,26/08/2020,1.59849E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/electra_base_uncased_en_2.6.0_2.4_1598485481403.zip,electra_base_uncased_en_2.6.0_2.4_1598485481403.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,electra_large_uncased,en,2.6.0,2.4,26/08/2020,1.59849E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/electra_large_uncased_en_2.6.0_2.4_1598485645331.zip,electra_large_uncased_en_2.6.0_2.4_1598485645331.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,BERT Base Uncased,bert_base_uncased,en,2.2.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_base_uncased_en_2.2.0_2.4_1598340514223.zip,bert_base_uncased_en_2.2.0_2.4_1598340514223.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,768,The model is imported from [https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1](https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1),"This model contains a deep bidirectional transformer trained on Wikipedia and the BookCorpus. The details are described in the paper ""[BERT: Pre,training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"".",,,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,BERT Base Cased,bert_base_cased,en,2.2.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_base_cased_en_2.2.0_2.4_1598340336670.zip,bert_base_cased_en_2.2.0_2.4_1598340336670.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,768,The model is imported from [https://tfhub.dev/google/bert_cased_L-24_H-1024_A-16/1](https://tfhub.dev/google/bert_cased_L-24_H-1024_A-16/1),"This model contains a deep bidirectional transformer trained on Wikipedia and the BookCorpus. The details are described in the paper ""[BERT: Pre,training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"".",,,1,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,BERT Large Uncased,bert_large_uncased,en,2.2.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_large_uncased_en_2.2.0_2.4_1598341287005.zip,bert_large_uncased_en_2.2.0_2.4_1598341287005.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,1024,The model is imported from [https://tfhub.dev/google/bert_uncased_L-24_H-1024_A-16/1](https://tfhub.dev/google/bert_uncased_L-24_H-1024_A-16/1),"This model contains a deep bidirectional transformer trained on Wikipedia and the BookCorpus. The details are described in the paper ""[BERT: Pre,training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"".",,,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,BERT Large Cased,bert_large_cased,en,2.2.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_large_cased_en_2.2.0_2.4_1598340717429.zip,bert_large_cased_en_2.2.0_2.4_1598340717429.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,1024,The model is imported from [https://tfhub.dev/google/bert_cased_L-24_H-1024_A-16/1](https://tfhub.dev/google/bert_cased_L-24_H-1024_A-16/1),"This model contains a deep bidirectional transformer trained on Wikipedia and the BookCorpus. The details are described in the paper ""[BERT: Pre,training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"".",,,1,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,covidbert_large_uncased,en,2.6.0,2.4,26/08/2020,1.59848E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/covidbert_large_uncased_en_2.6.0_2.4_1598484981419.zip,covidbert_large_uncased_en_2.6.0_2.4_1598484981419.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L2_128,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L2_128_en_2.6.0_2.4_1598344320681.zip,small_bert_L2_128_en_2.6.0_2.4_1598344320681.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L4_128,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L4_128_en_2.6.0_2.4_1598344330158.zip,small_bert_L4_128_en_2.6.0_2.4_1598344330158.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L6_128,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L6_128_en_2.6.0_2.4_1598344340449.zip,small_bert_L6_128_en_2.6.0_2.4_1598344340449.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L8_128,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L8_128_en_2.6.0_2.4_1598344352001.zip,small_bert_L8_128_en_2.6.0_2.4_1598344352001.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L10_128,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L10_128_en_2.6.0_2.4_1598344364541.zip,small_bert_L10_128_en_2.6.0_2.4_1598344364541.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L12_128,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L12_128_en_2.6.0_2.4_1598344378220.zip,small_bert_L12_128_en_2.6.0_2.4_1598344378220.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L2_256,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L2_256_en_2.6.0_2.4_1598344391697.zip,small_bert_L2_256_en_2.6.0_2.4_1598344391697.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L4_256,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L4_256_en_2.6.0_2.4_1598344409205.zip,small_bert_L4_256_en_2.6.0_2.4_1598344409205.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L6_256,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L6_256_en_2.6.0_2.4_1598344429629.zip,small_bert_L6_256_en_2.6.0_2.4_1598344429629.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L8_256,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L8_256_en_2.6.0_2.4_1598344454830.zip,small_bert_L8_256_en_2.6.0_2.4_1598344454830.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L10_256,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L10_256_en_2.6.0_2.4_1598344485022.zip,small_bert_L10_256_en_2.6.0_2.4_1598344485022.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L12_256,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L12_256_en_2.6.0_2.4_1598344517363.zip,small_bert_L12_256_en_2.6.0_2.4_1598344517363.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L2_512,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L2_512_en_2.6.0_2.4_1598344551843.zip,small_bert_L2_512_en_2.6.0_2.4_1598344551843.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L4_512,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L4_512_en_2.6.0_2.4_1598344591466.zip,small_bert_L4_512_en_2.6.0_2.4_1598344591466.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L6_512,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L6_512_en_2.6.0_2.4_1598344643979.zip,small_bert_L6_512_en_2.6.0_2.4_1598344643979.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L8_512,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L8_512_en_2.6.0_2.4_1598344705269.zip,small_bert_L8_512_en_2.6.0_2.4_1598344705269.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L10_512,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L10_512_en_2.6.0_2.4_1598344780916.zip,small_bert_L10_512_en_2.6.0_2.4_1598344780916.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L12_512,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L12_512_en_2.6.0_2.4_1598344865471.zip,small_bert_L12_512_en_2.6.0_2.4_1598344865471.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L2_768,en,2.6.0,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L2_768_en_2.6.0_2.4_1598344957042.zip,small_bert_L2_768_en_2.6.0_2.4_1598344957042.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L4_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L4_768_en_2.6.0_2.4_1598345024690.zip,small_bert_L4_768_en_2.6.0_2.4_1598345024690.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L6_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L6_768_en_2.6.0_2.4_1598345125237.zip,small_bert_L6_768_en_2.6.0_2.4_1598345125237.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L8_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L8_768_en_2.6.0_2.4_1598345245072.zip,small_bert_L8_768_en_2.6.0_2.4_1598345245072.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L10_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L10_768_en_2.6.0_2.4_1598345383155.zip,small_bert_L10_768_en_2.6.0_2.4_1598345383155.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,small_bert_L12_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/small_bert_L12_768_en_2.6.0_2.4_1598345548247.zip,small_bert_L12_768_en_2.6.0_2.4_1598345548247.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,Elmo,elmo,en,2.4.0,2.4,31/01/2020,1.58049E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/elmo_en_2.4.0_2.4_1580488815299.zip,elmo_en_2.4.0_2.4_1580488815299.zip,,ElmoEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings.scala,John Snow Labs,embeddings,open source,public,5121024,The model is imported from [https://tfhub.dev/google/elmo/3](https://tfhub.dev/google/elmo/3),"Computes contextualized word representations using character,based word representations and bidirectional LSTMs.,This model outputs fixed embeddings at each LSTM layer and a learnable aggregation of the 3 layers.,* `word_emb`: the character,based word representations with shape [batch_size, max_length, 512].  == word_emb,* `lstm_outputs1`: the first LSTM hidden state with shape [batch_size, max_length, 1024]. === lstm_outputs1,* `lstm_outputs2`: the second LSTM hidden state with shape [batch_size, max_length, 1024]. === lstm_outputs2,* `elmo`: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape [batch_size, max_length, 1024]  == elmo,The complex architecture achieves state of the art results on several benchmarks. Note that this is a very computationally expensive module compared to word embedding modules that only perform embedding lookups. The use of an accelerator is recommended.,The details are described in the paper ""[Deep contextualized word representations](https://arxiv.org/abs/1802.05365)"".",,,1,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.ElmoEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings.scala
1,public/models,ALBERT Base Uncase,albert_base_uncased,en,2.5.0,2.4,28/04/2020,1.58807E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/albert_base_uncased_en_2.5.0_2.4_1588073363475.zip,albert_base_uncased_en_2.5.0_2.4_1588073363475.zip,,AlbertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala,John Snow Labs,embeddings,open source,public,768,The model is imported from [https://tfhub.dev/google/albert_base/3](https://tfhub.dev/google/albert_base/3),"ALBERT is ""A Lite"" version of BERT, a popular unsupervised language representation learning algorithm. ALBERT uses parameter,reduction techniques that allow for large,scale configurations, overcome previous memory limitations, and achieve better behavior with respect to model degradation. The details are described in the paper ""[ALBERT: A Lite BERT for Self,supervised Learning of Language Representations.](https://arxiv.org/abs/1909.11942)""",,,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.AlbertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala
1,public/models,ALBERT Large Uncase,albert_large_uncased,en,2.5.0,2.4,28/04/2020,1.58807E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/albert_large_uncased_en_2.5.0_2.4_1588073397355.zip,albert_large_uncased_en_2.5.0_2.4_1588073397355.zip,,AlbertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala,John Snow Labs,embeddings,open source,public,1024,The model is imported from [https://tfhub.dev/google/albert_large/3](https://tfhub.dev/google/albert_large/3),"ALBERT is ""A Lite"" version of BERT, a popular unsupervised language representation learning algorithm. ALBERT uses parameter,reduction techniques that allow for large,scale configurations, overcome previous memory limitations, and achieve better behavior with respect to model degradation. The details are described in the paper ""[ALBERT: A Lite BERT for Self,supervised Learning of Language Representations.](https://arxiv.org/abs/1909.11942)""",,,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.AlbertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala
1,public/models,ALBERT XLarge Uncase,albert_xlarge_uncased,en,2.5.0,2.4,28/04/2020,1.58807E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/albert_xlarge_uncased_en_2.5.0_2.4_1588073443653.zip,albert_xlarge_uncased_en_2.5.0_2.4_1588073443653.zip,,AlbertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala,John Snow Labs,embeddings,open source,public,2048,The model is imported from [https://tfhub.dev/google/albert_xlarge/3](https://tfhub.dev/google/albert_xlarge/3),"ALBERT is ""A Lite"" version of BERT, a popular unsupervised language representation learning algorithm. ALBERT uses parameter,reduction techniques that allow for large,scale configurations, overcome previous memory limitations, and achieve better behavior with respect to model degradation. The details are described in the paper ""[ALBERT: A Lite BERT for Self,supervised Learning of Language Representations.](https://arxiv.org/abs/1909.11942)""",,,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.AlbertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala
1,public/models,ALBERT XXLarge Uncase,albert_xxlarge_uncased,en,2.5.0,2.4,28/04/2020,1.58807E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/albert_xxlarge_uncased_en_2.5.0_2.4_1588073588232.zip,albert_xxlarge_uncased_en_2.5.0_2.4_1588073588232.zip,,AlbertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala,John Snow Labs,embeddings,open source,public,1024,The model is imported from [https://tfhub.dev/google/albert_xlarge/3](https://tfhub.dev/google/albert_xlarge/3),"ALBERT is ""A Lite"" version of BERT, a popular unsupervised language representation learning algorithm. ALBERT uses parameter,reduction techniques that allow for large,scale configurations, overcome previous memory limitations, and achieve better behavior with respect to model degradation. The details are described in the paper ""[ALBERT: A Lite BERT for Self,supervised Learning of Language Representations.](https://arxiv.org/abs/1909.11942)""",,,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.AlbertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala
1,public/models,XLNet Base,xlnet_base_cased,en,2.5.0,2.4,28/04/2020,1.58807E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/xlnet_base_cased_en_2.5.0_2.4_1588074114942.zip,xlnet_base_cased_en_2.5.0_2.4_1588074114942.zip,,XlnetEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.scala,John Snow Labs,embeddings,open source,public,768,The model is imported from [https://github.com/zihangdai/xlnet](https://github.com/zihangdai/xlnet),"XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer,XL as the backbone model, exhibiting excellent performance for language tasks involving long context. Overall, XLNet achieves state,of,the,art (SOTA) results on various downstream language tasks including question answering, natural language inference, sentiment analysis, and document ranking. The details are described in the paper ""[‚ÄãXLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)""",,,1,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.XlnetEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.scala
1,public/models,XLNet Large,xlnet_large_cased,en,2.5.0,2.4,28/04/2020,1.58807E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/xlnet_large_cased_en_2.5.0_2.4_1588074397954.zip,xlnet_large_cased_en_2.5.0_2.4_1588074397954.zip,,XlnetEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.scala,John Snow Labs,embeddings,open source,public,1024,The model is imported from [https://github.com/zihangdai/xlnet](https://github.com/zihangdai/xlnet),"XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer,XL as the backbone model, exhibiting excellent performance for language tasks involving long context. Overall, XLNet achieves state,of,the,art (SOTA) results on various downstream language tasks including question answering, natural language inference, sentiment analysis, and document ranking. The details are described in the paper ""[‚ÄãXLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)""",,,1,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.XlnetEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.scala
1,public/models,Universal Sentence Encoder,tfhub_use,en,2.4.0,2.4,17/04/2020,1.58714E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/tfhub_use_en_2.4.0_2.4_1587136330099.zip,tfhub_use_en_2.4.0_2.4_1587136330099.zip,USE,UniversalSentenceEncoder,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder.scala,John Snow Labs,,open source,public,512,The model is imported from [https://tfhub.dev/google/universal-sentence-encoder/2](https://tfhub.dev/google/universal-sentence-encoder/2),"The Universal Sentence Encoder encodes text into high,dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.,The model is trained and optimized for greater,than,word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length English text and the output is a 512 dimensional vector. We apply this model to the STS benchmark for semantic similarity, and the results can be seen in the example notebook made available. The universal,sentence,encoder model is trained with a deep averaging network (DAN) encoder.,The details are described in the paper ""[Universal Sentence Encoder](https://arxiv.org/abs/1803.11175)"".",,,1,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder.scala
1,public/models,Universal Sentence Encoder Large,tfhub_use_lg,en,2.4.0,2.4,17/04/2020,1.58714E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/tfhub_use_lg_en_2.4.0_2.4_1587136993894.zip,tfhub_use_lg_en_2.4.0_2.4_1587136993894.zip,USE,UniversalSentenceEncoder,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder.scala,John Snow Labs,,open source,public,512,The model is imported from [https://tfhub.dev/google/universal-sentence-encoder-large/3](https://tfhub.dev/google/universal-sentence-encoder-large/3),"The Universal Sentence Encoder encodes text into high,dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.,The model is trained and optimized for greater,than,word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length English text and the output is a 512 dimensional vector. We apply this model to the STS benchmark for semantic similarity, and the results can be seen in the example notebook made available. The universal,sentence,encoder model is trained with a deep averaging network (DAN) encoder.,The details are described in the paper ""[Universal Sentence Encoder](https://arxiv.org/abs/1803.11175)"".",,,1,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder.scala
1,public/models,,sent_electra_small_uncased,en,2.6.0,2.4,27/08/2020,1.59849E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_electra_small_uncased_en_2.6.0_2.4_1598489761661.zip,sent_electra_small_uncased_en_2.6.0_2.4_1598489761661.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_electra_base_uncased,en,2.6.0,2.4,27/08/2020,1.59849E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_electra_base_uncased_en_2.6.0_2.4_1598489784655.zip,sent_electra_base_uncased_en_2.6.0_2.4_1598489784655.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_electra_large_uncased,en,2.6.0,2.4,27/08/2020,1.59849E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_electra_large_uncased_en_2.6.0_2.4_1598489955147.zip,sent_electra_large_uncased_en_2.6.0_2.4_1598489955147.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_bert_base_uncased,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_bert_base_uncased_en_2.6.0_2.4_1598346203624.zip,sent_bert_base_uncased_en_2.6.0_2.4_1598346203624.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_bert_base_cased,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_bert_base_cased_en_2.6.0_2.4_1598346030732.zip,sent_bert_base_cased_en_2.6.0_2.4_1598346030732.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_bert_large_uncased,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_bert_large_uncased_en_2.6.0_2.4_1598347026632.zip,sent_bert_large_uncased_en_2.6.0_2.4_1598347026632.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_bert_large_cased,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_bert_large_cased_en_2.6.0_2.4_1598346401930.zip,sent_bert_large_cased_en_2.6.0_2.4_1598346401930.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_biobert_pubmed_base_cased,en,2.6.0,2.4,18/09/2020,1.60045E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_biobert_pubmed_base_cased_en_2.6.0_2.4_1600449483871.zip,sent_biobert_pubmed_base_cased_en_2.6.0_2.4_1600449483871.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_biobert_pubmed_large_cased,en,2.6.0,2.4,19/09/2020,1.60053E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_biobert_pubmed_large_cased_en_2.6.0_2.4_1600531709085.zip,sent_biobert_pubmed_large_cased_en_2.6.0_2.4_1600531709085.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_biobert_pmc_base_cased,en,2.6.0,2.4,19/09/2020,1.60053E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_biobert_pmc_base_cased_en_2.6.0_2.4_1600532770743.zip,sent_biobert_pmc_base_cased_en_2.6.0_2.4_1600532770743.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_biobert_pubmed_pmc_base_cased,en,2.6.0,2.4,19/09/2020,1.60053E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_biobert_pubmed_pmc_base_cased_en_2.6.0_2.4_1600533114335.zip,sent_biobert_pubmed_pmc_base_cased_en_2.6.0_2.4_1600533114335.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_biobert_clinical_base_cased,en,2.6.0,2.4,19/09/2020,1.60053E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_biobert_clinical_base_cased_en_2.6.0_2.4_1600533460155.zip,sent_biobert_clinical_base_cased_en_2.6.0_2.4_1600533460155.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_biobert_discharge_base_cased,en,2.6.0,2.4,19/09/2020,1.60053E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_biobert_discharge_base_cased_en_2.6.0_2.4_1600533806048.zip,sent_biobert_discharge_base_cased_en_2.6.0_2.4_1600533806048.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_covidbert_large_uncased,en,2.6.0,2.4,27/08/2020,1.59849E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_covidbert_large_uncased_en_2.6.0_2.4_1598488155401.zip,sent_covidbert_large_uncased_en_2.6.0_2.4_1598488155401.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L2_128,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L2_128_en_2.6.0_2.4_1598350305687.zip,sent_small_bert_L2_128_en_2.6.0_2.4_1598350305687.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L4_128,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L4_128_en_2.6.0_2.4_1598350314094.zip,sent_small_bert_L4_128_en_2.6.0_2.4_1598350314094.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L6_128,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L6_128_en_2.6.0_2.4_1598350323564.zip,sent_small_bert_L6_128_en_2.6.0_2.4_1598350323564.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L8_128,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L8_128_en_2.6.0_2.4_1598350334113.zip,sent_small_bert_L8_128_en_2.6.0_2.4_1598350334113.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L10_128,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L10_128_en_2.6.0_2.4_1598350346103.zip,sent_small_bert_L10_128_en_2.6.0_2.4_1598350346103.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L12_128,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L12_128_en_2.6.0_2.4_1598350359233.zip,sent_small_bert_L12_128_en_2.6.0_2.4_1598350359233.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L2_256,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L2_256_en_2.6.0_2.4_1598350372298.zip,sent_small_bert_L2_256_en_2.6.0_2.4_1598350372298.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L4_256,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L4_256_en_2.6.0_2.4_1598350389644.zip,sent_small_bert_L4_256_en_2.6.0_2.4_1598350389644.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L6_256,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L6_256_en_2.6.0_2.4_1598350409969.zip,sent_small_bert_L6_256_en_2.6.0_2.4_1598350409969.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L8_256,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L8_256_en_2.6.0_2.4_1598350433990.zip,sent_small_bert_L8_256_en_2.6.0_2.4_1598350433990.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L10_256,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L10_256_en_2.6.0_2.4_1598350461634.zip,sent_small_bert_L10_256_en_2.6.0_2.4_1598350461634.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L12_256,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L12_256_en_2.6.0_2.4_1598350492180.zip,sent_small_bert_L12_256_en_2.6.0_2.4_1598350492180.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L2_512,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L2_512_en_2.6.0_2.4_1598350526043.zip,sent_small_bert_L2_512_en_2.6.0_2.4_1598350526043.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L4_512,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L4_512_en_2.6.0_2.4_1598350568942.zip,sent_small_bert_L4_512_en_2.6.0_2.4_1598350568942.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L6_512,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L6_512_en_2.6.0_2.4_1598350624049.zip,sent_small_bert_L6_512_en_2.6.0_2.4_1598350624049.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L8_512,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L8_512_en_2.6.0_2.4_1598350686215.zip,sent_small_bert_L8_512_en_2.6.0_2.4_1598350686215.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L10_512,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L10_512_en_2.6.0_2.4_1598350765497.zip,sent_small_bert_L10_512_en_2.6.0_2.4_1598350765497.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L12_512,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L12_512_en_2.6.0_2.4_1598350859875.zip,sent_small_bert_L12_512_en_2.6.0_2.4_1598350859875.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L2_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L2_768_en_2.6.0_2.4_1598350960245.zip,sent_small_bert_L2_768_en_2.6.0_2.4_1598350960245.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L4_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L4_768_en_2.6.0_2.4_1598351030380.zip,sent_small_bert_L4_768_en_2.6.0_2.4_1598351030380.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L6_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L6_768_en_2.6.0_2.4_1598351137007.zip,sent_small_bert_L6_768_en_2.6.0_2.4_1598351137007.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L8_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L8_768_en_2.6.0_2.4_1598351300711.zip,sent_small_bert_L8_768_en_2.6.0_2.4_1598351300711.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L10_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L10_768_en_2.6.0_2.4_1598351479319.zip,sent_small_bert_L10_768_en_2.6.0_2.4_1598351479319.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_small_bert_L12_768,en,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_small_bert_L12_768_en_2.6.0_2.4_1598351662548.zip,sent_small_bert_L12_768_en_2.6.0_2.4_1598351662548.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,classifierdl_use_trec6,en,2.5.0,2.4,03/05/2020,1.58849E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/classifierdl_use_trec6_en_2.5.0_2.4_1588492648979.zip,classifierdl_use_trec6_en_2.5.0_2.4_1588492648979.zip,with tfhub_use,ClassifierDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala,John Snow Labs,classifier,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala
1,public/models,,classifierdl_use_trec50,en,2.5.0,2.4,03/05/2020,1.58849E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/classifierdl_use_trec50_en_2.5.0_2.4_1588493558481.zip,classifierdl_use_trec50_en_2.5.0_2.4_1588493558481.zip,with tfhub_use,ClassifierDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala,John Snow Labs,classifier,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala
1,public/models,,classifierdl_use_spam,en,2.5.3,2.4,03/07/2020,1.59378E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/classifierdl_use_spam_en_2.5.3_2.4_1593783318934.zip,classifierdl_use_spam_en_2.5.3_2.4_1593783318934.zip,with tfhub_use,ClassifierDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala,John Snow Labs,classifier,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala
1,public/models,,classifierdl_use_fakenews,en,2.5.3,2.4,03/07/2020,1.59378E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/classifierdl_use_fakenews_en_2.5.3_2.4_1593783319296.zip,classifierdl_use_fakenews_en_2.5.3_2.4_1593783319296.zip,with tfhub_use,ClassifierDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala,John Snow Labs,classifier,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala
1,public/models,,classifierdl_use_emotion,en,2.5.3,2.4,03/07/2020,1.59378E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/classifierdl_use_emotion_en_2.5.3_2.4_1593783319297.zip,classifierdl_use_emotion_en_2.5.3_2.4_1593783319297.zip,with tfhub_use,ClassifierDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala,John Snow Labs,classifier,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala
1,public/models,,classifierdl_use_cyberbullying,en,2.5.3,2.4,03/07/2020,1.59378E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/classifierdl_use_cyberbullying_en_2.5.3_2.4_1593783319298.zip,classifierdl_use_cyberbullying_en_2.5.3_2.4_1593783319298.zip,with tfhub_use,ClassifierDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala,John Snow Labs,classifier,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala
1,public/models,,classifierdl_use_sarcasm,en,2.5.3,2.4,03/07/2020,1.59378E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/classifierdl_use_sarcasm_en_2.5.3_2.4_1593783319298.zip,classifierdl_use_sarcasm_en_2.5.3_2.4_1593783319298.zip,with tfhub_use,ClassifierDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala,John Snow Labs,classifier,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala
1,public/models,,multiclassifierdl_use_toxic,en,2.6.0,2.4,03/09/2020,1.59914E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/multiclassifierdl_use_toxic_en_2.6.0_2.4_1599144262640.zip,multiclassifierdl_use_toxic_en_2.6.0_2.4_1599144262640.zip,with tfhub_use,MultiClassifierDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.scala,John Snow Labs,classifier,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.scala
1,public/models,,multiclassifierdl_use_toxic_sm,en,2.6.0,2.4,03/09/2020,1.59914E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/multiclassifierdl_use_toxic_sm_en_2.6.0_2.4_1599144262902.zip,multiclassifierdl_use_toxic_sm_en_2.6.0_2.4_1599144262902.zip,with tfhub_use,MultiClassifierDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.scala,John Snow Labs,classifier,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.scala
1,public/models,,multiclassifierdl_use_e2e,en,2.6.0,2.4,03/09/2020,1.59915E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/multiclassifierdl_use_e2e_en_2.6.0_2.4_1599146072149.zip,multiclassifierdl_use_e2e_en_2.6.0_2.4_1599146072149.zip,with tfhub_use,MultiClassifierDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.scala,John Snow Labs,classifier,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.scala
1,public/models,,sentimentdl_use_imdb,en,2.5.0,2.4,08/06/2020,1.59161E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sentimentdl_use_imdb_en_2.5.0_2.4_1591608094321.zip,sentimentdl_use_imdb_en_2.5.0_2.4_1591608094321.zip,with tfhub_use,SentimentDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.scala,John Snow Labs,sentiment,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.SentimentDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.scala
1,public/models,,sentimentdl_use_twitter,en,2.5.0,2.4,10/05/2020,1.58911E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sentimentdl_use_twitter_en_2.5.0_2.4_1589108892106.zip,sentimentdl_use_twitter_en_2.5.0_2.4_1589108892106.zip,with tfhub_use,SentimentDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.scala,John Snow Labs,sentiment,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.SentimentDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.scala
1,public/models,,sentimentdl_glove_imdb,en,2.5.0,2.4,05/05/2020,1.58868E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sentimentdl_glove_imdb_en_2.5.0_2.4_1588682682507.zip,sentimentdl_glove_imdb_en_2.5.0_2.4_1588682682507.zip,with glove_100d,SentimentDLModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.scala,John Snow Labs,sentiment,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.SentimentDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.scala
1,public/models,Finnish Lemmatizer,lemma,fi,2.5.0,2.4,05/05/2020,1.58867E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_fi_2.5.0_2.4_1588671290521.zip,lemma_fi_2.5.0_2.4_1588671290521.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Finnish,pos_ud_tdt,fi,2.5.0,2.4,04/05/2020,1.58862E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_tdt_fi_2.5.0_2.4_1588622348985.zip,pos_ud_tdt_fi_2.5.0_2.4_1588622348985.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,fi,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_fi_2.5.4_2.4_1594742441054.zip,stopwords_fi_2.5.4_2.4_1594742441054.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,wikiner_6B_100,fi,2.6.0,2.4,30/08/2020,1.59897E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/finnish_ner_6B_100_fi_2.6.0_2.4_1598965807300.zip,finnish_ner_6B_100_fi_2.6.0_2.4_1598965807300.zip,glove_100d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,wikiner_6B_300,fi,2.6.0,2.4,30/08/2020,1.59897E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/finnish_ner_6B_300_fi_2.6.0_2.4_1598965807718.zip,finnish_ner_6B_300_fi_2.6.0_2.4_1598965807718.zip,glove_6B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,wikiner_840B_300,fi,2.6.0,2.4,30/08/2020,1.59897E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/finnish_ner_840B_300_fi_2.6.0_2.4_1598965807720.zip,finnish_ner_840B_300_fi_2.6.0_2.4_1598965807720.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,bert_finnish_cased,fi,2.6.0,2.4,31/08/2020,1.5989E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_finnish_cased_fi_2.6.0_2.4_1598896927571.zip,bert_finnish_cased_fi_2.6.0_2.4_1598896927571.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,bert_finnish_uncased,fi,2.6.0,2.4,31/08/2020,1.5989E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_finnish_uncased_fi_2.6.0_2.4_1598897239983.zip,bert_finnish_uncased_fi_2.6.0_2.4_1598897239983.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,sent_bert_finnish_cased,fi,2.6.0,2.4,31/08/2020,1.5989E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_bert_finnish_cased_fi_2.6.0_2.4_1598897560014.zip,sent_bert_finnish_cased_fi_2.6.0_2.4_1598897560014.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,sent_bert_finnish_uncased,fi,2.6.0,2.4,31/08/2020,1.5989E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_bert_finnish_uncased_fi_2.6.0_2.4_1598897885576.zip,sent_bert_finnish_uncased_fi_2.6.0_2.4_1598897885576.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,lemma,fr,2.0.2,2.4,29/04/2019,1.55653E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_fr_2.0.2_2.4_1556531462843.zip,lemma_fr_2.0.2_2.4_1556531462843.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,,pos_ud_gsd,fr,2.0.2,2.4,29/04/2019,1.55653E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_gsd_fr_2.0.2_2.4_1556531457346.zip,pos_ud_gsd_fr_2.0.2_2.4_1556531457346.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,fr,2.1.0,2.4,22/01/2020,1.5797E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_fr_2.1.0_2.4_1579699913554.zip,wikiner_840B_300_fr_2.1.0_2.4_1579699913554.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_FR.ipynb,0,https://demo.johnsnowlabs.com/public/NER_FR,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,fr,2.1.0,2.4,22/01/2020,1.5797E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_fr_2.1.0_2.4_1579699913554.zip,wikiner_840B_300_fr_2.1.0_2.4_1579699913554.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_FR.ipynb,0,https://demo.johnsnowlabs.com/public/NER_FR,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,stopwords,fr,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_fr_2.5.4_2.4_1594742439495.zip,stopwords_fr_2.5.4_2.4_1594742439495.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,lemma,de,2.0.8,2.4,03/08/2019,1.56486E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_de_2.0.8_2.4_1564861935209.zip,lemma_de_2.0.8_2.4_1564861935209.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,,pos_ud_hdt,de,2.0.8,2.4,22/06/2019,1.56123E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_hdt_de_2.0.8_2.4_1561232528570.zip,pos_ud_hdt_de_2.0.8_2.4_1561232528570.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,de,2.1.0,2.4,22/01/2020,1.5797E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_de_2.1.0_2.4_1579699913555.zip,wikiner_840B_300_de_2.1.0_2.4_1579699913555.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://de.wikipedia.org](https://de.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_DE.ipynb,0,https://demo.johnsnowlabs.com/public/NER_DE,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,de,2.1.0,2.4,22/01/2020,1.5797E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_de_2.1.0_2.4_1579699913555.zip,wikiner_840B_300_de_2.1.0_2.4_1579699913555.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://de.wikipedia.org](https://de.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_DE.ipynb,0,https://demo.johnsnowlabs.com/public/NER_DE,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,Stop Words Cleaner for German,stopwords,de,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_de_2.5.4_2.4_1594742442247.zip,stopwords_de_2.5.4_2.4_1594742442247.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,The model is imported from [https://github.com/WorldBrain/remove-stopwords](https://github.com/WorldBrain/remove-stopwords),"This model removes 'stop words' from text. Stop words are words so common that they can removed without significantly altering the meaning of a text. Removing stop words is useful when one wants to deal with only the most semantically important words in a text, and ignore words that are rarely semantically relevant, such as articles and prepositions.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/stop-words/StopWordsCleaner.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,lemma_dxc,it,2.0.2,2.4,29/04/2019,1.55653E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_dxc_it_2.0.2_2.4_1556531469058.zip,lemma_dxc_it_2.0.2_2.4_1556531469058.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,,pos_ud_isdt,it,2.0.8,2.4,10/06/2019,1.56017E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_isdt_it_2.0.8_2.4_1560168427464.zip,pos_ud_isdt_it_2.0.8_2.4_1560168427464.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,it,2.1.0,2.4,22/01/2020,1.5797E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_it_2.1.0_2.4_1579699913554.zip,wikiner_840B_300_it_2.1.0_2.4_1579699913554.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://it.wikipedia.org](https://it.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_IT.ipynb,0,https://demo.johnsnowlabs.com/public/NER_IT,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,it,2.1.0,2.4,22/01/2020,1.5797E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_it_2.1.0_2.4_1579699913554.zip,wikiner_840B_300_it_2.1.0_2.4_1579699913554.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://it.wikipedia.org](https://it.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_IT.ipynb,0,https://demo.johnsnowlabs.com/public/NER_IT,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,stopwords,it,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_it_2.5.4_2.4_1594742442063.zip,stopwords_it_2.5.4_2.4_1594742442063.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Norwegian Lemmatizer,lemma,nb,2.5.0,2.4,05/05/2020,1.58869E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_nb_2.5.0_2.4_1588693886432.zip,lemma_nb_2.5.0_2.4_1588693886432.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Norwegian Nynorsk,pos_ud_nynorsk,nn,2.5.0,2.4,05/05/2020,1.58869E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_nynorsk_nn_2.5.0_2.4_1588693690964.zip,pos_ud_nynorsk_nn_2.5.0_2.4_1588693690964.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,Part of Speech for Norwegian,pos_ud_bokmaal,nb,2.5.0,2.4,05/05/2020,1.58869E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_bokmaal_nb_2.5.0_2.4_1588693881973.zip,pos_ud_bokmaal_nb_2.5.0_2.4_1588693881973.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,norne_6B_100,no,2.5.0,2.4,06/05/2020,1.58878E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/norne_6B_100_no_2.5.0_2.4_1588781289907.zip,norne_6B_100_no_2.5.0_2.4_1588781289907.zip,glove_100d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,norne_6B_300,no,2.5.0,2.4,06/05/2020,1.58878E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/norne_6B_300_no_2.5.0_2.4_1588781290264.zip,norne_6B_300_no_2.5.0_2.4_1588781290264.zip,glove_6B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,norne_840B_300,no,2.5.0,2.4,06/05/2020,1.58878E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/norne_840B_300_no_2.5.0_2.4_1588781290267.zip,norne_840B_300_no_2.5.0_2.4_1588781290267.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,Polish Lemmatizer,lemma,pl,2.5.0,2.4,03/05/2020,1.58852E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_pl_2.5.0_2.4_1588518491035.zip,lemma_pl_2.5.0_2.4_1588518491035.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Polish,pos_ud_lfg,pl,2.5.0,2.4,03/05/2020,1.58852E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_lfg_pl_2.5.0_2.4_1588518541171.zip,pos_ud_lfg_pl_2.5.0_2.4_1588518541171.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,WikiNER 6B 100,wikiner_6B_100,pl,2.5.0,2.4,03/05/2020,1.58852E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_pl_2.5.0_2.4_1588519719293.zip,wikiner_6B_100_pl_2.5.0_2.4_1588519719293.zip,glove_100d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model was trained based on data from [https://pl.wikipedia.org](https://pl.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PL.ipynb,0,https://demo.johnsnowlabs.com/public/NER_PL,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 6B 300,wikiner_6B_300,pl,2.5.0,2.4,03/05/2020,1.58852E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_pl_2.5.0_2.4_1588519719571.zip,wikiner_6B_300_pl_2.5.0_2.4_1588519719571.zip,glove_6B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model was trained based on data from  [https://pl.wikipedia.org](https://pl.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PL.ipynb,0,https://demo.johnsnowlabs.com/public/NER_PL,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,pl,2.5.0,2.4,03/05/2020,1.58852E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_pl_2.5.0_2.4_1588519719572.zip,wikiner_840B_300_pl_2.5.0_2.4_1588519719572.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model was trained based on data from  [https://pl.wikipedia.org](https://pl.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PL.ipynb,0,https://demo.johnsnowlabs.com/public/NER_PL,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,stopwords,pl,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_pl_2.5.4_2.4_1594742438519.zip,stopwords_pl_2.5.4_2.4_1594742438519.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Portuguese Lemmatizer,lemma,pt,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_pt_2.5.0_2.4_1588499301752.zip,lemma_pt_2.5.0_2.4_1588499301752.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Portuguese,pos_ud_bosque,pt,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_bosque_pt_2.5.0_2.4_1588499443093.zip,pos_ud_bosque_pt_2.5.0_2.4_1588499443093.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,WikiNER 6B 100,wikiner_6B_100,pt,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_pt_2.5.0_2.4_1588495233192.zip,wikiner_6B_100_pt_2.5.0_2.4_1588495233192.zip,glove_100d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model was trained based on data from [https://pt.wikipedia.org](https://pt.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb,0,https://demo.johnsnowlabs.com/public/NER_PT,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 6B 300,wikiner_6B_300,pt,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_pt_2.5.0_2.4_1588495233641.zip,wikiner_6B_300_pt_2.5.0_2.4_1588495233641.zip,glove_6B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model was trained based on data from [https://pt.wikipedia.org](https://pt.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb,0,https://demo.johnsnowlabs.com/public/NER_PT,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,pt,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_pt_2.5.0_2.4_1588495233642.zip,wikiner_840B_300_pt_2.5.0_2.4_1588495233642.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model was trained based on data from  [https://pt.wikipedia.org](https://pt.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb,0,https://demo.johnsnowlabs.com/public/NER_PT,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,stopwords,pt,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_pt_2.5.4_2.4_1594742441703.zip,stopwords_pt_2.5.4_2.4_1594742441703.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,bert_portuguese_base_cased,pt,2.6.0,2.4,10/09/2020,1.59974E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_portuguese_base_cased_pt_2.6.0_2.4_1599740263165.zip,bert_portuguese_base_cased_pt_2.6.0_2.4_1599740263165.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,bert_portuguese_large_cased,pt,2.6.0,2.4,10/09/2020,1.59974E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_portuguese_large_cased_pt_2.6.0_2.4_1599740263521.zip,bert_portuguese_large_cased_pt_2.6.0_2.4_1599740263521.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,Russian Lemmatizer,lemma,ru,2.4.4,2.4,12/03/2020,1.58401E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_ru_2.4.4_2.4_1584013425855.zip,lemma_ru_2.4.4_2.4_1584013425855.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Russian,pos_ud_gsd,ru,2.4.4,2.4,12/03/2020,1.58401E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_gsd_ru_2.4.4_2.4_1584013495069.zip,pos_ud_gsd_ru_2.4.4_2.4_1584013495069.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,WikiNER 6B 100,wikiner_6B_100,ru,2.4.4,2.4,12/03/2020,1.58401E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_ru_2.4.4_2.4_1584014001452.zip,wikiner_6B_100_ru_2.4.4_2.4_1584014001452.zip,glove_100d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://ru.wikipedia.org](https://ru.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_RU.ipynb,0,https://demo.johnsnowlabs.com/public/NER_RU,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 6B 300,wikiner_6B_300,ru,2.4.4,2.4,12/03/2020,1.58401E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_ru_2.4.4_2.4_1584014001694.zip,wikiner_6B_300_ru_2.4.4_2.4_1584014001694.zip,glove_6B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://ru.wikipedia.org](https://ru.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_RU.ipynb,0,https://demo.johnsnowlabs.com/public/NER_RU,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,ru,2.4.4,2.4,12/03/2020,1.58401E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_ru_2.4.4_2.4_1584014001695.zip,wikiner_840B_300_ru_2.4.4_2.4_1584014001695.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://ru.wikipedia.org](https://ru.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_RU.ipynb,0,https://demo.johnsnowlabs.com/public/NER_RU,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,stopwords,ru,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_ru_2.5.4_2.4_1594742439248.zip,stopwords_ru_2.5.4_2.4_1594742439248.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Spanish Lemmatizer,lemma,es,2.4.0,2.4,16/02/2020,1.58189E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_es_2.4.0_2.4_1581890818386.zip,lemma_es_2.4.0_2.4_1581890818386.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Spanish,pos_ud_gsd,es,2.4.0,2.4,16/02/2020,1.58189E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_gsd_es_2.4.0_2.4_1581891015986.zip,pos_ud_gsd_es_2.4.0_2.4_1581891015986.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,WikiNER 6B 100,wikiner_6B_100,es,2.4.0,2.4,17/02/2020,1.58197E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_es_2.4.0_2.4_1581971941700.zip,wikiner_6B_100_es_2.4.0_2.4_1581971941700.zip,glove_100d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://es.wikipedia.org](https://es.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_ES.ipynb,0,https://demo.johnsnowlabs.com/public/NER_ES,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 6B 300,wikiner_6B_300,es,2.4.0,2.4,17/02/2020,1.58197E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_es_2.4.0_2.4_1581971942090.zip,wikiner_6B_300_es_2.4.0_2.4_1581971942090.zip,glove_6B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://es.wikipedia.org](https://es.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_ES.ipynb,0,https://demo.johnsnowlabs.com/public/NER_ES,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,WikiNER 840B 300,wikiner_840B_300,es,2.4.0,2.4,17/02/2020,1.58197E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_es_2.4.0_2.4_1581971942091.zip,wikiner_840B_300_es_2.4.0_2.4_1581971942091.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,The model is trained based on data from [https://es.wikipedia.org](https://es.wikipedia.org),"WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_ES.ipynb,0,https://demo.johnsnowlabs.com/public/NER_ES,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,Stop Words Cleaner for Spanish,stopwords,es,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_es_2.5.4_2.4_1594742441303.zip,stopwords_es_2.5.4_2.4_1594742441303.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,The model is imported from [https://github.com/WorldBrain/remove-stopwords](https://github.com/WorldBrain/remove-stopwords),"This model removes 'stop words' from text. Stop words are words so common that they can removed without significantly altering the meaning of a text. Removing stop words is useful when one wants to deal with only the most semantically important words in a text, and ignore words that are rarely semantically relevant, such as articles and prepositions.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/stop-words/StopWordsCleaner.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Swedish Lemmatizer,lemma,sv,2.5.0,2.4,05/05/2020,1.58867E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_sv_2.5.0_2.4_1588666548498.zip,lemma_sv_2.5.0_2.4_1588666548498.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Spanish (Venezuela),pos_ud_tal,sv,2.5.0,2.4,04/05/2020,1.58862E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_tal_sv_2.5.0_2.4_1588622711284.zip,pos_ud_tal_sv_2.5.0_2.4_1588622711284.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,sv,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_sv_2.5.4_2.4_1594742438273.zip,stopwords_sv_2.5.4_2.4_1594742438273.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,swedish_ner_6B_100,sv,2.6.0,2.4,30/08/2020,1.59881E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/swedish_ner_6B_100_sv_2.6.0_2.4_1598810268071.zip,swedish_ner_6B_100_sv_2.6.0_2.4_1598810268071.zip,glove_100d,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,swedish_ner_6B_300,sv,2.6.0,2.4,30/08/2020,1.59881E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/swedish_ner_6B_300_sv_2.6.0_2.4_1598810268071.zip,swedish_ner_6B_300_sv_2.6.0_2.4_1598810268071.zip,glove_6B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,swedish_ner_840B_300,sv,2.6.0,2.4,30/08/2020,1.59881E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/swedish_ner_840B_300_sv_2.6.0_2.4_1598810268072.zip,swedish_ner_840B_300_sv_2.6.0_2.4_1598810268072.zip,glove_840B_300,NerDLModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,John Snow Labs,ner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala
1,public/models,,stopwords,af,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_af_2.5.4_2.4_1594742440083.zip,stopwords_af_2.5.4_2.4_1594742440083.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,ar,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_ar_2.5.4_2.4_1594742440256.zip,stopwords_ar_2.5.4_2.4_1594742440256.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,hy,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_hy_2.5.4_2.4_1594742439626.zip,stopwords_hy_2.5.4_2.4_1594742439626.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Armenian Lemmatizer,lemma,hy,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_hy_2.5.5_2.4_1596054393298.zip,lemma_hy_2.5.5_2.4_1596054393298.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Armenian,pos_ud_armtdp,hy,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_armtdp_hy_2.5.5_2.4_1596053517801.zip,pos_ud_armtdp_hy_2.5.5_2.4_1596053517801.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,eu,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_eu_2.5.4_2.4_1594742441951.zip,stopwords_eu_2.5.4_2.4_1594742441951.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Basque Lemmatizer,lemma,eu,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_eu_2.5.5_2.4_1596054393659.zip,lemma_eu_2.5.5_2.4_1596054393659.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Basque,pos_ud_bdt,eu,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_bdt_eu_2.5.5_2.4_1596053577577.zip,pos_ud_bdt_eu_2.5.5_2.4_1596053577577.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,bn,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_bn_2.5.4_2.4_1594742440339.zip,stopwords_bn_2.5.4_2.4_1594742440339.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,br,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_br_2.5.4_2.4_1594742440778.zip,stopwords_br_2.5.4_2.4_1594742440778.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Breton Lemmatizer,lemma,br,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_br_2.5.5_2.4_1596054394143.zip,lemma_br_2.5.5_2.4_1596054394143.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Breton,pos_ud_keb,br,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_keb_br_2.5.5_2.4_1596053588899.zip,pos_ud_keb_br_2.5.5_2.4_1596053588899.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,Bulgarian Lemmatizer,lemma,bg,2.5.0,2.4,05/05/2020,1.58867E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_bg_2.5.0_2.4_1588666297763.zip,lemma_bg_2.5.0_2.4_1588666297763.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Bulgarian,pos_ud_btb,bg,2.5.0,2.4,04/05/2020,1.58862E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_btb_bg_2.5.0_2.4_1588621401140.zip,pos_ud_btb_bg_2.5.0_2.4_1588621401140.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,bg,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_bg_2.5.4_2.4_1594742440962.zip,stopwords_bg_2.5.4_2.4_1594742440962.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,ca,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_ca_2.5.4_2.4_1594742440888.zip,stopwords_ca_2.5.4_2.4_1594742440888.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Catalan Lemmatizer,lemma,ca,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_ca_2.5.5_2.4_1596054394549.zip,lemma_ca_2.5.5_2.4_1596054394549.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Catalan,pos_ud_ancora,ca,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_ancora_ca_2.5.5_2.4_1596053819077.zip,pos_ud_ancora_ca_2.5.5_2.4_1596053819077.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,Chinese Lemmatizer,lemma,cs,2.5.0,2.4,05/05/2020,1.58867E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_cs_2.5.0_2.4_1588666300042.zip,lemma_cs_2.5.0_2.4_1588666300042.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Czech,pos_ud_pdt,cs,2.5.0,2.4,04/05/2020,1.58862E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_pdt_cs_2.5.0_2.4_1588622155494.zip,pos_ud_pdt_cs_2.5.0_2.4_1588622155494.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,cs,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_cs_2.5.4_2.4_1594742440427.zip,stopwords_cs_2.5.4_2.4_1594742440427.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,eo,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_eo_2.5.4_2.4_1594742438724.zip,stopwords_eo_2.5.4_2.4_1594742438724.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,gl,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_gl_2.5.4_2.4_1594742441210.zip,stopwords_gl_2.5.4_2.4_1594742441210.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Galician Lemmatizer,lemma,gl,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_gl_2.5.5_2.4_1596054395787.zip,lemma_gl_2.5.5_2.4_1596054395787.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Galician,pos_ud_treegal,gl,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_treegal_gl_2.5.5_2.4_1596053906222.zip,pos_ud_treegal_gl_2.5.5_2.4_1596053906222.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,Greek Lemmatizer,lemma,el,2.5.0,2.4,05/05/2020,1.58869E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_el_2.5.0_2.4_1588686951720.zip,lemma_el_2.5.0_2.4_1588686951720.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Greek,pos_ud_gdt,el,2.5.0,2.4,05/05/2020,1.58869E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_gdt_el_2.5.0_2.4_1588686949851.zip,pos_ud_gdt_el_2.5.0_2.4_1588686949851.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,el,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_el_2.5.4_2.4_1594742437880.zip,stopwords_el_2.5.4_2.4_1594742437880.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,ha,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_ha_2.5.4_2.4_1594742441392.zip,stopwords_ha_2.5.4_2.4_1594742441392.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,he,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_he_2.5.4_2.4_1594742441877.zip,stopwords_he_2.5.4_2.4_1594742441877.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,hi,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_hi_2.5.4_2.4_1594742439035.zip,stopwords_hi_2.5.4_2.4_1594742439035.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Hindi Lemmatizer,lemma,hi,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_hi_2.5.5_2.4_1596054396201.zip,lemma_hi_2.5.5_2.4_1596054396201.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Hindi,pos_ud_hdtb,hi,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_hdtb_hi_2.5.5_2.4_1596054066666.zip,pos_ud_hdtb_hi_2.5.5_2.4_1596054066666.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,Hungarian Lemmatizer,lemma,hu,2.5.0,2.4,05/05/2020,1.58867E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_hu_2.5.0_2.4_1588671968880.zip,lemma_hu_2.5.0_2.4_1588671968880.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Hungarian,pos_ud_szeged,hu,2.5.0,2.4,05/05/2020,1.58867E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_szeged_hu_2.5.0_2.4_1588671966774.zip,pos_ud_szeged_hu_2.5.0_2.4_1588671966774.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,hu,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_hu_2.5.4_2.4_1594742441137.zip,stopwords_hu_2.5.4_2.4_1594742441137.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,id,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_id_2.5.4_2.4_1594742441630.zip,stopwords_id_2.5.4_2.4_1594742441630.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Indonesian Lemmatizer,lemma,id,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_id_2.5.5_2.4_1596054397023.zip,lemma_id_2.5.5_2.4_1596054397023.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Indonesian,pos_ud_gsd,id,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_gsd_id_2.5.5_2.4_1596054136894.zip,pos_ud_gsd_id_2.5.5_2.4_1596054136894.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,ga,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_ga_2.5.4_2.4_1594742439377.zip,stopwords_ga_2.5.4_2.4_1594742439377.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Irish Lemmatizer,lemma,ga,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_ga_2.5.5_2.4_1596054397576.zip,lemma_ga_2.5.5_2.4_1596054397576.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Irish,pos_ud_idt,ga,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_idt_ga_2.5.5_2.4_1596054150271.zip,pos_ud_idt_ga_2.5.5_2.4_1596054150271.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,ja,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_ja_2.5.4_2.4_1594742438927.zip,stopwords_ja_2.5.4_2.4_1594742438927.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,la,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_la_2.5.4_2.4_1594742439769.zip,stopwords_la_2.5.4_2.4_1594742439769.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Latin Lemmatizer,lemma,la,2.5.5,2.4,29/07/2020,1.59606E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_la_2.5.5_2.4_1596055005368.zip,lemma_la_2.5.5_2.4_1596055005368.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Latin,pos_ud_llct,la,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_llct_la_2.5.5_2.4_1596054191115.zip,pos_ud_llct_la_2.5.5_2.4_1596054191115.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,lv,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_lv_2.5.4_2.4_1594742439893.zip,stopwords_lv_2.5.4_2.4_1594742439893.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Latvian Lemmatizer,lemma,lv,2.5.5,2.4,29/07/2020,1.59606E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_lv_2.5.5_2.4_1596055006860.zip,lemma_lv_2.5.5_2.4_1596055006860.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Latvian,pos_ud_lvtb,lv,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_lvtb_lv_2.5.5_2.4_1596054308284.zip,pos_ud_lvtb_lv_2.5.5_2.4_1596054308284.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,mr,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_mr_2.5.4_2.4_1594742439994.zip,stopwords_mr_2.5.4_2.4_1594742439994.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Marathi Lemmatizer,lemma,mr,2.5.5,2.4,29/07/2020,1.59606E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_mr_2.5.5_2.4_1596055007712.zip,lemma_mr_2.5.5_2.4_1596055007712.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Marathi,pos_ud_ufal,mr,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_ufal_mr_2.5.5_2.4_1596054314811.zip,pos_ud_ufal_mr_2.5.5_2.4_1596054314811.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,fa,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_fa_2.5.4_2.4_1594742438615.zip,stopwords_fa_2.5.4_2.4_1594742438615.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Romanian Lemmatizer,lemma,ro,2.5.0,2.4,05/05/2020,1.58867E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_ro_2.5.0_2.4_1588666512149.zip,lemma_ro_2.5.0_2.4_1588666512149.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Romanian,pos_ud_rrt,ro,2.5.0,2.4,04/05/2020,1.58862E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_rrt_ro_2.5.0_2.4_1588622539956.zip,pos_ud_rrt_ro_2.5.0_2.4_1588622539956.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,ro,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_ro_2.5.4_2.4_1594742441548.zip,stopwords_ro_2.5.4_2.4_1594742441548.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Slovak Lemmatizer,lemma,sk,2.5.0,2.4,05/05/2020,1.58867E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_sk_2.5.0_2.4_1588666524270.zip,lemma_sk_2.5.0_2.4_1588666524270.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Slovak,pos_ud_snk,sk,2.5.0,2.4,04/05/2020,1.58862E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_snk_sk_2.5.0_2.4_1588622627281.zip,pos_ud_snk_sk_2.5.0_2.4_1588622627281.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,sk,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_sk_2.5.4_2.4_1594742441462.zip,stopwords_sk_2.5.4_2.4_1594742441462.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,sl,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_sl_2.5.4_2.4_1594742442155.zip,stopwords_sl_2.5.4_2.4_1594742442155.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Slovenian Lemmatizer,lemma,sl,2.5.5,2.4,29/07/2020,1.59606E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_sl_2.5.5_2.4_1596055008133.zip,lemma_sl_2.5.5_2.4_1596055008133.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Slovenian,pos_ud_ssj,sl,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_ssj_sl_2.5.5_2.4_1596054388189.zip,pos_ud_ssj_sl_2.5.5_2.4_1596054388189.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,so,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_so_2.5.4_2.4_1594742441799.zip,stopwords_so_2.5.4_2.4_1594742441799.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,st,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_st_2.5.4_2.4_1594742438831.zip,stopwords_st_2.5.4_2.4_1594742438831.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,sw,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_sw_2.5.4_2.4_1594742438383.zip,stopwords_sw_2.5.4_2.4_1594742438383.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,,stopwords,th,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_th_2.5.4_2.4_1594742440606.zip,stopwords_th_2.5.4_2.4_1594742440606.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Turkish Lemmatizer,lemma,tr,2.5.0,2.4,21/04/2020,1.58748E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_tr_2.5.0_2.4_1587479962436.zip,lemma_tr_2.5.0_2.4_1587479962436.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Turkish,pos_ud_imst,tr,2.5.0,2.4,21/04/2020,1.58748E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_imst_tr_2.5.0_2.4_1587480006078.zip,pos_ud_imst_tr_2.5.0_2.4_1587480006078.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,tr,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_tr_2.5.4_2.4_1594742440173.zip,stopwords_tr_2.5.4_2.4_1594742440173.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,English(UK) Lemmatizer,lemma,uk,2.5.0,2.4,05/05/2020,1.58867E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_uk_2.5.0_2.4_1588671294202.zip,lemma_uk_2.5.0_2.4_1588671294202.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for English(UK),pos_ud_iu,uk,2.5.0,2.4,05/05/2020,1.58867E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_iu_uk_2.5.0_2.4_1588668890963.zip,pos_ud_iu_uk_2.5.0_2.4_1588668890963.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,yo,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_yo_2.5.4_2.4_1594742440695.zip,stopwords_yo_2.5.4_2.4_1594742440695.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Yoruba Lemmatizer,lemma,yo,2.5.5,2.4,29/07/2020,1.59606E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/lemma_yo_2.5.5_2.4_1596055008864.zip,lemma_yo_2.5.5_2.4_1596055008864.zip,Lemmatizer,LemmatizerModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,John Snow Labs,lemmatizer,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model uses context and language knowledge to assign all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words. The lemmatizer takes into consideration the context surrounding a word to determine which root is correct when the word form alone is ambiguous.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/b2eb08610dd49d5b15077cc499a94b4ec1e8b861/jupyter/annotation/english/model-downloader/Create%20custom%20pipeline%20-%20NerDL.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala
1,public/models,Part of Speech for Yoruba,pos_ud_ytb,yo,2.5.5,2.4,29/07/2020,1.59605E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/pos_ud_ytb_yo_2.5.5_2.4_1596054392981.zip,pos_ud_ytb_yo_2.5.5_2.4_1596054392981.zip,POS UD,PerceptronModel,,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,John Snow Labs,pos,open source,public,,The model is imported from [https://universaldependencies.org](https://universaldependencies.org),"This model annotates the part of speech of tokens in a text. The [parts of speech](https://universaldependencies.org/u/pos/) annotated include PRON (pronoun), CCONJ (coordinating conjunction), and 15 others. The part of speech model is useful for extracting the grammatical structure of a piece of text automatically.",,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/2da56c087da53a2fac1d51774d49939e05418e57/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala
1,public/models,,stopwords,zu,2.5.4,2.4,14/07/2020,1.59474E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/stopwords_zu_2.5.4_2.4_1594742440504.zip,stopwords_zu_2.5.4_2.4_1594742440504.zip,,StopWordsCleaner,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,John Snow Labs,stopwords_cleaner,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala
1,public/models,Glove 840B 300,glove_840B_300,xx,2.0.2,2.4,22/01/2020,1.5797E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/glove_840B_300_xx_2.0.2_2.4_1579698926752.zip,glove_840B_300_xx_2.0.2_2.4_1579698926752.zip,GloVe,WordEmbeddingsModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.scala,John Snow Labs,embeddings,open source,public,300,The model is imported from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/),"GloVe (Global Vectors) is a model for distributed word representation. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity. It outperformed many common Word2vec models on the word analogy task. One benefit of GloVe is that it is the result of directly modeling relationships, instead of getting them as a side effect of training a language model.",,,1,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.WordEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.scala
1,public/models,Glove 6B 300,glove_6B_300,xx,2.0.2,2.4,22/01/2020,1.5797E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/glove_6B_300_xx_2.0.2_2.4_1579698630432.zip,glove_6B_300_xx_2.0.2_2.4_1579698630432.zip,GloVe,WordEmbeddingsModel,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.scala,John Snow Labs,embeddings,open source,public,300,The model is imported from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/),"GloVe (Global Vectors) is a model for distributed word representation. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity. It outperformed many common Word2vec models on the word analogy task. One benefit of GloVe is that it is the result of directly modeling relationships, instead of getting them as a side effect of training a language model.",,,0,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.WordEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.scala
1,public/models,,bert_multi_cased,xx,2.0.3,2.4,25/08/2020,1.59834E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_multi_cased_xx_2.0.3_2.4_1598341875191.zip,bert_multi_cased_xx_2.0.3_2.4_1598341875191.zip,,BertEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala
1,public/models,,sent_bert_multi_cased,xx,2.6.0,2.4,25/08/2020,1.59835E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/sent_bert_multi_cased_xx_2.6.0_2.4_1598347692999.zip,sent_bert_multi_cased_xx_2.6.0_2.4_1598347692999.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,labse,xx,2.6.0,2.4,23/09/2020,1.60086E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/labse_xx_2.6.0_2.4_1600858075633.zip,labse_xx_2.6.0_2.4_1600858075633.zip,,BertSentenceEmbeddings,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,John Snow Labs,embeddings,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala
1,public/models,,ld_wiki_7,xx,2.5.0,2.4,12/07/2020,1.59458E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/ld_wiki_7_xx_2.5.0_2.4_1594580829482.zip,ld_wiki_7_xx_2.5.0_2.4_1594580829482.zip,,LanguageDetectorDL,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL.scala,John Snow Labs,,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ld.dl.LanguageDetectorDL,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL.scala
1,public/models,,ld_wiki_20,xx,2.5.0,2.4,12/07/2020,1.59458E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/ld_wiki_20_xx_2.5.0_2.4_1594580837846.zip,ld_wiki_20_xx_2.5.0_2.4_1594580837846.zip,,LanguageDetectorDL,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL.scala,John Snow Labs,,open source,public,,,,,,,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ld.dl.LanguageDetectorDL,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL.scala
1,public/models,Explain Document Small,explain_document_sm,,2.6.0,2.4,30/08/2020,1.59882E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_da_2.6.0_2.4_1598817450878.zip,explain_document_sm_da_2.6.0_2.4_1598817450878.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.6.0,2.4,30/08/2020,1.59882E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_da_2.6.0_2.4_1598817214832.zip,explain_document_md_da_2.6.0_2.4_1598817214832.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.6.0,2.4,30/08/2020,1.59882E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_da_2.6.0_2.4_1598816023826.zip,explain_document_lg_da_2.6.0_2.4_1598816023826.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Small,entity_recognizer_sm,,2.6.0,2.4,30/08/2020,1.59882E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_da_2.6.0_2.4_1598818908295.zip,entity_recognizer_sm_da_2.6.0_2.4_1598818908295.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.6.0,2.4,30/08/2020,1.59882E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_da_2.6.0_2.4_1598818680084.zip,entity_recognizer_md_da_2.6.0_2.4_1598818680084.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.6.0,2.4,30/08/2020,1.59882E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_da_2.6.0_2.4_1598817534570.zip,entity_recognizer_lg_da_2.6.0_2.4_1598817534570.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Small,explain_document_sm,,2.5.0,2.4,03/05/2020,1.58855E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_nl_2.5.0_2.4_1588546621618.zip,explain_document_sm_nl_2.5.0_2.4_1588546621618.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.5.0,2.4,03/05/2020,1.58855E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_nl_2.5.0_2.4_1588546605329.zip,explain_document_md_nl_2.5.0_2.4_1588546605329.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.5.0,2.4,04/05/2020,1.58861E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_nl_2.5.0_2.4_1588612556770.zip,explain_document_lg_nl_2.5.0_2.4_1588612556770.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Small,entity_recognizer_sm,,2.5.0,2.4,03/05/2020,1.58855E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_nl_2.5.0_2.4_1588546655907.zip,entity_recognizer_sm_nl_2.5.0_2.4_1588546655907.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.5.0,2.4,03/05/2020,1.58855E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_nl_2.5.0_2.4_1588546645304.zip,entity_recognizer_md_nl_2.5.0_2.4_1588546645304.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.5.0,2.4,04/05/2020,1.58861E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_nl_2.5.0_2.4_1588612569958.zip,entity_recognizer_lg_nl_2.5.0_2.4_1588612569958.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document ML,explain_document_ml,,2.0.2,2.4,28/01/2020,1.58025E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_ml_en_2.0.2_2.4_1580252705962.zip,explain_document_ml_en_2.0.2_2.4_1580252705962.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document DL,explain_document_dl,,2.0.0,2.4,19/03/2020,1.58463E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_dl_en_2.0.0_2.4_1584626657780.zip,explain_document_dl_en_2.0.0_2.4_1584626657780.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Recognize Entities DL,recognize_entities_dl,,2.1.0,2.4,19/03/2020,1.58463E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/recognize_entities_dl_en_2.1.0_2.4_1584626752821.zip,recognize_entities_dl_en_2.1.0_2.4_1584626752821.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Recognize Entities DL,recognize_entities_bert,,2.0.0,2.4,08/09/2020,1.59955E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/recognize_entities_bert_en_2.0.0_2.4_1599554769343.zip,recognize_entities_bert_en_2.0.0_2.4_1599554769343.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,OntoNotes Entities Small,onto_recognize_entities_sm,,2.1.0,2.4,22/01/2020,1.57973E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/onto_recognize_entities_sm_en_2.1.0_2.4_1579730599257.zip,onto_recognize_entities_sm_en_2.1.0_2.4_1579730599257.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,OntoNotes Entities Large,onto_recognize_entities_lg,,2.1.0,2.4,22/01/2020,1.57973E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/onto_recognize_entities_lg_en_2.1.0_2.4_1579729320751.zip,onto_recognize_entities_lg_en_2.1.0_2.4_1579729320751.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Match Datetime,match_datetime,,2.0.0,2.4,10/03/2020,1.58385E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/match_datetime_en_2.0.0_2.4_1583845866149.zip,match_datetime_en_2.0.0_2.4_1583845866149.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Match Pattern,match_pattern,,2.0.0,2.4,21/02/2020,1.58225E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/match_pattern_en_2.0.0_2.4_1582247694074.zip,match_pattern_en_2.0.0_2.4_1582247694074.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Match Chunk,match_chunks,,2.1.0,2.4,28/01/2020,1.58025E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/match_chunks_en_2.1.0_2.4_1580246868138.zip,match_chunks_en_2.1.0_2.4_1580246868138.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Match Phrases,match_phrases,,2.0.0,2.4,28/01/2020,1.58026E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/match_phrases_en_2.0.0_2.4_1580255815623.zip,match_phrases_en_2.0.0_2.4_1580255815623.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Clean Stop,clean_stop,,2.1.0,2.4,24/03/2020,1.58507E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/clean_stop_en_2.1.0_2.4_1585072736217.zip,clean_stop_en_2.1.0_2.4_1585072736217.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Clean Pattern,clean_pattern,,2.0.0,2.4,28/01/2020,1.58025E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/clean_pattern_en_2.0.0_2.4_1580246862642.zip,clean_pattern_en_2.0.0_2.4_1580246862642.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Clean Slang,clean_slang,,2.0.0,2.4,28/01/2020,1.58026E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/clean_slang_en_2.0.0_2.4_1580255816146.zip,clean_slang_en_2.0.0_2.4_1580255816146.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Check Spelling,check_spelling,,2.0.2,2.4,28/01/2020,1.58025E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/check_spelling_en_2.0.2_2.4_1580246859135.zip,check_spelling_en_2.0.2_2.4_1580246859135.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Check Spelling DL,check_spelling_dl,,2.5.0,2.4,09/05/2020,1.58902E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/check_spelling_dl_en_2.5.0_2.4_1589015487144.zip,check_spelling_dl_en_2.5.0_2.4_1589015487144.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Analyze Sentiment,analyze_sentiment,,2.1.0,2.4,31/01/2020,1.58048E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/analyze_sentiment_en_2.1.0_2.4_1580483464667.zip,analyze_sentiment_en_2.1.0_2.4_1580483464667.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Analyze Sentiment DL,analyze_sentimentdl_use_imdb,,2.5.0,2.4,08/06/2020,1.59161E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/analyze_sentimentdl_use_imdb_en_2.5.0_2.4_1591608106144.zip,analyze_sentimentdl_use_imdb_en_2.5.0_2.4_1591608106144.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Analyze Sentiment DL,analyze_sentimentdl_use_twitter,,2.5.0,2.4,10/05/2020,1.58911E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/analyze_sentimentdl_use_twitter_en_2.5.0_2.4_1589108892106.zip,analyze_sentimentdl_use_twitter_en_2.5.0_2.4_1589108892106.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Dependency Parse,dependency_parse,,2.0.2,2.4,28/01/2020,1.58026E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/dependency_parse_en_2.0.2_2.4_1580255669655.zip,dependency_parse_en_2.0.2_2.4_1580255669655.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Small,explain_document_sm,,2.6.0,2.4,01/09/2020,1.59897E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_fi_2.6.0_2.4_1598969916062.zip,explain_document_sm_fi_2.6.0_2.4_1598969916062.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.6.0,2.4,01/09/2020,1.59897E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_fi_2.6.0_2.4_1598969670205.zip,explain_document_md_fi_2.6.0_2.4_1598969670205.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.6.0,2.4,01/09/2020,1.59897E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_fi_2.6.0_2.4_1598968459075.zip,explain_document_lg_fi_2.6.0_2.4_1598968459075.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Small,entity_recognizer_sm,,2.6.0,2.4,01/09/2020,1.59897E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_fi_2.6.0_2.4_1598971407192.zip,entity_recognizer_sm_fi_2.6.0_2.4_1598971407192.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.6.0,2.4,01/09/2020,1.59897E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_fi_2.6.0_2.4_1598971186842.zip,entity_recognizer_md_fi_2.6.0_2.4_1598971186842.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.6.0,2.4,01/09/2020,1.59897E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_fi_2.6.0_2.4_1598970014560.zip,entity_recognizer_lg_fi_2.6.0_2.4_1598970014560.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.0.2,2.4,22/01/2020,1.57971E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_fr_2.0.2_2.4_1579709189947.zip,explain_document_lg_fr_2.0.2_2.4_1579709189947.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.0.2,2.4,22/01/2020,1.57972E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_fr_2.0.2_2.4_1579722754344.zip,explain_document_md_fr_2.0.2_2.4_1579722754344.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.0.8,2.4,22/01/2020,1.57971E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_fr_2.0.8_2.4_1579710310593.zip,entity_recognizer_lg_fr_2.0.8_2.4_1579710310593.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.0.8,2.4,22/01/2020,1.57972E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_fr_2.0.8_2.4_1579722764594.zip,entity_recognizer_md_fr_2.0.8_2.4_1579722764594.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.1.0,2.4,22/01/2020,1.57972E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_de_2.1.0_2.4_1579722852211.zip,explain_document_lg_de_2.1.0_2.4_1579722852211.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.1.0,2.4,22/01/2020,1.57972E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_de_2.1.0_2.4_1579722872528.zip,explain_document_md_de_2.1.0_2.4_1579722872528.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.1.0,2.4,22/01/2020,1.57972E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_de_2.1.0_2.4_1579722883057.zip,entity_recognizer_lg_de_2.1.0_2.4_1579722883057.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.1.0,2.4,22/01/2020,1.57972E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_de_2.1.0_2.4_1579722895254.zip,entity_recognizer_md_de_2.1.0_2.4_1579722895254.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.0.8,2.4,22/01/2020,1.57972E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_it_2.0.8_2.4_1579722789680.zip,explain_document_lg_it_2.0.8_2.4_1579722789680.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.0.8,2.4,22/01/2020,1.57972E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_it_2.0.8_2.4_1579722813892.zip,explain_document_md_it_2.0.8_2.4_1579722813892.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.0.8,2.4,22/01/2020,1.57972E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_it_2.0.8_2.4_1579722823718.zip,entity_recognizer_lg_it_2.0.8_2.4_1579722823718.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.0.8,2.4,22/01/2020,1.57972E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_it_2.0.8_2.4_1579722834033.zip,entity_recognizer_md_it_2.0.8_2.4_1579722834033.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Small,explain_document_sm,,2.5.0,2.4,06/05/2020,1.58878E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_no_2.5.0_2.4_1588784132955.zip,explain_document_sm_no_2.5.0_2.4_1588784132955.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.5.0,2.4,06/05/2020,1.58878E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_no_2.5.0_2.4_1588783879809.zip,explain_document_md_no_2.5.0_2.4_1588783879809.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.5.0,2.4,06/05/2020,1.58878E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_no_2.5.0_2.4_1588782610672.zip,explain_document_lg_no_2.5.0_2.4_1588782610672.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Small,entity_recognizer_sm,,2.5.0,2.4,06/05/2020,1.58879E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_no_2.5.0_2.4_1588794567766.zip,entity_recognizer_sm_no_2.5.0_2.4_1588794567766.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.5.0,2.4,06/05/2020,1.58879E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_no_2.5.0_2.4_1588794357614.zip,entity_recognizer_md_no_2.5.0_2.4_1588794357614.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.5.0,2.4,06/05/2020,1.58879E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_no_2.5.0_2.4_1588793261642.zip,entity_recognizer_lg_no_2.5.0_2.4_1588793261642.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Small,explain_document_sm,,2.5.0,2.4,03/05/2020,1.58853E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_pl_2.5.0_2.4_1588531081173.zip,explain_document_sm_pl_2.5.0_2.4_1588531081173.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.5.0,2.4,03/05/2020,1.58853E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_pl_2.5.0_2.4_1588530841737.zip,explain_document_md_pl_2.5.0_2.4_1588530841737.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.5.0,2.4,03/05/2020,1.58853E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_pl_2.5.0_2.4_1588529695577.zip,explain_document_lg_pl_2.5.0_2.4_1588529695577.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Small,entity_recognizer_sm,,2.5.0,2.4,03/05/2020,1.58853E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_pl_2.5.0_2.4_1588532616080.zip,entity_recognizer_sm_pl_2.5.0_2.4_1588532616080.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.5.0,2.4,03/05/2020,1.58853E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_pl_2.5.0_2.4_1588532376753.zip,entity_recognizer_md_pl_2.5.0_2.4_1588532376753.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.5.0,2.4,03/05/2020,1.58853E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_pl_2.5.0_2.4_1588531171903.zip,entity_recognizer_lg_pl_2.5.0_2.4_1588531171903.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Small,explain_document_sm,,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_pt_2.5.0_2.4_1588501423743.zip,explain_document_sm_pt_2.5.0_2.4_1588501423743.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_pt_2.5.0_2.4_1588501189804.zip,explain_document_md_pt_2.5.0_2.4_1588501189804.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_pt_2.5.0_2.4_1588500056427.zip,explain_document_lg_pt_2.5.0_2.4_1588500056427.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Small,entity_recognizer_sm,,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_pt_2.5.0_2.4_1588502815900.zip,entity_recognizer_sm_pt_2.5.0_2.4_1588502815900.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_pt_2.5.0_2.4_1588502606198.zip,entity_recognizer_md_pt_2.5.0_2.4_1588502606198.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.5.0,2.4,03/05/2020,1.5885E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_pt_2.5.0_2.4_1588501526324.zip,entity_recognizer_lg_pt_2.5.0_2.4_1588501526324.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Small,explain_document_sm,,2.4.4,2.4,12/03/2020,1.58402E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_ru_2.4.4_2.4_1584017142719.zip,explain_document_sm_ru_2.4.4_2.4_1584017142719.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.4.4,2.4,12/03/2020,1.58402E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_ru_2.4.4_2.4_1584016917220.zip,explain_document_md_ru_2.4.4_2.4_1584016917220.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.4.4,2.4,12/03/2020,1.58402E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_ru_2.4.4_2.4_1584015824836.zip,explain_document_lg_ru_2.4.4_2.4_1584015824836.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Small,entity_recognizer_sm,,2.4.4,2.4,12/03/2020,1.58402E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_ru_2.4.4_2.4_1584018543619.zip,entity_recognizer_sm_ru_2.4.4_2.4_1584018543619.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.4.4,2.4,12/03/2020,1.58402E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_ru_2.4.4_2.4_1584018332357.zip,entity_recognizer_md_ru_2.4.4_2.4_1584018332357.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.4.4,2.4,12/03/2020,1.58402E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_ru_2.4.4_2.4_1584017227871.zip,entity_recognizer_lg_ru_2.4.4_2.4_1584017227871.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Small,explain_document_sm,,2.4.0,2.4,17/02/2020,1.58198E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_es_2.4.0_2.4_1581977077084.zip,explain_document_sm_es_2.4.0_2.4_1581977077084.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.4.0,2.4,17/02/2020,1.58198E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_es_2.4.0_2.4_1581976836224.zip,explain_document_md_es_2.4.0_2.4_1581976836224.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.4.0,2.4,17/02/2020,1.58198E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_es_2.4.0_2.4_1581975536033.zip,explain_document_lg_es_2.4.0_2.4_1581975536033.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Small,entity_recognizer_sm,,2.4.0,2.4,17/02/2020,1.58198E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_es_2.4.0_2.4_1581978479912.zip,entity_recognizer_sm_es_2.4.0_2.4_1581978479912.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.4.0,2.4,17/02/2020,1.58198E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_es_2.4.0_2.4_1581978260094.zip,entity_recognizer_md_es_2.4.0_2.4_1581978260094.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.4.0,2.4,17/02/2020,1.58198E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_es_2.4.0_2.4_1581977172660.zip,entity_recognizer_lg_es_2.4.0_2.4_1581977172660.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Small,explain_document_sm,,2.6.0,2.4,30/08/2020,1.59881E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_sm_sv_2.6.0_2.4_1598814474447.zip,explain_document_sm_sv_2.6.0_2.4_1598814474447.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Medium,explain_document_md,,2.6.0,2.4,30/08/2020,1.59881E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_md_sv_2.6.0_2.4_1598814189476.zip,explain_document_md_sv_2.6.0_2.4_1598814189476.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Explain Document Large,explain_document_lg,,2.6.0,2.4,30/08/2020,1.59881E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_lg_sv_2.6.0_2.4_1598812951336.zip,explain_document_lg_sv_2.6.0_2.4_1598812951336.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Small,entity_recognizer_sm,,2.6.0,2.4,30/08/2020,1.59882E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_sm_sv_2.6.0_2.4_1598815928569.zip,entity_recognizer_sm_sv_2.6.0_2.4_1598815928569.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Medium,entity_recognizer_md,,2.6.0,2.4,30/08/2020,1.59882E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_md_sv_2.6.0_2.4_1598815702563.zip,entity_recognizer_md_sv_2.6.0_2.4_1598815702563.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,Entity Recognizer Large,entity_recognizer_lg,,2.6.0,2.4,30/08/2020,1.59881E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/entity_recognizer_lg_sv_2.6.0_2.4_1598814573031.zip,entity_recognizer_lg_sv_2.6.0_2.4_1598814573031.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,LanguageDetectorDL,detect_language_7,,2.5.0,2.4,12/07/2020,1.59458E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/detect_language_7_xx_2.5.0_2.4_1594580832687.zip,detect_language_7_xx_2.5.0_2.4_1594580832687.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,public/models,LanguageDetectorDL,detect_language_20,,2.5.0,2.4,12/07/2020,1.59458E+12,,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/detect_language_20_xx_2.5.0_2.4_1594580840930.zip,detect_language_20_xx_2.5.0_2.4_1594580840930.zip,,Pipeline,,,John Snow Labs,pipeline,open source,public,,,,,,,,,
1,clinical/models,Assertion DL Clinical Embeddings,assertion_dl,en,2.4.0,2.4,28/01/2020,1.58024E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertion_dl_en_2.4.0_2.4_1580237286004.zip,assertion_dl_en_2.4.0_2.4_1580237286004.zip,embeddings_clinical,AssertionDLModel,"hypothetical, present, absent, possible, conditional, associated_with_someone_else",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,assertion",Licensed ,Healthcare,,"Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with `embeddings_clinical`",Deep learning named entity recognition model for assertions ,,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.Clinical_Assertion_Model.ipynb,0,,,
1,clinical/models,Assertion DL Healthcare Embeddings,assertion_dl_healthcare,en,2.6.0,2.4,23/09/2020,1.60085E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertion_dl_healthcare_en_2.6.0_2.4_1600849811713.zip,assertion_dl_healthcare_en_2.6.0_2.4_1600849811713.zip,embeddings_healthcare_100d,AssertionDLModel,"hypothetical, present, absent, possible, conditional, associated_with_someone_else",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,assertion",Licensed ,Healthcare,,"Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with `embeddings_clinical`",Deep learning named entity recognition model for assertions ,,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.Clinical_Assertion_Model.ipynb,0,,,
1,clinical/models,Assertion DL Large,assertion_dl_large,en,2.4.2,2.4,21/05/2020,1.59002E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertion_dl_large_en_2.5.0_2.4_1590022282256.zip,assertion_dl_large_en_2.5.0_2.4_1590022282256.zip,embeddings_clinical,AssertionDLModel,"hypothetical, present, absent, possible, conditional, associated_with_someone_else",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,assertion",Licensed ,Healthcare,,"Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with `embeddings_clinical`",Deep learning named entity recognition model for assertions ,,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.Clinical_Assertion_Model.ipynb,0,,,
1,clinical/models,Assertion DL I2B2,assertion_i2b2,en,2.4.2,2.4,07/05/2020,1.58881E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertion_i2b2_en_2.4.2_2.4_1588811895962.zip,assertion_i2b2_en_2.4.2_2.4_1588811895962.zip,embeddings_clinical,AssertionDLModel,"hypothetical, present, absent, possible, conditional, associated_with_someone_else",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,assertion",Licensed ,Healthcare,,"Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with `embeddings_clinical`",Deep learning named entity recognition model for assertions ,,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.Clinical_Assertion_Model.ipynb,0,,,
1,clinical/models,Assertion ML,assertion_ml,en,2.4.0,2.4,28/01/2020,1.58024E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertion_ml_en_2.4.0_2.4_1580237286004.zip,assertion_ml_en_2.4.0_2.4_1580237286004.zip,embeddings_clinical,AssertionLogRegModel,"hypothetical, present, absent, possible, conditional, associated_with_someone_else",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,assertion",Licensed ,Healthcare,,"Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with `embeddings_clinical`",Deep learning named entity recognition model for assertions ,,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.Clinical_Assertion_Model.ipynb,0,,,
0,clinical/models,Biobert Clinical Base Cased,biobert_clinical_base_cased,en,2.5.0,2.4,26/05/2020,1.59049E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobert_clinical_base_cased_en_2.5.0_2.4_1590489819943.zip,biobert_clinical_base_cased_en_2.5.0_2.4_1590489819943.zip,,BertEmbeddings,Contextual feature vectors based on biobert_clinical_base_cased,https://github.com/naver/biobert-pretrained,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,768,Trained on PubMed + MIMIC III corpora,Contextual embeddings representation using biobert_clinical_base_cased,,,1,,,
0,clinical/models,Biobert Discharge Base Cased,biobert_discharge_base_cased,en,2.5.0,2.4,26/05/2020,1.59049E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobert_discharge_base_cased_en_2.5.0_2.4_1590490193605.zip,biobert_discharge_base_cased_en_2.5.0_2.4_1590490193605.zip,,BertEmbeddings,Contextual feature vectors based on biobert_discharge_base_cased,https://github.com/naver/biobert-pretrained,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,768,Trained on PubMed + MIMIC III corpora,Contextual embeddings representation using biobert_discharge_base_cased,,,1,,,
0,clinical/models,Biobert Pmc Base Cased,biobert_pmc_base_cased,en,2.5.0,2.4,26/05/2020,1.59049E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobert_pmc_base_cased_en_2.5.0_2.4_1590489029151.zip,biobert_pmc_base_cased_en_2.5.0_2.4_1590489029151.zip,,BertEmbeddings,Contextual feature vectors based on biobert_pmc_base_cased,https://github.com/naver/biobert-pretrained,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,768,Trained on PubMed + MIMIC III corpora,Contextual embeddings representation using biobert_pmc_base_cased,,,1,,,
0,clinical/models,Biobert Pubmed Base Cased,biobert_pubmed_base_cased,en,2.5.0,2.4,15/09/2020,1.60018E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobert_pubmed_base_cased_en_2.6.0_2.4_1600182457870.zip,biobert_pubmed_base_cased_en_2.6.0_2.4_1600182457870.zip,,BertEmbeddings,Contextual feature vectors based on biobert_pubmed_base_cased,https://github.com/naver/biobert-pretrained,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,768,Trained on PubMed + MIMIC III corpora,Contextual embeddings representation using biobert_pubmed_base_cased,,,1,,,
0,clinical/models,Biobert Pubmed Large Cased,biobert_pubmed_large_cased,en,2.5.0,2.4,16/09/2020,1.60024E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobert_pubmed_large_cased_en_2.6.0_2.4_1600240494946.zip,biobert_pubmed_large_cased_en_2.6.0_2.4_1600240494946.zip,,BertEmbeddings,Contextual feature vectors based on biobert_pubmed_large_cased,https://github.com/naver/biobert-pretrained,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,768,Trained on PubMed + MIMIC III corpora,Contextual embeddings representation using biobert_pubmed_large_cased,,,1,,,
0,clinical/models,Biobert Pubmed Pmc Base Cased,biobert_pubmed_pmc_base_cased,en,2.5.0,2.4,26/05/2020,1.59049E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobert_pubmed_pmc_base_cased_en_2.5.0_2.4_1590489367180.zip,biobert_pubmed_pmc_base_cased_en_2.5.0_2.4_1590489367180.zip,,BertEmbeddings,Contextual feature vectors based on biobert_pubmed_pmc_base_cased,https://github.com/naver/biobert-pretrained,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,768,Trained on PubMed + MIMIC III corpora,Contextual embeddings representation using biobert_pubmed_pmc_base_cased,,,1,,,
1,clinical/models,ChunkResolver ICD10GM,chunkresolve_ICD10GM,de,2.5.5,2.4,06/09/2020,1.59943E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_ICD10GM_de_2.5.5_2.4_1599431635423.zip,chunkresolve_ICD10GM_de_2.5.5_2.4_1599431635423.zip,w2v_cc_300d,ChunkEntityResolverModel,Codes and their normalized definition with `clinical_embeddings`,,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,FILLUP,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_ICD10_GM_DE/,,
1,clinical/models,ChunkResolver Athena Conditions Healthcare,chunkresolve_athena_conditions_healthcare,en,2.6.0,2.4,16/09/2020,1.60027E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_athena_conditions_healthcare_en_2.6.0_2.4_1600265258887.zip,chunkresolve_athena_conditions_healthcare_en_2.6.0_2.4_1600265258887.zip,embeddings_healthcare_100d,ChunkEntityResolverModel,Athena Codes and their normalized definition,,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on Athena dataset,,,,1,,,
1,clinical/models,ChunkResolver CPT Clinical,chunkresolve_cpt_clinical,en,2.4.2,2.4,21/04/2020,1.58749E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_cpt_clinical_en_2.4.5_2.4_1587491373378.zip,chunkresolve_cpt_clinical_en_2.4.5_2.4_1587491373378.zip,embeddings_clinical,ChunkEntityResolverModel,chunkresolve_cpt_clinical Codes and their normalized definition,,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on Current Procedural Terminology dataset,,,,1,,,
1,clinical/models,ChunkResolver ICD10CM Clinical,chunkresolve_icd10cm_clinical,en,2.4.2,2.4,21/04/2020,1.58749E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_icd10cm_clinical_en_2.4.5_2.4_1587491222166.zip,chunkresolve_icd10cm_clinical_en_2.4.5_2.4_1587491222166.zip,embeddings_clinical,ChunkEntityResolverModel,ICD10-CM Codes and their normalized definition with `clinical_embeddings`,https://www.icd10data.com/ICD10CM/Codes/,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD10 Clinical Modification datasetwith tenths of variations per code,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/enterprise/healthcare/EntityResolution_ICD10_RxNorm_Detailed.ipynb,1,https://demo.johnsnowlabs.com/healthcare/ER_ICD10_CM/,,
1,clinical/models,ChunkResolver ICD10CM Diseases Clinical,chunkresolve_icd10cm_diseases_clinical,en,2.4.5,2.4,28/04/2020,1.58811E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_icd10cm_diseases_clinical_en_2.4.5_2.4_1588105984876.zip,chunkresolve_icd10cm_diseases_clinical_en_2.4.5_2.4_1588105984876.zip,embeddings_clinical,ChunkEntityResolverModel,ICD10-CM Codes and their normalized definition with `clinical_embeddings`,https://www.icd10data.com/ICD10CM/Codes/,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD10CM Dataset Range: A000-N989 Except Neoplasms and Musculoskeletal,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_ICD10_CM/,,
1,clinical/models,ChunkResolver ICD10CM Injuries Clinical,chunkresolve_icd10cm_injuries_clinical,en,2.4.5,2.4,28/04/2020,1.5881E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_icd10cm_injuries_clinical_en_2.4.5_2.4_1588103825347.zip,chunkresolve_icd10cm_injuries_clinical_en_2.4.5_2.4_1588103825347.zip,embeddings_clinical,ChunkEntityResolverModel,ICD10-CM Codes and their normalized definition with `clinical_embeddings`,https://www.icd10data.com/ICD10CM/Codes/S00-T88,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD10CM Dataset Range: S0000XA-S98929S ,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_ICD10_CM/,,
1,clinical/models,ChunkResolver ICD10CM Musculoskeletal Clinical,chunkresolve_icd10cm_musculoskeletal_clinical,en,2.4.5,2.4,28/04/2020,1.5881E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_icd10cm_musculoskeletal_clinical_en_2.4.5_2.4_1588103998999.zip,chunkresolve_icd10cm_musculoskeletal_clinical_en_2.4.5_2.4_1588103998999.zip,embeddings_clinical,ChunkEntityResolverModel,ICD10-CM Codes and their normalized definition with `clinical_embeddings`,https://www.icd10data.com/ICD10CM/Codes/M00-M99,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD10CM Dataset Range: M0000-M9979XXS,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_ICD10_CM/,,
1,clinical/models,ChunkResolver ICD10CM Neoplasms Clinical,chunkresolve_icd10cm_neoplasms_clinical,en,2.4.5,2.4,28/04/2020,1.58811E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_icd10cm_neoplasms_clinical_en_2.4.5_2.4_1588108205630.zip,chunkresolve_icd10cm_neoplasms_clinical_en_2.4.5_2.4_1588108205630.zip,embeddings_clinical,ChunkEntityResolverModel,ICD10-CM Codes and their normalized definition with `clinical_embeddings`,https://www.icd10data.com/ICD10CM/Codes/C00-D49,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,"Trained on ICD10CM Dataset Ranges: C000-D489, R590-R599",,,,1,https://demo.johnsnowlabs.com/healthcare/ER_ICD10_CM/,,
1,clinical/models,ChunkResolver ICD10CM Poison Ext Clinical,chunkresolve_icd10cm_poison_ext_clinical,en,2.4.5,2.4,28/04/2020,1.58811E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_icd10cm_poison_ext_clinical_en_2.4.5_2.4_1588106053455.zip,chunkresolve_icd10cm_poison_ext_clinical_en_2.4.5_2.4_1588106053455.zip,embeddings_clinical,ChunkEntityResolverModel,ICD10-CM Codes and their normalized definition with `clinical_embeddings`,https://www.icd10data.com/ICD10CM/Codes/S00-T88,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD10CM Dataset Range: T1500XA-T879,,,,1,,,
1,clinical/models,ChunkResolver ICD10CM Puerile Clinical,chunkresolve_icd10cm_puerile_clinical,en,2.4.5,2.4,28/04/2020,1.5881E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_icd10cm_puerile_clinical_en_2.4.5_2.4_1588103916781.zip,chunkresolve_icd10cm_puerile_clinical_en_2.4.5_2.4_1588103916781.zip,embeddings_clinical,ChunkEntityResolverModel,ICD10-CM Codes and their normalized definition with `clinical_embeddings`,https://www.icd10data.com/ICD10CM/Codes/O00-O9A,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD10CM Dataset Range: O0000-O9989,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_ICD10_CM/,,
1,clinical/models,ChunkResolver ICD10PCS Clinical,chunkresolve_icd10pcs_clinical,en,2.4.2,2.4,21/04/2020,1.58749E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_icd10pcs_clinical_en_2.4.5_2.4_1587491320087.zip,chunkresolve_icd10pcs_clinical_en_2.4.5_2.4_1587491320087.zip,embeddings_clinical,ChunkEntityResolverModel,ICD10-PCS Codes and their normalized definition with `clinical_embeddings`,https://www.icd10data.com/ICD10PCS/Codes,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD10 Procedure Coding System dataset,,,,1,,,
1,clinical/models,ChunkResolver ICDO Clinical,chunkresolve_icdo_clinical,en,2.4.2,2.4,21/04/2020,1.58749E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_icdo_clinical_en_2.4.5_2.4_1587491354644.zip,chunkresolve_icdo_clinical_en_2.4.5_2.4_1587491354644.zip,embeddings_clinical,ChunkEntityResolverModel,ICD-O Codes and their normalized definition with `clinical_embeddings`,https://apps.who.int/iris/bitstream/handle/10665/96612/9789241548496_eng.pdf,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD-O Histology Behaviour dataset,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_ICDO/,,
1,clinical/models,ChunkResolver LOINC Clinical,chunkresolve_loinc_clinical,en,2.5.0,2.4,16/05/2020,1.5896E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_loinc_clinical_en_2.5.0_2.4_1589599195201.zip,chunkresolve_loinc_clinical_en_2.5.0_2.4_1589599195201.zip,embeddings_clinical,ChunkEntityResolverModel,LOINC Codes and ther Standard Name with `clinical_embeddings`,https://loinc.org/,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on LOINC dataset with `embeddings_clinical`,,,,1,,,
1,clinical/models,ChunkResolver RxNorm Cd Clinical,chunkresolve_rxnorm_cd_clinical,en,2.5.1,2.4,27/07/2020,1.59581E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_rxnorm_cd_clinical_en_2.5.1_2.4_1595813950836.zip,chunkresolve_rxnorm_cd_clinical_en_2.5.1_2.4_1595813950836.zip,embeddings_clinical,ChunkEntityResolverModel,RxNorm Codes and their normalized definition with `clinical_embeddings`,https://www.nlm.nih.gov/pubs/techbull/nd19/brief/nd19_rxnorm_december_2019_release.html,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on December 2019 RxNorm Clinical Drugs (TTY=CD) ontology graph with `embeddings_clinical`,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_RXNORM/,,
1,clinical/models,ChunkResolver RxNorm Sbd Clinical,chunkresolve_rxnorm_sbd_clinical,en,2.5.1,2.4,27/07/2020,1.59581E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_rxnorm_sbd_clinical_en_2.5.1_2.4_1595813912622.zip,chunkresolve_rxnorm_sbd_clinical_en_2.5.1_2.4_1595813912622.zip,embeddings_clinical,ChunkEntityResolverModel,RxNorm Codes and their normalized definition with `clinical_embeddings`,https://www.nlm.nih.gov/pubs/techbull/nd19/brief/nd19_rxnorm_december_2019_release.html,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on December 2019 RxNorm Clinical Drugs (TTY=SBD) ontology graph with `embeddings_clinical`,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_RXNORM/,,
1,clinical/models,ChunkResolver RxNorm Scd Clinical,chunkresolve_rxnorm_scd_clinical,en,2.5.1,2.4,27/07/2020,1.59581E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_rxnorm_scd_clinical_en_2.5.1_2.4_1595813884363.zip,chunkresolve_rxnorm_scd_clinical_en_2.5.1_2.4_1595813884363.zip,embeddings_clinical,ChunkEntityResolverModel,RxNorm Codes and their normalized definition with `clinical_embeddings`,https://www.nlm.nih.gov/pubs/techbull/nd19/brief/nd19_rxnorm_december_2019_release.html,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on December 2019 RxNorm Clinical Drugs (TTY=SCD) ontology graph with `embeddings_clinical`,,,,1,,,
1,clinical/models,ChunkResolver RxNorm Xsmall Clinical,chunkresolve_rxnorm_xsmall_clinical,en,2.5.2,2.4,24/06/2020,1.59296E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_rxnorm_xsmall_clinical_en_2.5.2_2.4_1592959394598.zip,chunkresolve_rxnorm_xsmall_clinical_en_2.5.2_2.4_1592959394598.zip,embeddings_clinical,ChunkEntityResolverModel,Snomed Codes and their normalized definition with `clinical_embeddings`,http://www.snomed.org/,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on December 2019 RxNorm Subset,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/13.Snomed_Entity_Resolver_Model_Training.ipynb,1,,,
1,clinical/models,ChunkResolver SNOMED Findings Clinical,chunkresolve_snomed_findings_clinical,en,2.5.1,2.4,20/06/2020,1.59262E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/chunkresolve_snomed_findings_clinical_en_2.5.1_2.4_1592617161564.zip,chunkresolve_snomed_findings_clinical_en_2.5.1_2.4_1592617161564.zip,embeddings_clinical,ChunkEntityResolverModel,Snomed Codes and their normalized definition with `clinical_embeddings`,http://www.snomed.org/,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on SNOMED CT Findings,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/13.Snomed_Entity_Resolver_Model_Training.ipynb,1,https://demo.johnsnowlabs.com/healthcare/ER_SNOMED/,,
1,clinical/models,SentenceResolver CPT Clinical,biobertresolve_cpt,en,2.6.3,2.4,26/10/2020,1603673114746,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobertresolve_cpt_en_2.6.3_2.4_1603673114746.zip,biobertresolve_cpt_en_2.6.3_2.4_1603673114746.zip,sent_biobert_pubmed_base_cased,SentenceEntityResolverModel,CPT Codes and their normalized definition with BertSentenceEmbeddings: `sent_biobert_pubmed_base_cased`,https://en.wikipedia.org/wiki/Current_Procedural_Terminology,John Snow Labs,"clinical,entity_resolver,cpt",Licensed ,Healthcare,,Trained on Current Procedural Terminology dataset,,,,1,,,
1,clinical/models,SentenceResolver ICD10CM BioBert,biobertresolve_icd10cm,en,2.6.3,2.4,26/10/2020,1603673704767,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobertresolve_icd10cm_en_2.6.3_2.4_1603673704767.zip,biobertresolve_icd10cm_en_2.6.3_2.4_1603673704767.zip,sent_biobert_pubmed_base_cased,SentenceEntityResolverModel,ICD10-CM Codes and their normalized definition with BertSentenceEmbeddings: `sent_biobert_pubmed_base_cased`,https://www.icd10data.com/ICD10CM/Codes/,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD10CM Dataset,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_ICD10_CM/,,
1,clinical/models,SentenceResolver ICD10PCS BioBert,biobertresolve_icd10pcs,en,2.6.3,2.4,26/10/2020,1603678407701,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobertresolve_icd10pcs_en_2.6.3_2.4_1603678407701.zip,biobertresolve_icd10pcs_en_2.6.3_2.4_1603678407701.zip,sent_biobert_pubmed_base_cased,SentenceEntityResolverModel,ICD10-PCS Codes and their normalized definition with BertSentenceEmbeddings: `sent_biobert_pubmed_base_cased`,https://www.icd10data.com/ICD10PCS/Codes,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD10 Procedure Coding System dataset,,,,1,,,
1,clinical/models,SentenceResolver ICDO BioBert,biobertresolve_icdo,en,2.6.3,2.4,26/10/2020,1603673101579,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobertresolve_icdo_en_2.6.3_2.4_1603673101579.zip,biobertresolve_icdo_en_2.6.3_2.4_1603673101579.zip,sent_biobert_pubmed_base_cased,SentenceEntityResolverModel,ICD-O Codes and their normalized definition with BertSentenceEmbeddings: `sent_biobert_pubmed_base_cased`,https://apps.who.int/iris/bitstream/handle/10665/96612/9789241548496_eng.pdf,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on ICD-O Histology Behaviour dataset,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_ICDO/,,
1,clinical/models,SentenceResolver LOINC BioBert,biobertresolve_loinc,en,2.6.3,2.4,26/10/2020,1603677434936,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobertresolve_loinc_en_2.6.3_2.4_1603677434936.zip,biobertresolve_loinc_en_2.6.3_2.4_1603677434936.zip,sent_biobert_pubmed_base_cased,SentenceEntityResolverModel,LOINC Codes and ther Standard Name with BertSentenceEmbeddings: `sent_biobert_pubmed_base_cased`,https://loinc.org/,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on LOINC dataset with `embeddings_clinical`,,,,1,,,
1,clinical/models,SentenceResolver RxNorm Branded and Clinical Drug BioBert,biobertresolve_rxnorm_bdcd,en,2.6.3,2.4,26/10/2020,1603683487151,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobertresolve_rxnorm_bdcd_en_2.6.3_2.4_1603683487151.zip,biobertresolve_rxnorm_bdcd_en_2.6.3_2.4_1603683487151.zip,sent_biobert_pubmed_base_cased,SentenceEntityResolverModel,RxNorm Codes and their normalized definition with BertSentenceEmbeddings: `sent_biobert_pubmed_base_cased`,https://www.nlm.nih.gov/pubs/techbull/nd19/brief/nd19_rxnorm_december_2019_release.html,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on December 2019 RxNorm Clinical Drugs (TTY=CD) ontology graph with `embeddings_clinical`,,,,1,https://demo.johnsnowlabs.com/healthcare/ER_RXNORM/,,
1,clinical/models,SentenceResolver SNOMED Findings BioBert,biobertresolve_snomed_findings_clinical,en,2.6.3,2.4,26/10/2020,1603209744068E,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biobertresolve_snomed_findings_en_2.6.3_2.4_1603209744068.zip,biobertresolve_snomed_findings_en_2.6.3_2.4_1603209744068.zip,sent_biobert_pubmed_base_cased,SentenceEntityResolverModel,Snomed Codes and their normalized definition with BertSentenceEmbeddings: `sent_biobert_pubmed_base_cased`,http://www.snomed.org/,John Snow Labs,"clinical,entity_resolver",Licensed ,Healthcare,,Trained on SNOMED CT Findings,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/13.Snomed_Entity_Resolver_Model_Training.ipynb,1,https://demo.johnsnowlabs.com/healthcare/ER_SNOMED/,,
0,clinical/models,Classifierdl Biobert Adverse Events,classifierdl_biobert_ade,en,2.6.0,2.4,15/09/2020,1.6002E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/classifierdl_biobert_ade_en_2.6.0_2.4_1600201949450.zip,classifierdl_biobert_ade_en_2.6.0_2.4_1600201949450.zip,FILLUP,ClassifierDLModel,FILLUP,FILLUP,John Snow Labs,"clinical,classifier",Licensed ,Healthcare,,FILLUP,,,,,,,
0,clinical/models,Clinical Analysis,clinical_analysis,en,2.4.0,2.4,01/02/2020,1.5806E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/clinical_analysis_en_2.4.0_2.4_1580600773378.zip,clinical_analysis_en_2.4.0_2.4_1580600773378.zip,,PipelineModel,,,John Snow Labs,"clinical,pipeline",Licensed ,Healthcare,,,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb,,,,
0,clinical/models,Clinical Deidentification,clinical_deidentification,en,2.4.0,2.4,31/01/2020,1.58048E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/clinical_deidentification_en_2.4.0_2.4_1580481115376.zip,clinical_deidentification_en_2.4.0_2.4_1580481115376.zip,,PipelineModel,,,John Snow Labs,"clinical,pipeline",Licensed ,Healthcare,,,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb,,,,
0,clinical/models,Clinical Ner Assertion,clinical_ner_assertion,en,2.4.0,2.4,31/01/2020,1.58048E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/clinical_ner_assertion_en_2.4.0_2.4_1580481098096.zip,clinical_ner_assertion_en_2.4.0_2.4_1580481098096.zip,,PipelineModel,,,John Snow Labs,"clinical,pipeline",Licensed ,Healthcare,,,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb,,,,
0,clinical/models,Deidentify DL,deidentify_dl,en,2.4.0,2.4,28/01/2020,1.58024E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/deidentify_dl_en_2.4.0_2.4_1580237286004.zip,deidentify_dl_en_2.4.0_2.4_1580237286004.zip,embeddings_clinical,NerDLModel,"AGE,BIOID,CITY,COUNTRY,DATE,DOCTOR,EMAIL,FAX,HEALTHPLAN,HOSPITAL,IDNUM,MEDICALRECORD,ORGANIZATION,OTHER,PATIENT,PHONE,PROFESSION,STATE,STREET,USERNAME,X,ZIP",,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Rule based DeIdentifier based on `ner_deid`,,,,,,,
1,clinical/models,Deidentify Large,deidentify_large,en,2.5.1,2.4,19/07/2020,1.5952E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/deidentify_large_en_2.5.1_2.4_1595199111307.zip,deidentify_large_en_2.5.1_2.4_1595199111307.zip,ner_deid_large,DeIdentificationModel,"Contact, Location, Name, Profession",https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/,John Snow Labs,"clinical,deidentification",Licensed ,Healthcare,,"Trained on 10.000 Contact, Location, Name and Profession random replacements","Deidentify (Large) is a deidentification model. It identifies instances of protected health information in text documents, and it can either obfuscate them (e.g., replacing names with different, fake names) or mask them (e.g., replacing ""2020,06,04"" with ""<DATE>""). This model is useful for maintaining HIPAA compliance when dealing with text documents that contain protected health information.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentificiation.ipynb,,https://demo.johnsnowlabs.com/healthcare/DEID_PHI_TEXT,,
1,clinical/models,Deidentify RB,deidentify_rb,en,2.0.2,2.4,04/06/2019,1.55967E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/deidentify_rb_en_2.0.2_2.4_1559672122511.zip,deidentify_rb_en_2.0.2_2.4_1559672122511.zip,ner_deid,DeIdentificationModel,Personal Information in order to deidentify,,John Snow Labs,"clinical,deidentification",Licensed ,Healthcare,,Rule based DeIdentifier based on `ner_deid`,,,,,,,
1,clinical/models,Deidentify RB No Regex,deidentify_rb_no_regex,en,2.4.5,2.4,19/05/2020,1.58992E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/deidentify_rb_no_regex_en_2.5.0_2.4_1589924063833.zip,deidentify_rb_no_regex_en_2.5.0_2.4_1589924063833.zip,ner_deid,DeIdentificationModel,Personal Information in order to deidentify,,John Snow Labs,"clinical,deidentification",Licensed ,Healthcare,,Rule based DeIdentifier based on `ner_deid`,,,,,,,
1,clinical/models,Embeddings BioVec,embeddings_biovec,en,2.5.0,2.4,02/06/2020,1.59107E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_biovec_en_2.5.0_2.4_1591068211397.zip,embeddings_biovec_en_2.5.0_2.4_1591068211397.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_biovec,https://github.com/ncbi-nlp/BioSentVec,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,300,Trained on PubMed corpora,,,,,,,
1,clinical/models,Embeddings Clinical,embeddings_clinical,en,2.4.0,2.4,28/01/2020,1.58024E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_clinical_en_2.4.0_2.4_1580237286004.zip,embeddings_clinical_en_2.4.0_2.4_1580237286004.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_clinical,https://www.nlm.nih.gov/databases/download/pubmed_medline.html,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,200,Trained on PubMed corpora,,,,,,,
1,clinical/models,Embeddings Healthcare,embeddings_healthcare,en,2.4.4,2.4,26/03/2020,1.58519E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_healthcare_en_2.4.4_2.4_1585188313964.zip,embeddings_healthcare_en_2.4.4_2.4_1585188313964.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_healthcare,https://www.nlm.nih.gov/databases/download/pubmed_medline.html,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,400,Trained on PubMed + ICD10 + UMLS + MIMIC III corpora,,,,,,,
1,clinical/models,Embeddings Healthcare 100 dims,embeddings_healthcare_100d,en,2.5.0,2.4,29/05/2020,1.59079E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_healthcare_100d_en_2.5.0_2.4_1590794626292.zip,embeddings_healthcare_100d_en_2.5.0_2.4_1590794626292.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_healthcare_100d,https://www.nlm.nih.gov/databases/download/pubmed_medline.html,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,100,Trained on PubMed + ICD10 + UMLS + MIMIC III corpora,,,,,,,
1,clinical/models,Embeddings Scielo 150 dims,embeddings_scielo_150d,es,2.5.0,2.4,26/05/2020,1.59047E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_scielo_150d_es_2.5.0_2.4_1590467082526.zip,embeddings_scielo_150d_es_2.5.0_2.4_1590467082526.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_scielo_150d,https://zenodo.org/record/3744326#.XtViinVKh_U,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,150,Trained on Scielo Articles,,,,,,,
1,clinical/models,Embeddings Scielo 300 dims,embeddings_scielo_300d,es,2.5.0,2.4,26/05/2020,1.59047E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_scielo_300d_es_2.5.0_2.4_1590467138742.zip,embeddings_scielo_300d_es_2.5.0_2.4_1590467138742.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_scielo_300d,https://zenodo.org/record/3744326#.XtViinVKh_U,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,300,Trained on Scielo Articles,,,,,,,
1,clinical/models,Embeddings Scielo 50 dims,embeddings_scielo_50d,es,2.5.0,2.4,26/05/2020,1.59047E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_scielo_50d_es_2.5.0_2.4_1590467114993.zip,embeddings_scielo_50d_es_2.5.0_2.4_1590467114993.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_scielo_50d,https://zenodo.org/record/3744326#.XtViinVKh_U,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,50,Trained on Scielo Articles,,,,,,,
1,clinical/models,Embeddings Scielowiki 150 dims,embeddings_scielowiki_150d,es,2.5.0,2.4,26/05/2020,1.59047E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_scielowiki_150d_es_2.5.0_2.4_1590467545910.zip,embeddings_scielowiki_150d_es_2.5.0_2.4_1590467545910.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_scielowiki_150d,https://zenodo.org/record/3744326#.XtViinVKh_U,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,150,Trained on Scielo Articles + Clinical Wikipedia Articles,,,,,,,
1,clinical/models,Embeddings Scielowiki 300 dims,embeddings_scielowiki_300d,es,2.5.0,2.4,26/05/2020,1.59047E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_scielowiki_300d_es_2.5.0_2.4_1590467643391.zip,embeddings_scielowiki_300d_es_2.5.0_2.4_1590467643391.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_scielowiki_300d,https://zenodo.org/record/3744326#.XtViinVKh_U,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,300,Trained on Scielo Articles + Clinical Wikipedia Articles,,,,,,,
1,clinical/models,Embeddings Scielowiki 50 dims,embeddings_scielowiki_50d,es,2.5.0,2.4,26/05/2020,1.59047E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_scielowiki_50d_es_2.5.0_2.4_1590467602230.zip,embeddings_scielowiki_50d_es_2.5.0_2.4_1590467602230.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_scielowiki_50d,https://zenodo.org/record/3744326#.XtViinVKh_U,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,50,Trained on Scielo Articles + Clinical Wikipedia Articles,,,,,,,
1,clinical/models,Embeddings Sciwiki 150 dims,embeddings_sciwiki_150d,es,2.5.0,2.4,27/05/2020,1.59061E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_sciwiki_150d_es_2.5.0_2.4_1590609340084.zip,embeddings_sciwiki_150d_es_2.5.0_2.4_1590609340084.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_sciwiki_150d,https://zenodo.org/record/3744326#.XtViinVKh_U,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,150,Trained on Clinical Wikipedia Articles,,,,,,,
1,clinical/models,Embeddings Sciwiki 300 dims,embeddings_sciwiki_300d,es,2.5.0,2.4,27/05/2020,1.59061E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_sciwiki_300d_es_2.5.0_2.4_1590609454054.zip,embeddings_sciwiki_300d_es_2.5.0_2.4_1590609454054.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_sciwiki_300d,https://zenodo.org/record/3744326#.XtViinVKh_U,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,300,Trained on Clinical Wikipedia Articles,,,,,,,
1,clinical/models,Embeddings Sciwiki 50 dims,embeddings_sciwiki_50d,es,2.5.0,2.4,27/05/2020,1.59061E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/embeddings_sciwiki_50d_es_2.5.0_2.4_1590609287349.zip,embeddings_sciwiki_50d_es_2.5.0_2.4_1590609287349.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on embeddings_sciwiki_50d,https://zenodo.org/record/3744326#.XtViinVKh_U,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,50,Trained on Clinical Wikipedia Articles,,,,,,,
1,clinical/models,Explain Clinical Doc Clinical Assertion Relation Posology,explain_clinical_doc_carp,en,2.5.5,2.4,19/08/2020,1.59784E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/explain_clinical_doc_carp_en_2.5.5_2.4_1597841630062.zip,explain_clinical_doc_carp_en_2.5.5_2.4_1597841630062.zip,,PipelineModel,,,John Snow Labs,"clinical,pipeline",Licensed ,Healthcare,,,"A pretrained pipeline with ner_clinical, assertion_dl, re_clinical and ner_posology. It will extract clinical and medication entities, assign assertion status and find relationships between clinical entities.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb,,,,
1,clinical/models,Explain Clinical Doc Clinical Relation Assertion,explain_clinical_doc_cra,en,2.5.5,2.4,19/08/2020,1.59785E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/explain_clinical_doc_cra_en_2.5.5_2.4_1597846145640.zip,explain_clinical_doc_cra_en_2.5.5_2.4_1597846145640.zip,,PipelineModel,,,John Snow Labs,"clinical,pipeline",Licensed ,Healthcare,,,"A pretrained pipeline with ner_clinical, assertion_dl, re_clinical. It will extract clinical entities, assign assertion status and find relationships between clinical entities.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb,,,,
1,clinical/models,Explain Clinical Doc Events Relation Assertion,explain_clinical_doc_era,en,2.5.5,2.4,19/08/2020,1.59785E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/explain_clinical_doc_era_en_2.5.5_2.4_1597845753750.zip,explain_clinical_doc_era_en_2.5.5_2.4_1597845753750.zip,,PipelineModel,,,John Snow Labs,"clinical,pipeline",Licensed ,Healthcare,,,"A pretrained pipeline with ner_clinical_events, assertion_dl and re_temporal_events_clinical. It will extract clinical entities, assign assertion status and find temporal relationships between clinical entities",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb,,,,
1,clinical/models,Ner DL Model Anatomy,ner_anatomy,en,2.4.2,2.4,21/04/2020,1.58751E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_anatomy_en_2.4.2_2.4_1587513307751.zip,ner_anatomy_en_2.4.2_2.4_1587513307751.zip,embeddings_clinical,NerDLModel,"Anatomical_system,Cell,Cellular_component,Developing_anatomical_structure,Immaterial_anatomical_entity,Organ,Organism_subdivision,Organism_substance,Pathological_formation,Tissue,tissue_structure",http://www.nactem.ac.uk/anatomy/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on the Anatomical Entity Mention (AnEM) corpus with `embeddings_clinical`,Pretrained named entity recognition deep learning model for anatomy terms.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_ANATOMY/,,
1,clinical/models,Ner DL Model Bionlp,ner_bionlp,en,2.4.0,2.4,28/01/2020,1.58024E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_bionlp_en_2.4.0_2.4_1580237286004.zip,ner_bionlp_en_2.4.0_2.4_1580237286004.zip,embeddings_clinical,NerDLModel,"Amino_acid,Anatomical_system,Cancer,Cell,Cellular_component,Developing_anatomical_structure,Gene_or_gene_product,Immaterial_anatomical_entity,Organ,Organism,Organism_subdivision,Organism_substance,Pathological_formation,Simple_chemical,Tissue,tissue_structure",http://2013.bionlp-st.org/tasks/cancer-genetics,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on Cancer Genetics (CG) task of the BioNLP Shared Task 2013 with `embeddings_clinical`,Pretrained named entity recognition deep learning model for biology and genetics terms.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_TUMOR/,,
1,clinical/models,Ner DL Model Cancer Genetics,ner_cancer_genetics,en,2.4.2,2.4,22/04/2020,1.58757E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_cancer_genetics_en_2.4.2_2.4_1587567870408.zip,ner_cancer_genetics_en_2.4.2_2.4_1587567870408.zip,embeddings_clinical,NerDLModel,"DNA,RNA,cell_line,cell_type,protein",http://2013.bionlp-st.org/tasks/cancer-genetics,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on Cancer Genetics (CG) task of the BioNLP Shared Task 2013 with `embeddings_clinical`,Pretrained named entity recognition deep learning model for biology and genetics terms.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,,,,
1,clinical/models,Ner DL Model Cellular,ner_cellular,en,2.4.2,2.4,21/04/2020,1.58751E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_cellular_en_2.4.2_2.4_1587513308751.zip,ner_cellular_en_2.4.2_2.4_1587513308751.zip,embeddings_clinical,NerDLModel,"DNA,RNA,cell_line,cell_type,protein",http://www.geniaproject.org/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on the JNLPBA corpus containing more than 2.404 publication abstracts with `embeddings_clinical`,Pretrained named entity recognition deep learning model for molecular biology related terms.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,,,
0,clinical/models,Ner DL Model Chemicals and Proteins,ner_chemprot_clinical,en,2.5.5,2.4,06/09/2020,1.59936E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_chemprot_clinical_en_2.5.5_2.4_1599360199717.zip,ner_chemprot_clinical_en_2.5.5_2.4_1599360199717.zip,embeddings_clinical,NerDLModel,"CHEMICAL,N,Y",FILLUP,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,FILLUP,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,,https://demo.johnsnowlabs.com/healthcare/NER_CHEMPROT_CLINICAL/,,
1,clinical/models,Ner DL Model Clinical,ner_clinical,en,2.4.0,2.4,28/01/2020,1.58024E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_clinical_en_2.4.0_2.4_1580237286004.zip,ner_clinical_en_2.4.0_2.4_1580237286004.zip,embeddings_clinical,NerDLModel,"Problem, Test, Treatment",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,"Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with `embeddings_clinical`",Pretrained named entity recognition deep learning model for clinical terms.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_DIAG_PROC/,,
1,clinical/models,Ner DL Model Clinical (Large),ner_clinical_large,en,2.5.0,2.4,21/05/2020,1.59002E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_clinical_large_en_2.5.0_2.4_1590021302624.zip,ner_clinical_large_en_2.5.0_2.4_1590021302624.zip,embeddings_clinical,NerDLModel,"Problem, Test, Treatment",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on i2b2 augmented data with `clinical_embeddings`,"Clinical NER (Large) is a Named Entity Recognition model that annotates text to find references to clinical events. The entities it annotates are Problem, Treatment, and Test. Clinical NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_EVENTS_CLINICAL.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_EVENTS_CLINICAL/,,
0,clinical/models,Ner CRF Model Clinical,ner_crf,en,2.4.0,2.4,28/01/2020,1.58024E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_crf_en_2.4.0_2.4_1580237286004.zip,ner_crf_en_2.4.0_2.4_1580237286004.zip,embeddings_clinical,NerCrfModel,"Problem, Test, Treatment",FILLUP,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on i2b2 augmented data with `clinical_embeddings`,"Clinical NER (Large) is a Named Entity Recognition model that annotates text to find references to clinical events. The entities it annotates are Problem, Treatment, and Test. Clinical NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline.",,,,,,
1,clinical/models,Deidentification NER (Enriched),ner_deid_enriched,en,2.4.2,2.4,08/07/2020,1.59417E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_deid_enriched_en_2.5.3_2.4_1594170530497.zip,ner_deid_enriched_en_2.5.3_2.4_1594170530497.zip,embeddings_clinical,NerDLModel,"Age, City, Country, Date, Doctor, Hospital, Idnum, Medicalrecord, Organization, Patient, Phone, Profession, State, Street, Username, Zip",https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on JSL enriched n2c2 2014: De-identification and Heart Disease Risk Factors Challenge datasets with `embeddings_clinical`,"Deidentification NER (Enriched) is a Named Entity Recognition model that annotates text to find protected health information that may need to be deidentified. The entities it annotates are Age, City, Country, Date, Doctor, Hospital, Idnum, Medicalrecord, Organization, Patient, Phone, Profession, State, Street, Username, and Zip. Clinical NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_DEMOGRAPHICS.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_DEMOGRAPHICS/,,
1,clinical/models,Deidentification NER (Large),ner_deid_large,en,2.4.2,2.4,22/07/2020,1.59543E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_deid_large_en_2.5.3_2.4_1595427435246.zip,ner_deid_large_en_2.5.3_2.4_1595427435246.zip,embeddings_clinical,NerDLModel,"Age, Contact, Date, Id, Location, Name, Profession",https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on plain n2c2 2014: De-identification and Heart Disease Risk Factors Challenge datasets with `embeddings_clinical`,"Deidentification NER (Large) is a Named Entity Recognition model that annotates text to find protected health information that may need to be deidentified. The entities it annotates are Age, Contact, Date, Id, Location, Name, and Profession. Clinical NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline.",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_DEMOGRAPHICS.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_DEMOGRAPHICS/,,
1,clinical/models,Ner DL Model Clinical,ner_diag_proc,es,2.5.3,2.4,08/07/2020,1.59417E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_diag_proc_es_2.5.3_2.4_1594168623415.zip,ner_diag_proc_es_2.5.3_2.4_1594168623415.zip,embeddings_scielowiki_300d,NerDLModel,"Diagnostico, Procedimiento",https://temu.bsc.es/codiesp/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on CodiEsp Challenge dataset trained with `embeddings_scielowiki_300d`,Pretrained named entity recognition deep learning model for diagnostics and procedures in spanish,,,,,,
1,clinical/models,Ner DL Model Diseases,ner_diseases,en,2.4.4,2.4,17/03/2020,1.58445E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_diseases_en_2.4.4_2.4_1584452534235.zip,ner_diseases_en_2.4.4_2.4_1584452534235.zip,embeddings_clinical,NerDLModel,Disease,,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on i2b2 with `embeddings_clinical`,Pretrained named entity recognition deep learning model for diseases.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_DIAG_PROC/,,
1,clinical/models,Ner DL Model Drugs,ner_drugs,en,2.4.4,2.4,17/03/2020,1.58445E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_drugs_en_2.4.4_2.4_1584452534235.zip,ner_drugs_en_2.4.4_2.4_1584452534235.zip,embeddings_clinical,NerDLModel,DrugChem (Drug and Chemicals),https://www.i2b2.org/NLP/Medication,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on i2b2_med7 + FDA with `embeddings_clinical`.,Pretrained named entity recognition deep learning model for Drugs.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,,,
1,clinical/models,Ner DL Model Events `embeddings_clinical`,ner_events_clinical,en,2.5.0,2.4,18/08/2020,1.59778E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_events_clinical_en_2.5.5_2.4_1597775531760.zip,ner_events_clinical_en_2.5.5_2.4_1597775531760.zip,embeddings_clinical,NerDLModel,"CLINICAL_DEPT,DATE,DURATION,EVIDENTIAL,FREQUENCY,OCCURRENCE,PROBLEM,TEST,TIME,TREATMENT",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on i2b2 events data with `clinical_embeddings`,Pretrained named entity recognition deep learning model for clinical events.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_EVENTS_CLINICAL/,,
0,clinical/models,Ner DL Model Events `embeddings_healthcare`,ner_events_healthcare,en,2.6.0,2.4,23/09/2020,1.60085E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_events_healthcare_en_2.6.0_2.4_1600849907632.zip,ner_events_healthcare_en_2.6.0_2.4_1600849907632.zip,embeddings_healthcare_100d,NerDLModel,"CLINICAL_DEPT,DATE,DURATION,EVIDENTIAL,FREQUENCY,OCCURRENCE,PROBLEM,TEST,TIME,TREATMENT",,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,"Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with `embeddings_healthcare_100d`",,,,,,,
1,clinical/models,w2v_cc_300d,ner_healthcare,de,2.5.5,2.4,06/09/2020,1.59943E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_healthcare_de_2.5.5_2.4_1599433028253.zip,ner_healthcare_de_2.5.5_2.4_1599433028253.zip,FILLUP,NerDLModel,"BIOLOGICAL_CHEMISTRY,BIOLOGICAL_PARAMETER,BODY_FLUID,BODY_PART,DEGREE,DIAGLAB_PROCEDURE,DOSING,LOCAL_SPECIFICATION,MEASUREMENT,MEDICAL_CONDITION,MEDICAL_DEVICE,MEDICAL_SPECIFICATION,MEDICATION,PERSON,PROCESS,STATE_OF_HEALTH,TIME_INFORMATION,TISSUE,TREATMENT",,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,"Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with `w2v_cc_300d`",,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/14.German_Healthcare_Models.ipynb,,https://demo.johnsnowlabs.com/healthcare/NER_HEALTHCARE_DE/,,
0,clinical/models,Ner DL Model Healthcare,ner_healthcare,en,2.4.4,2.4,23/09/2020,1.60085E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_healthcare_en_2.6.0_2.4_1600849764614.zip,ner_healthcare_en_2.6.0_2.4_1600849764614.zip,FILLUP,NerDLModel,"PROBLEM,TEST,TREATMENT",,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,"Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with `embeddings_healthcare_100d`",Pretrained named entity recognition deep learning model for healthcare.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,,,
1,clinical/models,Ner DL Model Phenotype / Gene,ner_human_phenotype_gene_clinical,en,2.5.5,2.4,27/08/2020,1.59856E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_human_phenotype_gene_clinical_en_2.5.5_2.4_1598558253840.zip,ner_human_phenotype_gene_clinical_en_2.5.5_2.4_1598558253840.zip,embeddings_clinical,NerDLModel,"GENE,HP",,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,,,,,,https://demo.johnsnowlabs.com/healthcare/NER_HUMAN_PHENOTYPE_GENE_CLINICAL/,,
1,clinical/models,Ner DL Model Healthcare,ner_human_phenotype_go_clinical,en,2.5.5,2.4,27/08/2020,1.59856E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_human_phenotype_go_clinical_en_2.5.5_2.4_1598558398770.zip,ner_human_phenotype_go_clinical_en_2.5.5_2.4_1598558398770.zip,embeddings_clinical,NerDLModel,"GO,HP",,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,,,,,,https://demo.johnsnowlabs.com/healthcare/NER_HUMAN_PHENOTYPE_GO_CLINICAL/,,
1,clinical/models,Ner DL Model,ner_jsl,en,2.4.2,2.4,21/04/2020,1.58751E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_jsl_en_2.4.2_2.4_1587513304751.zip,ner_jsl_en_2.4.2_2.4_1587513304751.zip,embeddings_clinical,NerDLModel,"Age,Allergenic_substance,Blood_Pressure,Causative_Agents_(Virus_and_Bacteria),Cause_of_death,Date_of_death,Diagnosis,Dosage,Drug_Name,Drug_incident_description,Frequency,Gender,Lab_Name,Lab_Result,Maybe,Modifier,Name,Negated,Negation,O2_Saturation,Procedure,Procedure_Findings,Procedure_Name,Procedure_incident_description,Pulse_Rate,Respiratory_Rate,Route,Section_Name,Substance_Name,Symptom_Name,Temperature,Weight",https://www.johnsnowlabs.com/data/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on data gathered and manually annotated by John Snow Labs,Pretrained named entity recognition deep learning model for clinical terminology.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_SIGN_SYMP/,,
1,clinical/models,Ner DL Model Enriched,ner_jsl_enriched,en,2.4.2,2.4,21/04/2020,1.58751E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_jsl_enriched_en_2.4.2_2.4_1587513303751.zip,ner_jsl_enriched_en_2.4.2_2.4_1587513303751.zip,embeddings_clinical,NerDLModel,"Age,Allergenic_substance,Blood_Pressure,Causative_Agents_(Virus_and_Bacteria),Diagnosis,Dosage,Drug_Name,Frequency,Gender,Lab_Name,Lab_Result,Maybe,Modifier,Name,Negation,O2_Saturation,Procedure,Procedure_Name,Pulse_Rate,Respiratory_Rate,Route,Section_Name,Substance_Name,Symptom_Name,Temperature,Weight",https://www.johnsnowlabs.com/data/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on data gathered and manually annotated by John Snow Labs,Pretrained named entity recognition deep learning model for clinical terminology.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,,,
1,clinical/models,Ner DL Model Clinical (Large),ner_large_clinical,en,2.5.0,2.4,21/05/2020,1.59002E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_large_clinical_en_2.5.0_2.4_1590021302624.zip,ner_large_clinical_en_2.5.0_2.4_1590021302624.zip,embeddings_clinical,NerDLModel,"PROBLEM,TEST,TREATMENT",https://www.johnsnowlabs.com/data/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on data gathered and manually annotated by John Snow Labs,,,,,,,
1,clinical/models,NER DL Model Legal,ner_legal,de,2.5.5,2.4,07/09/2020,1.59947E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_legal_de_2.5.5_2.4_1599471454959.zip,ner_legal_de_2.5.5_2.4_1599471454959.zip,embeddings_clinical,NerDLModel,"AN,EUN,GRT,GS,INN,LD,LDS,LIT,MRK,ORG,PER,RR,RS,ST,STR,UN,VO,VS,VT",,John Snow Labs,"clinical,ner",Licensed ,Legal,,,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/15.German_Legal_Model.ipynb,,https://demo.johnsnowlabs.com/healthcare/NER_LEGAL_DE/,,
0,clinical/models,,ner_medmentions_coarse,en,2.5.0,2.4,23/05/2020,1.59027E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_medmentions_coarse_en_2.5.0_2.4_1590265407598.zip,ner_medmentions_coarse_en_2.5.0_2.4_1590265407598.zip,embeddings_clinical,NerDLModel,"Amino_Acid,_Peptide,_or_Protein,Anatomical_Structure,Biologic_Function,Biomedical_or_Dental_Material,Body_Location_or_Region,Body_Part,_Organ,_or_Organ_Component,Body_Substance,Body_System,Cell,Cell_Component,Chemical,Clinical_Attribute,Daily_or_Recreational_Activity,Diagnostic_Procedure,Disease_or_Syndrome,Eukaryote,Food,Fungus,Gene_or_Genome,Genetic_Function,Geographic_Area,Group,Health_Care_Activity,Indicator,_Reagent,_or_Diagnostic_Aid,Injury_or_Poisoning,Laboratory_Procedure,Mammal,Manufactured_Object,Medical_Device,Mental_Process,Mental_or_Behavioral_Dysfunction,Molecular_Biology_Research_Technique,Molecular_Function,Neoplastic_Process,Nucleic_Acid,_Nucleoside,_or_Nucleotide,Nucleotide_Sequence,Organic_Chemical,Organism_Attribute,Organization,Pathologic_Function,Pharmacologic_Substance,Plant,Population_Group,Professional_or_Occupational_Group,Prokaryote,Qualitative_Concept,Quantitative_Concept,Research_Activity,Sign_or_Symptom,Spatial_Concept,Substance,Therapeutic_or_Preventive_Procedure,Tissue,Virus",,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on MedMentions dataset,,,,,,,
1,clinical/models,Neoplasms NER,ner_neoplasms,es,2.5.3,2.4,08/07/2020,1.59417E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_neoplasms_es_2.5.3_2.4_1594168624415.zip,ner_neoplasms_es_2.5.3_2.4_1594168624415.zip,embeddings_scielowiki_300d,NerDLModel,MORFOLOGIA_NEOPLASIA,https://temu.bsc.es/cantemist/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Named Entity Recognition model for Neoplasic Morphology,"Neoplasms NER is a Named Entity Recognition model that annotates text to find references to tumors. The only entity it annotates is MalignantNeoplasm. Neoplasms NER is trained with the 'embeddings_scielowiki_300d' word embeddings model, so be sure to use the same embeddings in the pipeline.",,,0,,,
1,clinical/models,Ner DL Model Posology,ner_posology,en,2.4.2,2.4,17/03/2020,1.58445E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_posology_en_2.4.4_2.4_1584452534235.zip,ner_posology_en_2.4.4_2.4_1584452534235.zip,embeddings_clinical,NerDLModel,"DOSAGE,DRUG,DURATION,FORM,FREQUENCY,ROUTE,STRENGTH",https://open.fda.gov/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on the 2018 i2b2 dataset and FDA Drug datasets with `embeddings_clinical`.,"Pretrained named entity recognition deep learning model for posology, this NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_POSOLOGY/,,
0,clinical/models,,ner_posology_healthcare,en,2.6.0,2.4,23/09/2020,1.60085E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_posology_healthcare_en_2.6.0_2.4_1600849852424.zip,ner_posology_healthcare_en_2.6.0_2.4_1600849852424.zip,embeddings_healthcare,NerDLModel,"Dosage,Drug,Duration,Form,Frequency,Route,Strength",https://open.fda.gov/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on the 2018 i2b2 dataset and FDA Drug datasets with `embeddings_healthcare_100d`.,"Pretrained named entity recognition deep learning model for posology, this NER is trained with the 'embeddings_healthcare' word embeddings model, so be sure to use the same embeddings in the pipeline",,,,,,
1,clinical/models,Ner DL Model Posology Large,ner_posology_large,en,2.4.2,2.4,21/04/2020,1.58751E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_posology_large_en_2.4.2_2.4_1587513302751.zip,ner_posology_large_en_2.4.2_2.4_1587513302751.zip,embeddings_clinical,NerDLModel,"DOSAGE,DRUG,DURATION,FORM,FREQUENCY,ROUTE,STRENGTH",https://open.fda.gov/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on the 2018 i2b2 dataset and FDA Drug datasets with `embeddings_clinical`.,"Pretrained named entity recognition deep learning model for posology, this NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,,,
1,clinical/models,Ner DL Model Posology Small,ner_posology_small,en,2.4.2,2.4,21/04/2020,1.58751E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_posology_small_en_2.4.2_2.4_1587513301751.zip,ner_posology_small_en_2.4.2_2.4_1587513301751.zip,embeddings_clinical,NerDLModel,"DOSAGE,DRUG,DURATION,FORM,FREQUENCY,ROUTE,STRENGTH",https://www.i2b2.org/NLP/Medication,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on the 2018 i2b2 dataset (no FDA) with `embeddings_clinical`.,"Pretrained named entity recognition deep learning model for posology, this NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline",,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,,,
1,clinical/models,Ner DL Model Risk Factors,ner_risk_factors,en,2.4.2,2.4,21/04/2020,1.58751E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_risk_factors_en_2.4.2_2.4_1587513300751.zip,ner_risk_factors_en_2.4.2_2.4_1587513300751.zip,embeddings_clinical,NerDLModel,"CAD,DIABETES,FAMILY_HIST,HYPERLIPIDEMIA,HYPERTENSION,MEDICATION,OBESE,PHI,SMOKER",https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,Trained on plain n2c2 2014: De-identification and Heart Disease Risk Factors Challenge datasets with `embeddings_clinical`,Pretrained named entity recognition deep learning model for Heart Disease Risk Factors and Personal Health Information.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb,0,https://demo.johnsnowlabs.com/healthcare/NER_RISK_FACTORS/,,
1,clinical/models,POS Tagger Clinical,pos_clinical,en,2.0.2,2.4,30/04/2019,1.55666E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/pos_clinical_en_2.0.2_2.4_1556660550177.zip,pos_clinical_en_2.0.2_2.4_1556660550177.zip,embeddings_clinical,PerceptronModel,,,John Snow Labs,"clinical,pos",Licensed ,Healthcare,,Trained with MedPost dataset,,,,,,,
0,clinical/models,,ppl_posology_rxnorm,en,2.5.3,2.4,05/08/2020,1.59664E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ppl_posology_rxnorm_en_2.5.3_2.4_1596638834463.zip,ppl_posology_rxnorm_en_2.5.3_2.4_1596638834463.zip,,PipelineModel,,FILLUP,John Snow Labs,"clinical,pipeline",Licensed ,Healthcare,,FILLUP,,,,,,,
0,clinical/models,,re_chemprot_clinical,en,2.5.5,2.4,04/09/2020,1.59925E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/re_chemprot_clinical_en_2.5.5_2.4_1599250496881.zip,re_chemprot_clinical_en_2.5.5_2.4_1599250496881.zip,embeddings_clinical,RelationExtractionModel,,,John Snow Labs,"clinical,relation_extraction",Licensed ,Healthcare,,Trained on data gathered and manually annotated by John Snow Labs,,,,,,,
1,clinical/models,Relation Extraction Model Clinical,re_clinical,en,2.5.5,2.4,24/09/2020,1.60099E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/re_clinical_en_2.5.5_2.4_1600987935304.zip,re_clinical_en_2.5.5_2.4_1600987935304.zip,embeddings_clinical,RelationExtractionModel,"TrIP (improved), TrWP (worsened), TrCP (caused problem), TrAP (administered), TrNAP (avoided), TeRP (revealed problem), TeCP (investigate problem), PIP (problems related)",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,relation_extraction",Licensed ,Healthcare,,Trained on data gathered and manually annotated by John Snow Labs,Models the set of clinical relations defined in the 2010 i2b2 relation challenge.,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb,0,https://demo.johnsnowlabs.com/healthcare/RE_CLINICAL/,,
1,clinical/models,Relation Extraction Model Clinical,re_drug_drug_interaction_clinical,en,2.5.5,2.4,03/09/2020,1.59916E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/re_drug_drug_interaction_clinical_en_2.5.5_2.4_1599156924424.zip,re_drug_drug_interaction_clinical_en_2.5.5_2.4_1599156924424.zip,embeddings_clinical,RelationExtractionModel,,,John Snow Labs,"clinical,relation_extraction",Licensed ,Healthcare,,Trained on data gathered and manually annotated by John Snow Labs,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb,0,,,
1,clinical/models,Relation Extraction Model Clinical,re_human_phenotype_gene_clinical,en,2.5.5,2.4,27/08/2020,1.59856E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/re_human_phenotype_gene_clinical_en_2.5.5_2.4_1598560152543.zip,re_human_phenotype_gene_clinical_en_2.5.5_2.4_1598560152543.zip,embeddings_clinical,RelationExtractionModel,,,John Snow Labs,"clinical,relation_extraction",Licensed ,Healthcare,,Trained on data gathered and manually annotated by John Snow Labs,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb,0,,,
1,clinical/models,Relation Extraction Model Clinical,re_temporal_events_clinical,en,2.5.5,2.4,18/08/2020,1.59777E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/re_temporal_events_clinical_en_2.5.5_2.4_1597774124917.zip,re_temporal_events_clinical_en_2.5.5_2.4_1597774124917.zip,embeddings_clinical,RelationExtractionModel,"TrIP (improved), TrWP (worsened), TrCP (caused problem), TrAP (administered), TrNAP (avoided), TeRP (revealed problem), TeCP (investigate problem), PIP (problems related)",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,relation_extraction",Licensed ,Healthcare,,Trained on data gathered and manually annotated by John Snow Labs,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb,0,https://demo.johnsnowlabs.com/healthcare/RE_CLINICAL_EVENTS/,,
1,clinical/models,Relation Extraction Model Clinical,re_temporal_events_enriched_clinical,en,2.5.5,2.4,18/08/2020,1.59778E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/re_temporal_events_enriched_clinical_en_2.5.5_2.4_1597775105767.zip,re_temporal_events_enriched_clinical_en_2.5.5_2.4_1597775105767.zip,embeddings_clinical,RelationExtractionModel,"Extracts: Temporal relations (BEFORE, AFTER, SIMULTANEOUS, BEGUN_BY, ENDED_BY, DURING, BEFORE_OVERLAP) between clinical events (`ner_events_clinical`)",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,relation_extraction",Licensed ,Healthcare,,Trained on data gathered and manually annotated by John Snow Labs,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb,0,,,
0,clinical/models,,recognize_entities_posology,en,2.5.5,2.4,19/08/2020,1.59785E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/recognize_entities_posology_en_2.5.5_2.4_1597846280279.zip,recognize_entities_posology_en_2.5.5_2.4_1597846280279.zip,,PipelineModel,FILLUP,FILLUP,John Snow Labs,"clinical,pipeline",Licensed ,Healthcare,,FILLUP,,,,,,,
0,clinical/models,Deep Sentence Detector,sentence_detector_dl,en,2.6.0,2.4,13/09/2020,1.6E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/sentence_detector_dl_en_2.6.0_2.4_1600002888450.zip,sentence_detector_dl_en_2.6.0_2.4_1600002888450.zip,,DeepSentenceDetector,,https://github.com/dbmdz/deep-eos,John Snow Labs,"clinical,sentence_detector",Licensed ,Healthcare,,Please visit the [repo](https://github.com/dbmdz/deep-eos) for more information,,,,,,,
0,clinical/models,Deep Sentence Detector Multilingual,sentence_detector_dl,xx,2.6.0,2.4,14/09/2020,1.60009E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/sentence_detector_dl_xx_2.6.0_2.4_1600092755641.zip,sentence_detector_dl_xx_2.6.0_2.4_1600092755641.zip,,DeepSentenceDetector,,https://github.com/dbmdz/deep-eos,John Snow Labs,"clinical,sentence_detector",Licensed ,Healthcare,,Please visit the [repo](https://github.com/dbmdz/deep-eos) for more information,,,,,,,
0,clinical/models,Deep Sentence Detector Healthcare,sentence_detector_dl_healthcare,en,2.6.0,2.4,13/09/2020,1.6E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/sentence_detector_dl_healthcare_en_2.6.0_2.4_1600001082565.zip,sentence_detector_dl_healthcare_en_2.6.0_2.4_1600001082565.zip,,DeepSentenceDetector,,https://github.com/dbmdz/deep-eos,John Snow Labs,"clinical,sentence_detector",Licensed ,Healthcare,,Please visit the [repo](https://github.com/dbmdz/deep-eos) for more information,,,,,,,
1,clinical/models,Contextual Spellchecker Clinical,spellcheck_clinical,en,2.4.2,2.4,17/04/2020,1.58715E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/spellcheck_clinical_en_2.4.2_2.4_1587146727460.zip,spellcheck_clinical_en_2.4.2_2.4_1587146727460.zip,embeddings_clinical,ContextSpellCheckerModel,,,John Snow Labs,"clinical,spell_checker",Licensed ,Healthcare,,Trained with PubMed and i2b2 datasets,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/6.Clinical_Context_Spell_Checker.ipynb,,https://demo.johnsnowlabs.com/healthcare/CONTEXTUAL_SPELL_CHECKER/,,
0,clinical/models,,textmatch_cpt_token,en,2.4.0,2.4,21/04/2020,1.5875E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/textmatch_cpt_token_en_2.4.5_2.4_1587495106014.zip,textmatch_cpt_token_en_2.4.5_2.4_1587495106014.zip,,TextMatcherModel,,,John Snow Labs,"clinical,",Licensed ,Healthcare,,Trained on NER Synonym Augmented Procedural Terminology bigram tokens combined up to a window of one,,,,,,,
0,clinical/models,,textmatch_icdo_ner,en,2.4.0,2.4,21/04/2020,1.5875E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/textmatch_icdo_ner_en_2.4.5_2.4_1587495006987.zip,textmatch_icdo_ner_en_2.4.5_2.4_1587495006987.zip,,TextMatcherModel,,,John Snow Labs,"clinical,",Licensed ,Healthcare,,Trained on NER Synonym Augmented ICD Histology Behaviour bigram tokens up to a window of four,,,,,,,
1,clinical/models,Fastext Word Embeddings in German,w2v_cc_300d,de,2.5.5,2.4,06/09/2020,1.59943E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/w2v_cc_300d_de_2.5.5_2.4_1599428063692.zip,w2v_cc_300d_de_2.5.5_2.4_1599428063692.zip,,WordEmbeddingsModel,Word2Vec feature vectors based on w2v_cc_300d,https://fasttext.cc/docs/en/crawl-vectors.html,John Snow Labs,"clinical,embeddings",Licensed ,Healthcare,300,FastText common crawl word embeddings for Germany,,,https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/14.German_Healthcare_Models.ipynb,,,,
1,clinical/models,Classifierdl Biobert-pubmed Adverse Events,classifierdl_ade_biobert,en,2.6.2,2.4,06/10/2020,1.60149E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/classifierdl_ade_biobert_en_2.6.0_2.4_1601486646977.zip,classifierdl_ade_biobert_en_2.6.0_2.4_1601486646977.zip,biobert_pubmed_base_cased,ClassifierDLModel,"True, False",FILLUP,John Snow Labs,"clinical,classifier",Licensed ,Healthcare,,"Trained on DRUG-AE, 2018 i2b2, CADEC, and twitter ADE dataset",Classify if a user review/tweet contains any adverse drug reaction,,,,,,
1,clinical/models,Classifierdl Biobert-conversational Adverse Events,classifierdl_ade_conversational_biobert,en,2.6.2,2.4,06/10/2020,1.60174E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/classifierdl_ade_conversational_biobert_en_2.6.0_2.4_1601739878549.zip,classifierdl_ade_conversational_biobert_en_2.6.0_2.4_1601739878549.zip,biobert_pubmed_base_cased,ClassifierDLModel,"True, False",FILLUP,John Snow Labs,"clinical,classifier",Licensed ,Healthcare,,"Trained on DRUG-AE, 2018 i2b2, CADEC, and twitter ADE dataset",Classify if a user review/tweet contains any adverse drug reaction,,,,,,
1,clinical/models,Classifierdl Biobert-clinical Adverse Events,classifierdl_ade_clinicalbert,en,2.6.2,2.4,06/10/2020,1.60159E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/classifierdl_ade_clinicalbert_en_2.6.0_2.4_1601594738356.zip,classifierdl_ade_clinicalbert_en_2.6.0_2.4_1601594738356.zip,biobert_clinical_base_cased,ClassifierDLModel,"True, False",FILLUP,John Snow Labs,"clinical,classifier",Licensed ,Healthcare,,"Trained on DRUG-AE, 2018 i2b2, CADEC, and twitter ADE dataset",Classify if a user review/tweet contains any adverse drug reaction,,,,,,
1,clinical/models,NER Adverse Drug Events,ner_ade_clinical,en,2.6.2,2.4,06/10/2020,1.60137E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_ade_clinical_en_2.6.0_2.4_1601368505818.zip,ner_ade_clinical_en_2.6.0_2.4_1601368505818.zip,embeddings_clinical,NerDLModel,"ADE, DRUG",FILLUP,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,"Trained on DRUG-AE, 2018 i2b2, CADEC, and twitter ADE dataset",Extract adverse drug reaction events and drug entites from text,,,,,,
1,clinical/models,NER Adverse Drug Events,ner_ade_healthcare,en,2.6.2,2.4,06/10/2020,1.60145E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_ade_healthcare_en_2.6.0_2.4_1601450601043.zip,ner_ade_healthcare_en_2.6.0_2.4_1601450601043.zip,embeddings_healthcare_100d,NerDLModel,"ADE, DRUG",FILLUP,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,"Trained on DRUG-AE, 2018 i2b2, CADEC, and twitter ADE dataset",Extract adverse drug reaction events and drug entites from text,,,,,,
1,clinical/models,NER Adverse Drug Events,ner_ade_biobert,en,2.6.2,2.4,06/10/2020,1.60159E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_ade_biobert_en_2.6.0_2.4_1601594787264.zip,ner_ade_biobert_en_2.6.0_2.4_1601594787264.zip,biobert_pubmed_base_cased,NerDLModel,"ADE, DRUG",FILLUP,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,"Trained on DRUG-AE, 2018 i2b2, CADEC, and twitter ADE dataset",Extract adverse drug reaction events and drug entites from text,,,,,,
1,clinical/models,NER Adverse Drug Events,ner_ade_clinicalbert,en,2.6.2,2.4,06/10/2020,1.60159E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_ade_clinicalbert_en_2.6.0_2.4_1601594831715.zip,ner_ade_clinicalbert_en_2.6.0_2.4_1601594831715.zip,biobert_clinical_base_cased,NerDLModel,"ADE, DRUG",FILLUP,John Snow Labs,"clinical,ner",Licensed ,Healthcare,,"Trained on DRUG-AE, 2018 i2b2, CADEC, and twitter ADE dataset",Extract adverse drug reaction events and drug entites from text,,,,,,
1,clinical/models,Assertion with Biobert Embeddings,assertion_dl_biobert,en,2.6.2,2.4,06/10/2020,1.60193E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertiondl_biobert_en_2.6.1_2.4_1601928965625.zip,assertiondl_biobert_en_2.6.1_2.4_1601928965625.zip,biobert_pubmed_base_cased,AssertionDLModel,"hypothetical, present, absent, possible, conditional, associated_with_someone_else",https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/,John Snow Labs,"clinical,assertion",Licensed ,Healthcare,,"Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with `biobert_pubmed_base_cased`",Deep learning named entity recognition model for assertions ,,https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.Clinical_Assertion_Model.ipynb,0,,,
1,clinical/models,ADE Pipeline,explain_clinical_doc_ade,en,2.6.2,2.4,06/10/2020,1.60146E+12,s3,https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/explain_clinical_doc_ade_en_2.6.0_2.4_1601455031009.zip,explain_clinical_doc_ade_en_2.6.0_2.4_1601455031009.zip,,PipelineModel,"ADE, DRUG",FILLUP,John Snow Labs,"clinical,pipeline",Licensed ,Healthcare,,,"A pipeline for Adverse Drug Events (ADE) with ner_ade_biobert, assertiondl_biobert and classifierdl_ade_conversational_biobert. It will extract ADE and DRUG clinical entities, assigen assertion status to ADE entities, and then assign ADE status to a text(True means ADE, False means not related to ADE).Extract adverse drug reaction events and drug entites from text","ner_ade_biobert, assertiondl_biobert, classifierdl_ade_conversational_biobert",,,,,