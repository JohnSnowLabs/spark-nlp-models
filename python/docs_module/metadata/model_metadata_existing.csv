title,labels,model_author,model_name,latest_date,tags,description,code_samples,model_dataset,included_models,model_info,Dimension,Edition,Language,License,Compatibility,Input Labels,Case sensitive,Model Name,Output Labels,Type
WikiNER 6B 300,,John Snow Labs,wikiner_6B_300,2020-02-03,"[ner, fr, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_FR){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_FR.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_fr_2.4.0_2.4_1579717534654.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_300"", ""fr"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_300"", ""fr"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|fr|

|Case sensitive:|false|



{:.h2_title}
",,Official,fr,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,wikiner_6B_300,ner,ner
Deidentification NER (Enriched),,John Snow Labs,ner_deid_enriched,2020-03-04,"[ner, en, deidentify, licensed]","Deidentification NER (Enriched) is a Named Entity Recognition model that annotates text to find protected health information that may need to be deidentified. The entities it annotates are Age, City, Country, Date, Doctor, Hospital, Idnum, Medicalrecord, Organization, Patient, Phone, Profession, State, Street, Username, and Zip. Clinical NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/healthcare/NER_DEMOGRAPHICS){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_DEMOGRAPHICS.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_deid_enriched_en_2.4.2_2.4_1587513306751.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""ner_deid_enriched"", ""en"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""ner_deid_enriched"", ""en"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/](https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/),,"

{:.table-model}

|---|---|

|Model Name:|ner_deid_enriched|

|Type:|ner|

|Compatibility:| Spark NLP for Healthcare 2.4.2+ |

|License:|Licensed|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|en|

|Case sensitive:|false|





{:.h2_title}
",,Official,en,Licensed, Spark NLP for Healthcare 2.4.2+ ,"sentence, token, embeddings",false,ner_deid_enriched,ner,ner
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2019-07-13,"[open_source, ner, fr]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_FR){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_FR.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_fr_2.1.0_2.4_1563035043013.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""fr"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""fr"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.1.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|fr|

|Case sensitive:|false|



{:.h2_title}
",,Official,fr,Open Source, Spark NLP 2.1.0,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
Ner DL Model,"Age, Diagnosis, Dosage, Drug_name, Frequency, Gender, Lab_name, Lab_result, Symptom_name



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_jsl_en_2.4.2_2.4_1587513304751.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_jsl_en,2020-04-22,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for clinical terminology. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_jsl"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_jsl"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)

```



</div>



{:.model-param}
","Trained on data gathered and manually annotated by John Snow Labs.

https://www.johnsnowlabs.com/data/





{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_jsl_en_2.4.2_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.2|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.2,"[sentence,token, embeddings]",false,ner_jsl_en_2.4.2_2.4,[ner],ner
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2019-07-13,"[open_source, ner, de]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_DE){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_DE.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_de_2.1.0_2.4_1563035544700.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""de"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""de"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://de.wikipedia.org](https://de.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.1.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|de|

|Case sensitive:|false|



{:.h2_title}
",,Official,de,Open Source, Spark NLP 2.1.0,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
Clinical NER (Large),,John Snow Labs,ner_clinical_large,2020-05-10,"[ner, en, licensed]","Clinical NER (Large) is a Named Entity Recognition model that annotates text to find references to clinical events. The entities it annotates are Problem, Treatment, and Test. Clinical NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/healthcare/NER_EVENTS_CLINICAL){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_EVENTS_CLINICAL.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_large_clinical_en_2.5.0_2.4_1590021302624.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""ner_clinical_large"", ""en"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""ner_clinical_large"", ""en"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/](https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/),,"

{:.table-model}

|---|---|

|Model Name:|ner_clinical_large|

|Type:|ner|

|Compatibility:| Spark NLP for Healthcare 2.5.0+|

|License:|Licensed|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|en|

|Case sensitive:|false|





{:.h2_title}
",,Official,en,Licensed, Spark NLP for Healthcare 2.5.0+,"sentence, token, embeddings",false,ner_clinical_large,ner,ner
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2020-03-16,"[ner, ru, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_RU){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_RU.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_ru_2.4.4_2.4_1584014001695.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""ru"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""ru"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://ru.wikipedia.org](https://ru.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.4|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|ru|

|Case sensitive:|false|





{:.h2_title}
",,Official,ru,Open Source, Spark NLP 2.4.4,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
NerDLModel Bionlp," Amino_acid, Anatomical_system, Cancer, Cell, Cellular_component, Developing_anatomical_Structure, Gene_or_gene_product, Immaterial_anatomical_entity, Multi-tissue_structure, Organ, Organism, Organism_subdivision, Simple_chemical, Tissue



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_bionlp_en_2.4.0_2.4_1580237286004.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_bionlp_en,2020-01-30,"[licensed, ner, en]","

Pretrained named entity recognition deep learning model for biology and genetics terms. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_bionlp"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_bionlp"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)





```



</div>



{:.model-param}
","Trained on Cancer Genetics (CG) task of the BioNLP Shared Task 2013 with 'embeddings_clinical'.

http://2013.bionlp-st.org/tasks/cancer-genetics



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_bionlp_en_2.4.0_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.0|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.0,"[sentence,token, embeddings]",false,ner_bionlp_en_2.4.0_2.4,[ner],ner
ALBERT Base Uncase,,John Snow Labs,albert_base_uncased,2020-04-28,"[embeddings, en, open_source]","ALBERT is ""A Lite"" version of BERT, a popular unsupervised language representation learning algorithm. ALBERT uses parameter-reduction techniques that allow for large-scale configurations, overcome previous memory limitations, and achieve better behavior with respect to model degradation. The details are described in the paper ""[ALBERT: A Lite BERT for Self-supervised Learning of Language Representations.](https://arxiv.org/abs/1909.11942)""



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/albert_base_uncased_en_2.5.0_2.4_1588073363475.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = AlbertEmbeddings.pretrained(""albert_base_uncased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = AlbertEmbeddings.pretrained(""albert_base_uncased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/albert_base/3](https://tfhub.dev/google/albert_base/3)
",,"

{:.table-model}

|---|---|

|Model Name:|albert_base_uncased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|768|

|Case sensitive:|false|





{:.h2_title}
",768,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",false,albert_base_uncased,[word_embeddings],embeddings
WikiNER 6B 100,,John Snow Labs,wikiner_6B_100,2020-05-10,"[ner, pt, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_PT){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_pt_2.5.0_2.4_1588495233192.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_100"", ""pt"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_100"", ""pt"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://pt.wikipedia.org](https://pt.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_100|

|Type:|ner|

|Compatibility:| Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|pt|

|Case sensitive:|false|



{:.h2_title}
",,Official,pt,Open Source, Spark NLP 2.5.0,"sentence, token, embeddings",false,wikiner_6B_100,ner,ner
NerDLModel Posology Small,"Dosage, Drug, Duration, Form, Frequency, Route, Strength



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazon.com/auxdata.johnsnowlabs.com/clinical/models/ner_posology_small_en_2.4.2_2.4_1587513301751.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_posology_small_en,2020-04-22,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for posology. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}







```python



clinical_ner = NerDLModel.pretrained(""ner_posology_small"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)

ner_posology_small

results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_posology_small"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)





```



</div>



{:.model-param}
","Trained on the 2018 i2b2 dataset with 'embeddings_clinical'.

https://www.i2b2.org/NLP/Medication



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_posology_small_en_2.4.2_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.2|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.2,"[sentence,token, embeddings]",false,ner_posology_small_en_2.4.2_2.4,[ner],ner
GloVe 6B 300,,John Snow Labs,glove_6B_300,2020-02-03,"[embeddings, en, open_source]","GloVe (Global Vectors) is a model for distributed word representation. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity. It outperformed many common Word2vec models on the word analogy task. One benefit of GloVe is that it is the result of directly modeling relationships, instead of getting them as a side effect of training a language model.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_EN){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_EN.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/glove_6B_300_xx_2.4.0_2.4_1579698630432.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = WordEmbeddingsModel.pretrained(""glove_6B_300"", ""en"") \

        .setInputCols([""document"", ""token""]) \

        .setOutputCol(""embeddings"")

```



```scala



val embeddings = WordEmbeddingsModel.pretrained(""glove_6B_300"", ""en"")

        .setInputCols(Array(""document"", ""token""))

        .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
",The model is imported from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/),,"

{:.table-model}

|---|---|

|Model Name:|glove_6B_300|

|Type:|embeddings|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence. token|

|Output Labels:|embeddings|

|Language:|en|

|Dimension:|300|

|Case sensitive:|false|





{:.h2_title}
",300,Official,en,Open Source, Spark NLP 2.4.0,sentence. token,false,glove_6B_300,embeddings,embeddings
Explain Document DL,,John Snow Labs,explain_document_dl,,"[pipeline, en, open_source]","The *explain_document_dl* is a pretrained pipeline that we can use to process text with a simple pipeline that performs basic processing steps.



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/explain-document-ml/explain_document_ml.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/explain_document_dl_en_2.4.3_2.4_1584626657780.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```scala



code example

```



```python



pipeline = PretrainedPipeline('explain_document_dl', lang =' en').annotate(' Hello world!')

```



</div>



{:.model-param}
",,"The explain_document_ml has one Transformer and six annotators: 

- Documenssembler - A Transformer that creates a column that contains documents. 

- Sentence Segmenter - An annotator that produces the sentences of the document. 

- Tokenizer - An annotator that produces the tokens of the sentences. 

- SpellChecker - An annotator that produces the spelling-corrected tokens. 

- Stemmer - An annotator that produces the stems of the tokens. 

- Lemmatizer - An annotator that produces the lemmas of the tokens. 

- POS Tagger - An annotator that produces the parts of speech of the associated tokens.


","

{:.table-model}

|---|---|

|Model Name:|explain_document_dl|

|Type:|pipeline|

|Compatibility:|Spark NLP 2.5.5|

|License:|Open Source|

|Edition:|Community|

|Language:|[en]|




",,Community,[en],Open Source,Spark NLP 2.5.5,,,explain_document_dl,,pipeline
BERT Large Cased,,John Snow Labs,bert_large_cased,2020-01-02,"[open_source, embeddings, en]","This model contains a deep bidirectional transformer trained on Wikipedia and the BookCorpus. The details are described in the paper ""[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_large_cased_en_2.4.0_2.4_1580580251298.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = BertEmbeddings.pretrained(""bert_large_cased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = BertEmbeddings.pretrained(""bert_large_cased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/bert_cased_L-24_H-1024_A-16/1](https://tfhub.dev/google/bert_cased_L-24_H-1024_A-16/1)
",,"

{:.table-model}

|---|---|

|Model Name:|bert_large_cased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|1024|

|Case sensitive:|true|





{:.h2_title}
",1024,Official,[en],Open Source,Spark NLP 2.4.0,"[sentence, token]",true,bert_large_cased,[word_embeddings],embeddings
Universal Sentence Encoder,,John Snow Labs,tfhub_use,2020-04-17,"[embeddings, en, open_source]","The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.



The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length English text and the output is a 512 dimensional vector. We apply this model to the STS benchmark for semantic similarity, and the results can be seen in the example notebook made available. The universal-sentence-encoder model is trained with a deep averaging network (DAN) encoder.



The details are described in the paper ""[Universal Sentence Encoder](https://arxiv.org/abs/1803.11175)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/tfhub_use_en_2.4.0_2.4_1587136330099.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = UniversalSentenceEncoder.pretrained(""tfhub_use"", ""en"") \

      .setInputCols(""document"") \

      .setOutputCol(""sentence_embeddings"")

```



```scala



val embeddings = UniversalSentenceEncoder.pretrained(""tfhub_use"", ""en"")

      .setInputCols(""document"")

      .setOutputCol(""sentence_embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/universal-sentence-encoder/2](https://tfhub.dev/google/universal-sentence-encoder/2)
",,"

{:.table-model}

|---|---|

|Model Name:|tfhub_use|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence]|

|Output Labels:|[sentence_embeddings]|

|Language:|[en]|

|Dimension:|512|

|Case sensitive:|true|





{:.h2_title}
",512,Official,[en],Open Source,Spark NLP 2.4.0,[sentence],true,tfhub_use,[sentence_embeddings],embeddings
BioBERT Clinical,,John Snow Labs,biobert_clinical_base_cased,2020-07-20,"[embeddings, en, open_source]","This model contains a pre-trained weights of ClinicalBERT for generic clinical text. This domain-specific model has performance improvements on 3/5 clinical NLP tasks andd establishing a new state-of-the-art on the MedNLI dataset. The details are described in the paper ""[Publicly Available Clinical BERT Embeddings](https://www.aclweb.org/anthology/W19-1909/)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_clinical_base_cased_en_2.5.0_2.4_1590489819943.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = BertEmbeddings.pretrained(""biobert_clinical_base_cased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = BertEmbeddings.pretrained(""biobert_clinical_base_cased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://github.com/EmilyAlsentzer/clinicalBERT](https://github.com/EmilyAlsentzer/clinicalBERT)
",,"

{:.table-model}

|---|---|

|Model Name:|biobert_clinical_base_cased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|768|

|Case sensitive:|true|





{:.h2_title}
",768,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",true,biobert_clinical_base_cased,[word_embeddings],embeddings
Explain Clinical Doc ERA,,John Snow Labs,explain_clinical_doc_era_en,2020-08-19,"[pipeline, en, licensed]","A pretrained pipeline with ner_clinical_events, assertion_dl and re_temporal_events_clinical. It will extract clinical entities, assign assertion status and find temporal relationships between clinical entities



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/explain_clinical_doc_era_en_2.5.5_2.4_1597841630062.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python





pipeline = PretrainedPipeline('explain_clinical_doc_era', 'en', 'clinical/models')



annotations = pipeline.annotate(text)



annotations.keys()



```

```scala





pipeline = PretrainedPipeline('explain_clinical_doc_era', 'en', 'clinical/models')



annotations = pipeline.annotate(text)



annotations.keys()



```



</div>



{:.model-param}
",," - ner_clinical_events

 - assertion_dl

 - re_temporal_events_clinical

 

{:.h2_title}
","

{:.table-model}

|---|---|

|Model Name:|explain_clinical_doc_era_en_2.5.5_2.4|

|Type:|pipeline|

|Compatibility:|Spark NLP 2.5.5|

|License:|Licensed|

|Edition:|Healthcare|

|Language:|[en]|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.5.5,,,explain_clinical_doc_era_en_2.5.5_2.4,,pipeline
WikiNER 6B 300,,John Snow Labs,wikiner_6B_300,2020-05-10,"[ner, pl, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_PL){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PL.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_pl_2.5.0_2.4_1588519719571.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_300"", ""pl"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_300"", ""pl"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://pl.wikipedia.org](https://pl.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|pl|

|Case sensitive:|false|





{:.h2_title}
",,Official,pl,Open Source, Spark NLP 2.5.0,"sentence, token, embeddings",false,wikiner_6B_300,ner,ner
BERT Base Uncased,,John Snow Labs,bert_base_uncased,2020-01-02,"[open_source, embeddings, en]","This model contains a deep bidirectional transformer trained on Wikipedia and the BookCorpus. The details are described in the paper ""[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_base_cased_en_2.4.0_2.4_1580579557778.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = BertEmbeddings.pretrained(""bert_base_uncased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = BertEmbeddings.pretrained(""bert_base_uncased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1](https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1)
",,"

{:.table-model}

|---|---|

|Model Name:|bert_base_uncased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|768|

|Case sensitive:|false|



{:.h2_title}
",768,Official,[en],Open Source,Spark NLP 2.4.0,"[sentence, token]",false,bert_base_uncased,[word_embeddings],embeddings
XLNet Large,,John Snow Labs,xlnet_large_cased,2020-04-28,"[embeddings, en, open_source]","XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context. Overall, XLNet achieves state-of-the-art (SOTA) results on various downstream language tasks including question answering, natural language inference, sentiment analysis, and document ranking. The details are described in the paper ""[â€‹XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)""



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/xlnet_large_cased_en_2.5.0_2.4_1588074397954.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = XlnetEmbeddings.pretrained(""xlnet_large_cased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = XlnetEmbeddings.pretrained(""xlnet_large_cased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
",The model is imported from [https://github.com/zihangdai/xlnet](https://github.com/zihangdai/xlnet),,"

{:.table-model}

|---|---|

|Model Name:|xlnet_large_cased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|1024|

|Case sensitive:|true|



{:.h2_title}
",1024,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",true,xlnet_large_cased,[word_embeddings],embeddings
NerDLModel Clinical Large,"Problem, Test, Treatment





[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_clinical_large_en_2.5.0_2.4_1590021302624.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_clinical_large_en,2020-05-23,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for clinical terms. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_clinical_large"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala

val ner = NerDLModel.pretrained(""ner_clinical_large"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)



```



</div>



{:.model-param}
","Trained on augmented 2010 i2b2 challenge data with 'embeddings_clinical'.

https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_clinical_large_en_2.5.0_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.5.0|

|Edition:|Healthcare|

|License:|Licenced|

|Input Labels:|[sentence, token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licenced,Spark NLP 2.5.0,"[sentence, token, embeddings]",false,ner_clinical_large_en_2.5.0_2.4,[ner],ner
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2020-05-10,"[ner, pl, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_PL){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PL.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_pl_2.5.0_2.4_1588519719572.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""pl"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""pl"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://pl.wikipedia.org](https://pl.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|pl|

|Case sensitive:|false|





{:.h2_title}
",,Official,pl,Open Source, Spark NLP 2.5.0,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
WikiNER 6B 300,,John Snow Labs,wikiner_6B_300,2020-02-03,"[ner, es, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_ES){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_ES.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_es_2.4.0_2.4_1581971942090.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_300"", ""es"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_300"", ""es"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://es.wikipedia.org](https://es.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|es|

|Case sensitive:|false|



{:.h2_title}
",,Official,es,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,wikiner_6B_300,ner,ner
BERT Large Uncased,,John Snow Labs,bert_large_uncased,2020-01-02,"[open_source, embeddings, en]","This model contains a deep bidirectional transformer trained on Wikipedia and the BookCorpus. The details are described in the paper ""[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_large_uncased_en_2.4.0_2.4_1580581306683.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = BertEmbeddings.pretrained(""bert_large_uncased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = BertEmbeddings.pretrained(""bert_large_uncased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/bert_uncased_L-24_H-1024_A-16/1](https://tfhub.dev/google/bert_uncased_L-24_H-1024_A-16/1)
",,"

{:.table-model}

|---|---|

|Model Name:|bert_large_uncased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|1024|

|Case sensitive:|false|



{:.h2_title}
",1024,Official,[en],Open Source,Spark NLP 2.4.0,"[sentence, token]",false,bert_large_uncased,[word_embeddings],embeddings
Deidentification NER (Large),,John Snow Labs,ner_deid_large,2020-03-04,"[ner, en, deidentify, licensed]","Deidentification NER (Large) is a Named Entity Recognition model that annotates text to find protected health information that may need to be deidentified. The entities it annotates are Age, Contact, Date, Id, Location, Name, and Profession. Clinical NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/healthcare/NER_DEMOGRAPHICS){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_DEMOGRAPHICS.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_deid_large_en_2.4.2_2.4_1587513305751.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""ner_deid_large"", ""en"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""ner_deid_large"", ""en"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/](https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/),,"

{:.table-model}

|---|---|

|Model Name:|ner_deid_large|

|Type:|ner|

|Compatibility:| Spark NLP for Healthcare 2.4.2+|

|License:|Licensed|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|en|

|Case sensitive:|false|





{:.h2_title}
",,Official,en,Licensed, Spark NLP for Healthcare 2.4.2+,"sentence, token, embeddings",false,ner_deid_large,ner,ner
NerDLModel Drugs," - DrugChem



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_drugs_en_2.4.4_2.4_1584452534235.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_drugs_en,2020-03-25,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for Drugs. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_drugs"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_drugs"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)





```



</div>



{:.model-param}
","Trained on i2b2_med7 + FDA with 'embeddings_clinical'.

https://www.i2b2.org/NLP/Medication



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_drugs_en_2.4.4_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.4|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.4,"[sentence,token, embeddings]",false,ner_drugs_en_2.4.4_2.4,[ner],ner
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2020-02-03,"[ner, es, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_ES){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_ES.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_es_2.4.0_2.4_1581971942091.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""es"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""es"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://es.wikipedia.org](https://es.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|es|

|Case sensitive:|false|





{:.h2_title}
",,Official,es,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
Glove 840B 300,,John Snow Labs,glove_840B_300,2020-01-22,"[open_source, embeddings]","GloVe (Global Vectors) is a model for distributed word representation. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity. It outperformed many common Word2vec models on the word analogy task. One benefit of GloVe is that it is the result of directly modeling relationships, instead of getting them as a side effect of training a language model.



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/glove_840B_300_xx_2.4.0_2.4_1579698926752.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = WordEmbeddings.pretrained(""glove_840B_300"", ""xx"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = WordEmbeddings.pretrained(""glove_840B_300"", ""xx"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)
",,"

{:.table-model}

|---|---|

|Model Name:|glove_840B_300|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[xx]|

|Dimension:|300|

|Case sensitive:|true|



{:.h2_title}
",300,Official,[xx],Open Source,Spark NLP 2.4.0,"[sentence, token]",true,glove_840B_300,[word_embeddings],embeddings
Assertion DL Large,"

 - hypothetical

 - present

 - absent

 - possible

 - conditional

 - associated_with_someone_else



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.Clinical_Assertion_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertion_dl_large_en_2.5.0_2.4_1590022282256.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,assertion_dl_large_en,2020-05-21,"[ner, en, licensed]","

Deep learning named entity recognition model for assertions. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN.


","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel, NerConverter, AssertionDLModel.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_assertion = AssertionDLModel.pretrained(""assertion_dl_large"", ""en"", ""clinical/models"") \

    .setInputCols([""sentence"", ""ner_chunk"", ""embeddings""]) \

    .setOutputCol(""assertion"")

    

nlpPipeline = Pipeline(stages=[clinical_assertion])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



```



```scala



val clinical_assertion = AssertionDLModel.pretrained(""assertion_dl_large"", ""en"", ""clinical/models"") \

    .setInputCols([""sentence"", ""ner_chunk"", ""embeddings""]) \

    .setOutputCol(""assertion"")



val pipeline = new Pipeline().setStages(Array(clinical_assertion))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)

```



</div>



{:.model-param}
","Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with 'embeddings_clinical'.

https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|assertion_dl_large_en_2.5.0_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.5.0|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence, ner_chunk, embeddings]|

|Output Labels:|[assertion]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.5.0,"[sentence, ner_chunk, embeddings]",false,assertion_dl_large_en_2.5.0_2.4,[assertion],ner
XLNet Base,,John Snow Labs,xlnet_base_cased,2020-04-28,"[embeddings, en, open_source]","XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context. Overall, XLNet achieves state-of-the-art (SOTA) results on various downstream language tasks including question answering, natural language inference, sentiment analysis, and document ranking. The details are described in the paper ""[â€‹XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)""



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/xlnet_base_cased_en_2.5.0_2.4_1588074114942.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = XlnetEmbeddings.pretrained(""xlnet_base_cased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = XlnetEmbeddings.pretrained(""xlnet_base_cased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://github.com/zihangdai/xlnet](https://github.com/zihangdai/xlnet)
",,"

{:.table-model}

|---|---|

|Model Name:|xlnet_base_cased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|768|

|Case sensitive:|true|



{:.h2_title}
",768,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",true,xlnet_base_cased,[word_embeddings],embeddings
ALBERT XLarge Uncase,,John Snow Labs,albert_xlarge_uncased,2020-04-28,"[embeddings, en, open_source]","ALBERT is ""A Lite"" version of BERT, a popular unsupervised language representation learning algorithm. ALBERT uses parameter-reduction techniques that allow for large-scale configurations, overcome previous memory limitations, and achieve better behavior with respect to model degradation. The details are described in the paper ""[ALBERT: A Lite BERT for Self-supervised Learning of Language Representations.](https://arxiv.org/abs/1909.11942)""



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/albert_xlarge_uncased_en_2.5.0_2.4_1588073443653.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = AlbertEmbeddings.pretrained(""albert_xlarge_uncased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = AlbertEmbeddings.pretrained(""albert_xlarge_uncased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/albert_xlarge/3](https://tfhub.dev/google/albert_xlarge/3)
",,"

{:.table-model}

|---|---|

|Model Name:|albert_xlarge_uncased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|2048|

|Case sensitive:|false|





{:.h2_title}
",2048,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",false,albert_xlarge_uncased,[word_embeddings],embeddings
ALBERT XXLarge Uncase,,John Snow Labs,albert_xxlarge_uncased,2020-04-28,"[embeddings, en, open_source]","ALBERT is ""A Lite"" version of BERT, a popular unsupervised language representation learning algorithm. ALBERT uses parameter-reduction techniques that allow for large-scale configurations, overcome previous memory limitations, and achieve better behavior with respect to model degradation. The details are described in the paper ""[ALBERT: A Lite BERT for Self-supervised Learning of Language Representations.](https://arxiv.org/abs/1909.11942)""



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/albert_xxlarge_uncased_en_2.5.0_2.4_1588073588232.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = AlbertEmbeddings.pretrained(""albert_xxlarge_uncased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = AlbertEmbeddings.pretrained(""albert_xxlarge_uncased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/albert_xlarge/3](https://tfhub.dev/google/albert_xlarge/3)
",,"

{:.table-model}

|---|---|

|Model Name:|albert_xxlarge_uncased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|1024|

|Case sensitive:|false|



{:.h2_title}
",1024,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",false,albert_xxlarge_uncased,[word_embeddings],embeddings
Wiki NER 6B 100,,John Snow Labs,wikiner_6B_100,2019-07-13,"[open_source, ner, de]","Wiki NER is a Named Entity Recognition (or NER) model, that can be used to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. Wiki NER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_DE){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_DE.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_de_2.1.0_2.4_1564861417829.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_100"", ""de"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_100"", ""de"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is trained based on data from [https://de.wikipedia.org](https://de.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_100|

|Type:|ner|

|Compatibility:| Spark NLP 2.1.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|de|

|Case sensitive:|false|





{:.h2_title}
",,Official,de,Open Source, Spark NLP 2.1.0,"sentence, token, embeddings",false,wikiner_6B_100,ner,ner
BERT Base Cased,,John Snow Labs,bert_base_cased,2020-01-02,"[open_source, embeddings, en]","This model contains a deep bidirectional transformer trained on Wikipedia and the BookCorpus. The details are described in the paper ""[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_base_cased_en_2.4.0_2.4_1580579557778.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = BertEmbeddings.pretrained(""bert_base_cased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = BertEmbeddings.pretrained(""bert_base_cased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/bert_cased_L-24_H-1024_A-16/1](https://tfhub.dev/google/bert_cased_L-24_H-1024_A-16/1)
",,"

{:.table-model}

|---|---|

|Model Name:|bert_base_cased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|768|

|Case sensitive:|true|



{:.h2_title}
",768,Official,[en],Open Source,Spark NLP 2.4.0,"[sentence, token]",true,bert_base_cased,[word_embeddings],embeddings
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2020-02-03,"[ner, it, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_IT){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_IT.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_it_2.4.0_2.4_1579699913554.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""it"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""it"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://it.wikipedia.org](https://it.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|it|

|Case sensitive:|false|





{:.h2_title}
",,Official,it,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
WikiNER 6B 300,,John Snow Labs,wikiner_6B_300,2020-03-16,"[ner, ru, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_RU){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_RU.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_ru_2.4.4_2.4_1584014001694.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_300"", ""ru"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_300"", ""ru"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://ru.wikipedia.org](https://ru.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.4|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|ru|

|Case sensitive:|false|





{:.h2_title}
",,Official,ru,Open Source, Spark NLP 2.4.4,"sentence, token, embeddings",false,wikiner_6B_300,ner,ner
ALBERT Large Uncase,,John Snow Labs,albert_large_uncased,2020-04-28,"[embeddings, en, open_source]","ALBERT is ""A Lite"" version of BERT, a popular unsupervised language representation learning algorithm. ALBERT uses parameter-reduction techniques that allow for large-scale configurations, overcome previous memory limitations, and achieve better behavior with respect to model degradation. The details are described in the paper ""[ALBERT: A Lite BERT for Self-supervised Learning of Language Representations.](https://arxiv.org/abs/1909.11942)""



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/albert_large_uncased_en_2.5.0_2.4_1588073397355.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = AlbertEmbeddings.pretrained(""albert_large_uncased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = AlbertEmbeddings.pretrained(""albert_large_uncased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/albert_large/3](https://tfhub.dev/google/albert_large/3)
",,"

{:.table-model}

|---|---|

|Model Name:|albert_large_uncased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|1024|

|Case sensitive:|false|





{:.h2_title}
",1024,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",false,albert_large_uncased,[word_embeddings],embeddings
Assertion DL,"

 Hypothetical, Present, Absent, Possible, Conditional, Associated_with_someone_else 



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.Clinical_Assertion_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertion_dl_en_2.4.0_2.4_1580237286004.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,assertion_dl_en,2020-01-30,"[licensed, ner, en]","

Deep learning named entity recognition model for assertions. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN.


","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel, NerConverter, AssertionDLModel.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python

clinical_assertion = AssertionDLModel.pretrained(""assertion_dl"", ""en"", ""clinical/models"") \

    .setInputCols([""sentence"", ""ner_chunk"", ""embeddings""]) \

    .setOutputCol(""assertion"")

    

nlpPipeline = Pipeline(stages=[clinical_assertion])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)

```



```scala

val clinical_assertion = AssertionDLModel.pretrained(""assertion_dl"", ""en"", ""clinical/models"") \

    .setInputCols([""sentence"", ""ner_chunk"", ""embeddings""]) \

    .setOutputCol(""assertion"")



val pipeline = new Pipeline().setStages(Array(clinical_assertion))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)

```



</div>



{:.model-param}
","Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with 'embeddings_clinical'.

https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|assertion_dl_en_2.4.0_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.0|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence, ner_chunk, embeddings]|

|Output Labels:|[assertion]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.0,"[sentence, ner_chunk, embeddings]",false,assertion_dl_en_2.4.0_2.4,[assertion],ner
NerDLModel Healthcare," Problem, Test, Treatment





[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_healthcare_en_2.4.4_2.4_1585188313964.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_healthcare_en,2020-03-26,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for healthcare. Includes Problem, Test and Treatment entities. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_healthcare"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_healthcare"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)





```



</div>



{:.model-param}
","Trained on 2010 i2b2 challenge data with 'embeddings_clinical'.

https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_healthcare_en_2.4.4_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.4|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.4,"[sentence,token, embeddings]",false,ner_healthcare_en_2.4.4_2.4,[ner],ner
WikiNER 6B 300,,John Snow Labs,wikiner_6B_300,2019-07-13,"[open_source, ner, fr]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_FR){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_FR.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_fr_2.1.0_2.4_1564817386216.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_300"", ""fr"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_300"", ""fr"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.1.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|fr|

|Case sensitive:|false|





{:.h2_title}
",,Official,fr,Open Source, Spark NLP 2.1.0,"sentence, token, embeddings",false,wikiner_6B_300,ner,ner
NerDLModel Risk Factors,"CAD, Diabetes, Family_hist, Hyperlipidemia, Hypertension, Medication, Obese, PHI, Smoker




",John Snow Labs,ner_risk_factors_en,2020-04-22,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for Heart Disease Risk Factors and Personal Health Information. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_risk_factors_en_2.4.2_2.4_1587513300751.zip){:.button.button-orange.button-orange-trans.arr.button-icon}



{:.h2_title}
","



Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_risk_factors"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_risk_factors"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)





```



</div>



{:.model-param}
","Trained on plain n2c2 2014: De-identification and Heart Disease Risk Factors Challenge datasets with 'embeddings_clinical'.

https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_risk_factors_en_2.4.2_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.2|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.2,"[sentence,token, embeddings]",false,ner_risk_factors_en_2.4.2_2.4,[ner],ner
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2020-02-03,"[ner, de, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_DE){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_DE.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_de_2.4.0_2.4_1579699913555.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""de"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""de"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://de.wikipedia.org](https://de.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|de|

|Case sensitive:|false|





{:.h2_title}
",,Official,de,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
Deidentify (Large),,John Snow Labs,deidentify_large,2020-08-04,"[deid, en, licensed]","Deidentify (Large) is a deidentification model. It identifies instances of protected health information in text documents, and it can either obfuscate them (e.g., replacing names with different, fake names) or mask them (e.g., replacing ""2020-06-04"" with ""<DATE>""). This model is useful for maintaining HIPAA compliance when dealing with text documents that contain protected health information.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/healthcare/DEID_PHI_TEXT){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/DEID_PHI_TEXT.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/nerdl_deid_en_1.8.0_2.4_1545462443516.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



deid = DeIdentificationModel.pretrained(""deidentify_large"", ""en"") \

        .setInputCols([""sentence"", ""token"", ""ner_chunk""]) \

        .setOutputCol(""obfuscated"") \

          .setMode(""obfuscate"")

```



```scala



val deid = DeIdentificationModel.pretrained(""deidentify_large"", ""en"")

        .setInputCols(Array(""sentence"", ""token"", ""ner_chunk""))

        .setOutputCol(""obfuscated"") \

          .setMode(""obfuscate"")

```



</div>



{:.model-param}
",The model is imported from [https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/](https://portal.dbmi.hms.harvard.edu/projects/n2c2-2014/),,"

{:.table-model}

|---|---|

|Model Name:|deidentify_large|

|Type:|deid|

|Compatibility:| Spark NLP for Healthcare 2.5.5|

|License:|Licensed|

|Edition:|Official|

|Input Labels:|sentence, token, ner_chunk|

|Output Labels:|obfuscated|

|Language:|en|

|Case sensitive:|false|





{:.h2_title}
",,Official,en,Licensed, Spark NLP for Healthcare 2.5.5,"sentence, token, ner_chunk",false,deidentify_large,obfuscated,deid
Assertion ML,"

 Hypothetical, Present, Absent, Possible, Conditional, Associated_with_someone_else 



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.Clinical_Assertion_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertion_dl_large_en_2.5.0_2.4_1590022282256.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,assertion_ml_en,2020-01-30,"[licensed, ner, en]","

Logistic regression based named entity recognition model for assertions. 


","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel, NerConverter, AssertionLogRegModel.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_assertion_ml = AssertionLogRegModel.pretrained(""assertion_ml"", ""en"", ""clinical/models"") \

    .setInputCols([""sentence"", ""ner_chunk"", ""embeddings""]) \

    .setOutputCol(""assertion"")

    

nlpPipeline = Pipeline(stages=[clinical_assertion_ml])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



```



```scala



val clinical_assertion_ml = AssertionLogRegModel.pretrained(""assertion_ml"", ""en"", ""clinical/models"") \

    .setInputCols([""sentence"", ""ner_chunk"", ""embeddings""]) \

    .setOutputCol(""assertion"")



val pipeline = new Pipeline().setStages(Array(clinical_assertion_ml))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)

```



</div>



{:.model-param}
","Trained on 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text with 'embeddings_clinical'.

https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|assertion_ml_en_2.4.0_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.0|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence, ner_chunk, embeddings]|

|Output Labels:|[assertion]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.0,"[sentence, ner_chunk, embeddings]",false,assertion_ml_en_2.4.0_2.4,[assertion],ner
GloVe 840B 300,,John Snow Labs,glove_840B_300,2020-02-03,"[embeddings, en, open_source]","GloVe (Global Vectors) is a model for distributed word representation. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity. It outperformed many common Word2vec models on the word analogy task. One benefit of GloVe is that it is the result of directly modeling relationships, instead of getting them as a side effect of training a language model.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_EN){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_EN.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/glove_840B_300_xx_2.4.0_2.4_1579698926752.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = WordEmbeddingsModel.pretrained(""glove_840B_300"", ""en"") \

        .setInputCols([""document"", ""token""]) \

        .setOutputCol(""embeddings"")

```



```scala



val embeddings = WordEmbeddingsModel.pretrained(""glove_840B_300"", ""en"")

        .setInputCols(Array(""document"", ""token""))

        .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
",The model is imported from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/),,"

{:.table-model}

|---|---|

|Model Name:|glove_840B_300|

|Type:|embeddings|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence. token|

|Output Labels:|embeddings|

|Language:|en|

|Dimension:|300|

|Case sensitive:|false|



{:.h2_title}
",300,Official,en,Open Source, Spark NLP 2.4.0,sentence. token,false,glove_840B_300,embeddings,embeddings
WikiNER 6B 100,,John Snow Labs,wikiner_6B_100,2020-05-10,"[ner, nl, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_NL){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_NL.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_nl_2.5.0_2.4_1588546201140.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_100"", ""nl"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_100"", ""nl"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_100|

|Type:|ner|

|Compatibility:| Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|nl|

|Case sensitive:|false|





{:.h2_title}
",,Official,nl,Open Source, Spark NLP 2.5.0,"sentence, token, embeddings",false,wikiner_6B_100,ner,ner
Ner DL Model Enriched,"Age, Diagnosis, Dosage, Drug_name, Frequency, Gender, Lab_name, Lab_result, Symptom_name



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_jsl_enriched_en_2.4.2_2.4_1587513303751.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_jsl_enriched_en,2020-04-22,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for clinical terminology. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","



Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}







```python



clinical_ner = NerDLModel.pretrained(""ner_jsl_enriched"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_jsl_enriched"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)





```



</div>



{:.model-param}
","Trained on data gathered and manually annotated by John Snow Labs.

https://www.johnsnowlabs.com/data/





{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_jsl_enriched_en_2.4.2_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.2|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.2,"[sentence,token, embeddings]",false,ner_jsl_enriched_en_2.4.2_2.4,[ner],ner
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2019-07-13,"[open_source, ner, it]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_IT){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_IT.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_it_2.1.0_2.4_1563095099139.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""it"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""it"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://it.wikipedia.org](https://it.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.1.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|it|

|Case sensitive:|false|



{:.h2_title}
",,Official,it,Open Source, Spark NLP 2.1.0,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
Glove 6B 100,,John Snow Labs,glove_100d,2020-01-22,"[open_source, embeddings, en]","GloVe (Global Vectors) is a model for distributed word representation. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity. It outperformed many common Word2vec models on the word analogy task. One benefit of GloVe is that it is the result of directly modeling relationships, instead of getting them as a side effect of training a language model.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_EN/){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_dl.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/glove_100d_en_2.4.0_2.4_1579690104032.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = WordEmbeddingsModel.pretrained(""glove_100d"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = WordEmbeddingsModel.pretrained(""glove_100d"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)
",,"

{:.table-model}

|---|---|

|Model Name:|glove_100d|

|Type:|word_embeddings|

|Compatibility:|Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[embeddings]|

|Language:|[en]|

|Dimension:|100|

|Case sensitive:|false|





{:.h2_title}
",100,Official,[en],Open Source,Spark NLP 2.4.0,"[sentence, token]",false,glove_100d,[embeddings],word_embeddings
NerDLModel Clinical Events,"Date,Time,Problem,Test,Treatment,Occurence,Clinical_Dept,Evidential,Duration,Frequency,Admission,Discharge



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_events_clinical_en_2.5.0_2.4_1590021303624.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_events_clinical,2020-03-25,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for clinical events. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



clinical_ner = NerDLModel.pretrained(""ner_events_clinical"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_events_clinical"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)





```



</div>



{:.model-param}
","Trained on i2b2 events data with 'clinical_embeddings'. 

https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_events_clinical_en_2.5.0_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.5.0|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.5.0,"[sentence,token, embeddings]",false,ner_events_clinical_en_2.5.0_2.4,[ner],ner
Neoplasms NER,,John Snow Labs,ner_neoplasms,2020-07-03,"[ner, en, licensed]","Neoplasms NER is a Named Entity Recognition model that annotates text to find references to tumors. The only entity it annotates is MalignantNeoplasm. Neoplasms NER is trained with the 'embeddings_clinical' word embeddings model, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/healthcare/NER_TUMOR){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_TUMOR.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_neoplasms_es_2.5.3_2.4_1594168624415.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""ner_neoplasms"", ""en"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""ner_neoplasms"", ""en"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://temu.bsc.es/cantemist/](https://temu.bsc.es/cantemist/),,"

{:.table-model}

|---|---|

|Model Name:|ner_neoplasms|

|Type:|ner|

|Compatibility:| Spark NLP for Healthcare 2.5.3+|

|License:|Licensed|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|en|

|Case sensitive:|false|





{:.h2_title}
",,Official,en,Licensed, Spark NLP for Healthcare 2.5.3+,"sentence, token, embeddings",false,ner_neoplasms,ner,ner
BioBERT Discharge,,John Snow Labs,biobert_discharge_base_cased,2020-07-20,"[embeddings, en, open_source]","This model contains a pre-trained weights of ClinicalBERT for discharge summaries. This domain-specific model has performance improvements on 3/5 clinical NLP tasks andd establishing a new state-of-the-art on the MedNLI dataset. The details are described in the paper ""[Publicly Available Clinical BERT Embeddings](https://www.aclweb.org/anthology/W19-1909/)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_discharge_base_cased_en_2.5.0_2.4_1590490193605.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = BertEmbeddings.pretrained(""biobert_discharge_base_cased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = BertEmbeddings.pretrained(""biobert_discharge_base_cased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://github.com/EmilyAlsentzer/clinicalBERT](https://github.com/EmilyAlsentzer/clinicalBERT)
",,"

{:.table-model}

|---|---|

|Model Name:|biobert_discharge_base_cased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|768|

|Case sensitive:|true|





{:.h2_title}
",768,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",true,biobert_discharge_base_cased,[word_embeddings],embeddings
WikiNER 6B 300,,John Snow Labs,wikiner_6B_300,2020-02-03,"[ner, de, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_DE){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_DE.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_de_2.4.0_2.4_1579717534653.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_300"", ""de"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_300"", ""de"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://de.wikipedia.org](https://de.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|de|

|Case sensitive:|false|



{:.h2_title}
",,Official,de,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,wikiner_6B_300,ner,ner
BioBERT PMC,,John Snow Labs,biobert_pmc_base_cased,2020-07-20,"[embeddings, en, open_source]","This model contains a pre-trained weights of BioBERT, a language representation model for biomedical domain, especially designed for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, question answering, etc. The details are described in the paper ""[BioBERT: a pre-trained biomedical language representation model for biomedical text mining](https://arxiv.org/abs/1901.08746)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_pmc_base_cased_en_2.5.0_2.4_1590489029151.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = BertEmbeddings.pretrained(""biobert_pmc_base_cased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = BertEmbeddings.pretrained(""biobert_pmc_base_cased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://github.com/dmis-lab/biobert](https://github.com/dmis-lab/biobert)
",,"

{:.table-model}

|---|---|

|Model Name:|biobert_pmc_base_cased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|768|

|Case sensitive:|true|





{:.h2_title}
",768,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",true,biobert_pmc_base_cased,[word_embeddings],embeddings
WikiNER 6B 100,,John Snow Labs,wikiner_6B_100,2020-03-16,"[ner, ru, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_RU){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_RU.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_ru_2.4.4_2.4_1584014001452.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_100"", ""ru"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_100"", ""ru"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://ru.wikipedia.org](https://ru.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_100|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.4|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|ru|

|Case sensitive:|false|





{:.h2_title}
",,Official,ru,Open Source, Spark NLP 2.4.4,"sentence, token, embeddings",false,wikiner_6B_100,ner,ner
WikiNER 6B 300,,John Snow Labs,wikiner_6B_300,2020-05-10,"[ner, nl, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_NL){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_NL.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_nl_2.5.0_2.4_1588546201483.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_300"", ""nl"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_300"", ""nl"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|nl|

|Case sensitive:|false|



{:.h2_title}
",,Official,nl,Open Source, Spark NLP 2.5.0,"sentence, token, embeddings",false,wikiner_6B_300,ner,ner
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2020-02-03,"[ner, fr, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_FR){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_FR.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_fr_2.4.0_2.4_1579699913554.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""fr"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""fr"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|fr|

|Case sensitive:|false|





{:.h2_title}
",,Official,fr,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2020-05-10,"[ner, nl, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_NL){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_NL.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_nl_2.5.0_2.4_1588546201484.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""nl"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""nl"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is trained based on data from [https://fr.wikipedia.org](https://fr.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|nl|

|Case sensitive:|false|





{:.h2_title}
",,Official,nl,Open Source, Spark NLP 2.5.0,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
WikiNER 840B 300,,John Snow Labs,wikiner_840B_300,2020-05-10,"[ner, pt, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 840B 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_PT){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_840B_300_pt_2.5.0_2.4_1588495233642.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_840B_300"", ""pt"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_840B_300"", ""pt"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://pt.wikipedia.org](https://pt.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_840B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.5.0|

|Edition:|Official|

|License:|Open Source|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|pt|

|Case sensitive:|false|



{:.h2_title}
",,Official,pt,Open Source, Spark NLP 2.5.0,"sentence, token, embeddings",false,wikiner_840B_300,ner,ner
Elmo,,John Snow Labs,elmo,2020-01-31,"[embeddings, en, open_source]","Computes contextualized word representations using character-based word representations and bidirectional LSTMs.



This model outputs fixed embeddings at each LSTM layer and a learnable aggregation of the 3 layers.



* `word_emb`: the character-based word representations with shape [batch_size, max_length, 512].  == word_emb

* `lstm_outputs1`: the first LSTM hidden state with shape [batch_size, max_length, 1024]. === lstm_outputs1

* `lstm_outputs2`: the second LSTM hidden state with shape [batch_size, max_length, 1024]. === lstm_outputs2

* `elmo`: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape [batch_size, max_length, 1024]  == elmo

  

The complex architecture achieves state of the art results on several benchmarks. Note that this is a very computationally expensive module compared to word embedding modules that only perform embedding lookups. The use of an accelerator is recommended.



The details are described in the paper ""[Deep contextualized word representations](https://arxiv.org/abs/1802.05365)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/elmo_en_2.4.0_2.4_1580488815299.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = ElmoEmbeddings.pretrained(""elmo"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"") \

      .setPoolingLayer(""elmo"")

```



```scala



val embeddings = ElmoEmbeddings.pretrained(""elmo"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

      .setPoolingLayer(""elmo"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/elmo/3](https://tfhub.dev/google/elmo/3)
",,"

{:.table-model}

|---|---|

|Model Name:|elmo|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|512|1024|

|Case sensitive:|true|





{:.h2_title}
",5121024,Official,[en],Open Source,Spark NLP 2.4.0,"[sentence, token]",true,elmo,[word_embeddings],embeddings
Onto 100,,John Snow Labs,onto_100,2020-02-03,"[ner, en, open_source]","Onto is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. Onto was trained on the OntoNotes text corpus. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. Onto 100 is trained with GloVe 100d word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_EN_18){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_EN.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/onto_100_en_2.4.0_2.4_1579729071672.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""onto_100"", ""en"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""onto_100"", ""en"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://catalog.ldc.upenn.edu/LDC2013T19](https://catalog.ldc.upenn.edu/LDC2013T19),,"

{:.table-model}

|---|---|

|Model Name:|onto_100|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|en|

|Case sensitive:|false|



{:.h2_title}
",,Official,en,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,onto_100,ner,ner
NerDLModel Posology Large,"Dosage, Drug, Duration, Form, Frequency, Route, Strength



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_posology_large_en_2.4.2_2.4_1587513302751.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_posology_large_en,2020-04-22,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for posology. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_posology_large"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_posology_large"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)





```



</div>



{:.model-param}
","Trained on the 2018 i2b2 dataset and FDA Drug datasets with 'embeddings_clinical'.

https://open.fda.gov/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_posology_large_en_2.4.2_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.2|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.2,"[sentence,token, embeddings]",false,ner_posology_large_en_2.4.2_2.4,[ner],ner
NerDLModel Diseases," - Disease



{:.btn-box}

[Live Demo](#){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_diseases_en_2.4.4_2.4_1584452534235.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_diseases_en,2020-03-25,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for diseases. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_diseases"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_diseases"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)



}



```



</div>



{:.model-param}
","Trained on i2b2 with 'embeddings_clinical'.

https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_diseases_en_2.4.4_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.4|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.4,"[sentence,token, embeddings]",false,ner_diseases_en_2.4.4_2.4,[ner],ner
RelationExtractionModel Clinical,"

TrIP: A certain treatment has improved or cured a medical problem (eg, â€˜infection resolved with antibiotic courseâ€™)



TrWP: A patient's medical problem has deteriorated or worsened because of or in spite of a treatment being administered (eg, â€˜the tumor was growing despite the drainâ€™)



TrCP: A treatment caused a medical problem (eg, â€˜penicillin causes a rashâ€™)



TrAP: A treatment administered for a medical problem (eg, â€˜Dexamphetamine for narcolepsyâ€™)



TrNAP: The administration of a treatment was avoided because of a medical problem (eg, â€˜Ralafen which is contra-indicated because of ulcersâ€™)



TeRP: A test has revealed some medical problem (eg, â€˜an echocardiogram revealed a pericardial effusionâ€™)



TeCP: A test was performed to investigate a medical problem (eg, â€˜chest x-ray done to rule out pneumoniaâ€™)



PIP: Two problems are related to each other (eg, â€˜Azotemia presumed secondary to sepsisâ€™)





[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/re_clinical_en_2.5.5_2.4_1596928426753.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


",John Snow Labs,re_clinical_en,2020-08-09,"[re, en, licensed]","

Models the set of clinical relations defined in the 2010 i2b2 relation challenge.



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, PerceptronModel, NerDLModel, NerConverter, DependencyParserModel, RelationExtractionModel.



The precision of the RE model is controlled by ""setMaxSyntacticDistance(4)"", which sets the maximum syntactic distance between named entities to 4. A larger value will improve recall at the expense at lower precision.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python





clinical_re_Model = RelationExtractionModel()\

    .pretrained(""re_clinical"", ""en"", 'clinical/models')\

    .setInputCols([""embeddings"", ""pos_tags"", ""ner_chunks"", ""dependencies""])\

    .setOutputCol(""relations"")\

    .setMaxSyntacticDistance(4)\

    .setRelationPairs([""problem-test"", ""problem-treatment""]) # Possible relation pairs. Default is all relations.



loaded_pipeline = Pipeline(stages=[clinical_re_Model])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



loaded_model = loaded_pipeline.fit(empty_data)



loaded_lmodel = LightPipeline(loaded_model)



annotations = loaded_lmodel.fullAnnotate(text)



rel_df = get_relations_df (annotations)

```



</div>



{:.model-param}
","Trained on augmented 2010 i2b2 challenge data with 'clinical_embeddings'.

https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|re_clinical_en_2.5.5_2.4|

|Type:|re|

|Compatibility:|Spark NLP 2.5.5|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[embeddings, pos_tags, ner_chunks, dependencies]|

|Output Labels:|[relations]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.5.5,"[embeddings, pos_tags, ner_chunks, dependencies]",false,re_clinical_en_2.5.5_2.4,[relations],re
Onto 300,,John Snow Labs,onto_300,2020-02-03,"[ner, en, open_source]","Onto is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. Onto was trained on the OntoNotes text corpus. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. Onto 300 is trained with GloVe 840B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_EN_18){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_EN.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/onto_300_en_2.4.0_2.4_1579729071854.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""onto_300"", ""en"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""onto_300"", ""en"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://catalog.ldc.upenn.edu/LDC2013T19](https://catalog.ldc.upenn.edu/LDC2013T19),,"

{:.table-model}

|---|---|

|Model Name:|onto_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|en|

|Case sensitive:|false|





{:.h2_title}
",,Official,en,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,onto_300,ner,ner
WikiNER 6B 100,,John Snow Labs,wikiner_6B_100,2020-05-10,"[ner, pl, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_PL){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PL.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_pl_2.5.0_2.4_1588519719293.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_100"", ""pl"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_100"", ""pl"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://pl.wikipedia.org](https://pl.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_100|

|Type:|ner|

|Compatibility:| Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|pl|

|Case sensitive:|false|





{:.h2_title}
",,Official,pl,Open Source, Spark NLP 2.5.0,"sentence, token, embeddings",false,wikiner_6B_100,ner,ner
NerDLModel Clinical," Problem, Test, Treatment



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_clinical_en_2.4.0_2.4_1580237286004.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_clinical_en,2020-01-30,"[licensed, ner, en]","

Pretrained named entity recognition deep learning model for clinical terms. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN.



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_clinical"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")





nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_clinical"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)



```



</div>



{:.model-param}
","Trained on 2010 i2b2 challenge data with `embeddings_clinical`.

https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_clinical_en_2.4.0_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.0|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.0,"[sentence,token, embeddings]",false,ner_clinical_en_2.4.0_2.4,[ner],ner
BioBERT Pubmed,,John Snow Labs,biobert_pubmed_base_cased,2020-07-20,"[embeddings, en, open_source]","This model contains a pre-trained weights of BioBERT, a language representation model for biomedical domain, especially designed for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, question answering, etc. The details are described in the paper ""[BioBERT: a pre-trained biomedical language representation model for biomedical text mining](https://arxiv.org/abs/1901.08746)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_pubmed_base_cased_en_2.5.0_2.4_1590487367971.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = BertEmbeddings.pretrained(""biobert_pubmed_base_cased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = BertEmbeddings.pretrained(""biobert_pubmed_base_cased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://github.com/dmis-lab/biobert](https://github.com/dmis-lab/biobert)
",,"

{:.table-model}

|---|---|

|Model Name:|biobert_pubmed_base_cased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|768|

|Case sensitive:|true|





{:.h2_title}
",768,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",true,biobert_pubmed_base_cased,[word_embeddings],embeddings
NerDLModel Posology,"Dosage,Drug,Duration,Form,Frequency,Route,Strength



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_posology_en_2.4.4_2.4_1584452534235.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_posology_en,2020-04-15,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for posology. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_posology"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_posology"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)

```



</div>



{:.model-param}
","Trained on the 2018 i2b2 dataset and FDA Drug datasets with 'embeddings_clinical'.

https://open.fda.gov/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_posology_en_2.4.2_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.2|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.2,"[sentence,token, embeddings]",false,ner_posology_en_2.4.2_2.4,[ner],ner
BioBERT Pubmed PMC,,John Snow Labs,biobert_pubmed_pmc_base_cased,2020-07-20,"[embeddings, en, open_source]","This model contains a pre-trained weights of BioBERT, a language representation model for biomedical domain, especially designed for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, question answering, etc. The details are described in the paper ""[BioBERT: a pre-trained biomedical language representation model for biomedical text mining](https://arxiv.org/abs/1901.08746)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_pubmed_pmc_base_cased_en_2.5.0_2.4_1590489367180.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = BertEmbeddings.pretrained(""biobert_pubmed_pmc_base_cased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = BertEmbeddings.pretrained(""biobert_pubmed_pmc_base_cased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://github.com/dmis-lab/biobert](https://github.com/dmis-lab/biobert)
",,"

{:.table-model}

|---|---|

|Model Name:|biobert_pubmed_pmc_base_cased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|768|

|Case sensitive:|true|





{:.h2_title}
",768,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",true,biobert_pubmed_pmc_base_cased,[word_embeddings],embeddings
Universal Sentence Encoder Large,,John Snow Labs,tfhub_use_lg,2020-04-17,"[embeddings, en, open_source]","The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.



The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length English text and the output is a 512 dimensional vector. We apply this model to the STS benchmark for semantic similarity, and the results can be seen in the example notebook made available. The universal-sentence-encoder model is trained with a deep averaging network (DAN) encoder.



The details are described in the paper ""[Universal Sentence Encoder](https://arxiv.org/abs/1803.11175)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/tfhub_use_lg_en_2.4.0_2.4_1587136993894.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = UniversalSentenceEncoder.pretrained(""tfhub_use_lg"", ""en"") \

      .setInputCols(""document"") \

      .setOutputCol(""sentence_embeddings"")

```



```scala



val embeddings = UniversalSentenceEncoder.pretrained(""tfhub_use_lg"", ""en"")

      .setInputCols(""document"")

      .setOutputCol(""sentence_embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://tfhub.dev/google/universal-sentence-encoder-large/3](https://tfhub.dev/google/universal-sentence-encoder-large/3)
",,"

{:.table-model}

|---|---|

|Model Name:|tfhub_use_lg|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence]|

|Output Labels:|[sentence_embeddings]|

|Language:|[en]|

|Dimension:|512|

|Case sensitive:|true|





{:.h2_title}
",512,Official,[en],Open Source,Spark NLP 2.4.0,[sentence],true,tfhub_use_lg,[sentence_embeddings],embeddings
Glove 6B 300,,John Snow Labs,glove_6B_300,2020-01-22,"[open_source, embeddings]","GloVe (Global Vectors) is a model for distributed word representation. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity. It outperformed many common Word2vec models on the word analogy task. One benefit of GloVe is that it is the result of directly modeling relationships, instead of getting them as a side effect of training a language model.



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/glove_6B_300_xx_2.4.0_2.4_1579698630432.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = WordEmbeddings.pretrained(""glove_6B_300"", ""xx"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = WordEmbeddings.pretrained(""glove_6B_300"", ""xx"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)
",,"

{:.table-model}

|---|---|

|Model Name:|glove_6B_300|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[xx]|

|Dimension:|300|

|Case sensitive:|false|



{:.h2_title}
",300,Official,[xx],Open Source,Spark NLP 2.4.0,"[sentence, token]",false,glove_6B_300,[word_embeddings],embeddings
NerDLModel Cellular,"DNA, Cell_type, Cell_line, RNA, Protein



[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_cellular_en_2.4.2_2.4_1587513308751.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_cellular_en,2020-04-22,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for molecular biology related terms. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}





```python



clinical_ner = NerDLModel.pretrained(""ner_cellular"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_cellular"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)

```



</div>



{:.model-param}
","Trained on the JNLPBA corpus containing more than 2.404 publication abstracts with 'embeddings_clinical'.

http://www.geniaproject.org/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_cellular_en_2.4.2_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.2|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.2,"[sentence,token, embeddings]",false,ner_cellular_en_2.4.2_2.4,[ner],ner
WikiNER 6B 300,,John Snow Labs,wikiner_6B_300,2020-02-03,"[ner, it, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_IT){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_IT.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_it_2.4.0_2.4_1579717534334.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_300"", ""it"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_300"", ""it"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://it.wikipedia.org](https://it.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|it|

|Case sensitive:|false|



{:.h2_title}
",,Official,it,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,wikiner_6B_300,ner,ner
WikiNER 6B 300,,John Snow Labs,wikiner_6B_300,2019-07-13,"[open_source, ner, it]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_IT){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_IT.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_it_2.1.0_2.4_1564906405608.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_300"", ""it"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_300"", ""it"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://it.wikipedia.org](https://it.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.1.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|it|

|Case sensitive:|false|





{:.h2_title}
",,Official,it,Open Source, Spark NLP 2.1.0,"sentence, token, embeddings",false,wikiner_6B_300,ner,ner
WikiNER 6B 300,,John Snow Labs,wikiner_6B_300,2020-05-10,"[ner, pt, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_PT){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_pt_2.5.0_2.4_1588495233641.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_300"", ""pt"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_300"", ""pt"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://pt.wikipedia.org](https://pt.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_300|

|Type:|ner|

|Compatibility:| Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|pt|

|Case sensitive:|false|





{:.h2_title}
",,Official,pt,Open Source, Spark NLP 2.5.0,"sentence, token, embeddings",false,wikiner_6B_300,ner,ner
NerDLModel Anatomy,"Anatomical_system,Cell,Cellular_component,Developing_anatomical_structure,Immaterial_anatomical_entity,Multi-tissue_structure,Organ,Organism_subdivision,Organism_substance,Pathological_formation,Tissue





[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_anatomy_en_2.4.2_2.4_1587513307751.zip){:.button.button-orange.button-orange-trans.arr.button-icon}




",John Snow Labs,ner_anatomy_en,2020-04-22,"[ner, en, licensed]","

Pretrained named entity recognition deep learning model for anatomy terms. Includes Anatomical_system, Cell, Cellular_component, Developing_anatomical_structure, Immaterial_anatomical_entity, Multi-tissue_structure, Organ, Organism_subdivision, Organism_substance, Pathological_formation, and Tissue entities. The SparkNLP deep learning model (NerDL) is inspired by a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM-CNN. 



{:.h2_title}
","

Use as part of an nlp pipeline with the following stages: DocumentAssembler, SentenceDetector, Tokenizer, WordEmbeddingsModel, NerDLModel. Add the NerConverter to the end of the pipeline to convert entity tokens into full entity chunks.



<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}







```python



clinical_ner = NerDLModel.pretrained(""ner_anatomy"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



nlpPipeline = Pipeline(stages=[clinical_ner])



empty_data = spark.createDataFrame([[""""]]).toDF(""text"")



model = nlpPipeline.fit(empty_data)



results = model.transform(data)



```



```scala



val ner = NerDLModel.pretrained(""ner_anatomy"", ""en"", ""clinical/models"") \

  .setInputCols([""sentence"", ""token"", ""embeddings""]) \

  .setOutputCol(""ner"")



val pipeline = new Pipeline().setStages(Array(ner))



val result = pipeline.fit(Seq.empty[String].toDS.toDF(""text"")).transform(data)





```



</div>



{:.model-param}
","Trained on the Anatomical Entity Mention (AnEM) corpus with 'embeddings_clinical'.

http://www.nactem.ac.uk/anatomy/



{:.h2_title}
",,"

{:.table-model}

|---|---|

|Model Name:|ner_anatomy_en_2.4.2_2.4|

|Type:|ner|

|Compatibility:|Spark NLP 2.4.2|

|Edition:|Healthcare|

|License:|Licensed|

|Input Labels:|[sentence,token, embeddings]|

|Output Labels:|[ner]|

|Language:|[en]|

|Case sensitive:|false|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.4.2,"[sentence,token, embeddings]",false,ner_anatomy_en_2.4.2_2.4,[ner],ner
WikiNER 6B 100,,John Snow Labs,wikiner_6B_100,2020-02-03,"[ner, es, open_source]","WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}

[Live Demo](https://demo.johnsnowlabs.com/public/NER_ES){:.button.button-orange}{:target=""_blank""}

[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_ES.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_es_2.4.0_2.4_1581971941700.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



ner = NerDLModel.pretrained(""wikiner_6B_100"", ""es"") \

        .setInputCols([""document"", ""token"", ""embeddings""]) \

        .setOutputCol(""ner"")

```



```scala



val ner = NerDLModel.pretrained(""wikiner_6B_100"", ""es"")

        .setInputCols(Array(""document"", ""token"", ""embeddings""))

        .setOutputCol(""ner"")

```



</div>



{:.model-param}
",The model is imported from [https://es.wikipedia.org](https://es.wikipedia.org),,"

{:.table-model}

|---|---|

|Model Name:|wikiner_6B_100|

|Type:|ner|

|Compatibility:| Spark NLP 2.4.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|sentence, token, embeddings|

|Output Labels:|ner|

|Language:|es|

|Case sensitive:|false|



{:.h2_title}
",,Official,es,Open Source, Spark NLP 2.4.0,"sentence, token, embeddings",false,wikiner_6B_100,ner,ner
BioBERT Pubmed Large,,John Snow Labs,biobert_pubmed_large_cased,2020-07-20,"[embeddings, en, open_source]","This model contains a pre-trained weights of BioBERT, a language representation model for biomedical domain, especially designed for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, question answering, etc. The details are described in the paper ""[BioBERT: a pre-trained biomedical language representation model for biomedical text mining](https://arxiv.org/abs/1901.08746)"".



{:.btn-box}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/biobert_pubmed_large_cased_en_2.5.0_2.4_1590487739645.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python



embeddings = BertEmbeddings.pretrained(""biobert_pubmed_large_cased"", ""en"") \

      .setInputCols(""sentence"", ""token"") \

      .setOutputCol(""embeddings"")

```



```scala



val embeddings = BertEmbeddings.pretrained(""biobert_pubmed_large_cased"", ""en"")

      .setInputCols(""sentence"", ""token"")

      .setOutputCol(""embeddings"")

```



</div>



{:.model-param}
","The model is imported from [https://github.com/dmis-lab/biobert](https://github.com/dmis-lab/biobert)
",,"

{:.table-model}

|---|---|

|Model Name:|biobert_pubmed_large_cased|

|Type:|embeddings|

|Compatibility:|Spark NLP 2.5.0|

|License:|Open Source|

|Edition:|Official|

|Input Labels:|[sentence, token]|

|Output Labels:|[word_embeddings]|

|Language:|[en]|

|Dimension:|1024|

|Case sensitive:|true|



{:.h2_title}
",1024,Official,[en],Open Source,Spark NLP 2.5.0,"[sentence, token]",true,biobert_pubmed_large_cased,[word_embeddings],embeddings
Explain Clinical Doc CARP,,John Snow Labs,explain_clinical_doc_carp_en,2020-08-19,"[pipeline, en, licensed]","A pretrained pipeline with ner_clinical, assertion_dl, re_clinical and ner_posology. It will extract clinical and medication entities, assign assertion status and find relationships between clinical entities.







[//]: <[Live Demo](){:.button.button-orange}{:target=""_blank""}>



{:.btn-box}

<button class=""button button-orange"" disabled>Live Demo</button>

[Open in Colab](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target=""_blank""}{:target=""_blank""}

[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/explain_clinical_doc_carp_en_2.5.5_2.4_1597841630062.zip){:.button.button-orange.button-orange-trans.arr.button-icon}


","

<div class=""tabs-box"" markdown=""1"">



{% include programmingLanguageSelectScalaPython.html %}



```python

pipeline = PretrainedPipeline('explain_clinical_doc_carp', 'en', 'clinical/models')



annotations = pipeline.annotate(text)



annotations.keys()

```



{:.noactive}

```scala

```



</div>



{:.model-param}
",," - ner_clinical

 - assertion_dl

 - re_clinical

 - ner_posology

{:.h2_title}
","

{:.table-model}

|---|---|

|Model Name:|explain_clinical_doc_carp_en_2.5.5_2.4|

|Type:|pipeline|

|Compatibility:|Spark NLP 2.5.5|

|License:|Licensed|

|Edition:|Healthcare|

|Language:|[en]|



{:.h2_title}
",,Healthcare,[en],Licensed,Spark NLP 2.5.5,,,explain_clinical_doc_carp_en_2.5.5_2.4,,pipeline
