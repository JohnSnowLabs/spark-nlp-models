type,approach_class,model_class,class_description,inputs,output,class_license,dataset_schema,class_annotation_sample,tags,class_parameters,reference_url,paper_url,scala_docs,scala_source,scala_source_tests,evaluator_class,paper_abstract,scala_nlp_code,python_nlp_code,python_nlu_code,wikipedia_link
assertion_dl,AssertionDLApproach,AssertionDLModel,Assertion of Clinical Entities based on Deep Learning,"document, chunk, word_embeddings",assertion,licensed,,,"clinical,assertion,dl",,,,,,,,,,,,
assertion_logreg,AssertionLogRegApproach,AssertionLogRegModel,Assertion of Clinical Entities based on Logistic Regression,"document, chunk, word_embeddings",assertion,licensed,,,"clinical,assertion,ml,logreg",,,,,,,,,,,,
chunk_entity_resolver,ChunkEntityResolverApproach,ChunkEntityResolverModel,Entity Resolution model Based on KNN using Word Embeddings + Word Movers Distance,"token, chunk_embeddings",entity,licensed,,,"clinical,entity,resolution",,,,,,,,,,,,
deidentification,DeIdentification,DeIdentificationModel,Anonymization and DeIdentification model based on outputs from DeId NERs and Replacement Dictionaries,"document, token, chunk",document,licensed,,,"clinical,deidentification,rule based",,,,,,,,,,,,
relation_extraction,RelationExtractionApproach,RelationExtractionModel,Relation Extraction model based on syntactic features using deep learning,"word_embeddings, chunk, pos, dependency",category,licensed,,,"clinical,relation,extraction",,,,,,,,,,,,
default_chunker,,Chunker,This annotator matches a pattern of part-of-speech tags in order to return meaningful phrases from document. See https://nlu.johnsnowlabs.com/docs/en/examples#part-of-speech--pos as a frerence for all possible POS tags with examples,"document, pos",chunk,open source,,,"ner,named entity recognition, chunking ","[{'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['document', 'pos']"", 'param_setter_method': ""model.setInputCols(['document', 'pos'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'chunk', 'param_setter_method': ""model.setOutputCol('chunk')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'regexParsers', 'param_description': 'an array of grammar based chunk parsers', 'param_default_value': ""['<NN>+', '<PP>']"", 'param_setter_method': ""model.setRegexParsers(['<NN>+', '<PP>'])"", 'param_getter_method': 'model.getRegexParsers()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Chunker,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Chunker.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/ChunkerTestSpec.scala,,,,,,
ngram,,NGramGenerator,Integrates Spark ML NGram function into Spark ML with a new cumulative feature to also generate range ngrams like the scikit-learn library,"token, pos",ngrams,open source,,,"ngram, n-gramm, chunking,  shingel, ","[{'param_name': 'n', 'param_description': 'number elements per n-gram (>=1)', 'param_default_value': '2', 'param_setter_method': 'model.setN(2)', 'param_getter_method': 'model.getN()'}, {'param_name': 'enableCumulative', 'param_description': 'whether to calculate just the actual n-grams or all n-grams from 1 through n', 'param_default_value': 'False', 'param_setter_method': 'model.setEnableCumulative(False)', 'param_getter_method': 'model.getEnableCumulative()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token']"", 'param_setter_method': ""model.setInputCols(['token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'ngrams', 'param_setter_method': ""model.setOutputCol('ngrams')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.NGramGenerator,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/NGramGenerator.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/NGramGeneratorTestSpec.scala,,,,,,https://en.wikipedia.org/wiki/N-gram
classifier_dl,ClassifierDLApproach,ClassifierDLModel,Multi-class Text Classification. ClassifierDL uses the state-of-the-art Universal Sentence Encoder as an input for text classifications. The ClassifierDL annotator uses a deep learning model (DNNs) we have built inside TensorFlow and supports up to 100 classes,"sentence_embeddings, label",category,open source,,,"classification, deep learning","[{'param_name': 'classes', 'param_description': 'get the tags used to trained this NerDLModel', 'param_default_value': ""[' HUM', ' NUM', ' ENTY', ' LOC', ' DESC', ' ABBR']"", 'param_setter_method': ""model.setClasses([' HUM', ' NUM', ' ENTY', ' LOC', ' DESC', ' ABBR'])"", 'param_getter_method': 'model.getClasses()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence_embeddings']"", 'param_setter_method': ""model.setInputCols(['sentence_embeddings'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'category', 'param_setter_method': ""model.setOutputCol('category')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'tfhub_use', 'param_setter_method': ""model.setStorageRef('tfhub_use')"", 'param_getter_method': 'model.getStorageRef()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLTestSpec.scala,,,,,,
multi_classifier,MultiClassifierDLApproach,MultiClassifierDLModel,Multi-label Text Classification. MultiClassifierDL uses a Bidirectional GRU with Convolution model that we have built inside TensorFlow and supports up to 100 classes.,"sentence_embeddings, label",category,open source,,,"classification,multi class classification","[{'param_name': 'threshold', 'param_description': 'The minimum threshold for each label to be accepted. Default is 0.5', 'param_default_value': '0.5', 'param_setter_method': 'model.setThreshold(0.5)', 'param_getter_method': 'model.getThreshold()'}, {'param_name': 'classes', 'param_description': 'get the tags used to trained this NerDLModel', 'param_default_value': ""['toxic', 'severe_toxic', 'identity_hate', 'insult', 'obscene', 'threat']"", 'param_setter_method': ""model.setClasses(['toxic', 'severe_toxic', 'identity_hate', 'insult', 'obscene', 'threat'])"", 'param_getter_method': 'model.getClasses()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence_embeddings']"", 'param_setter_method': ""model.setInputCols(['sentence_embeddings'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'category', 'param_setter_method': ""model.setOutputCol('category')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'tfhub_use', 'param_setter_method': ""model.setStorageRef('tfhub_use')"", 'param_getter_method': 'model.getStorageRef()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLTestSpec.scala,,,,,,
sentiment_dl,SentimentDLApproach,SentimentDLModel,Multi-class Sentiment Analysis Annotator. SentimentDL is an annotator for multi-class sentiment analysis. This annotator comes with 2 available pre-trained models trained on IMDB and Twitter datasets,"sentence, label, sentence_embeddings",category,open source,,,"sentiment classification, sentiment, classification, deep learning","[{'param_name': 'threshold', 'param_description': 'The minimum threshold for the final result otheriwse it will be neutral', 'param_default_value': '0.6', 'param_setter_method': 'model.setThreshold(0.6)', 'param_getter_method': 'model.getThreshold()'}, {'param_name': 'thresholdLabel', 'param_description': 'In case the score is less than threshold, what should be the label. Default is neutral.', 'param_default_value': 'neutral', 'param_setter_method': ""model.setThresholdLabel('neutral')"", 'param_getter_method': 'model.getThresholdLabel()'}, {'param_name': 'classes', 'param_description': 'get the tags used to trained this NerDLModel', 'param_default_value': ""['positive', 'negative']"", 'param_setter_method': ""model.setClasses(['positive', 'negative'])"", 'param_getter_method': 'model.getClasses()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence_embeddings']"", 'param_setter_method': ""model.setInputCols(['sentence_embeddings'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'category', 'param_setter_method': ""model.setOutputCol('category')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'tfhub_use', 'param_setter_method': ""model.setStorageRef('tfhub_use')"", 'param_getter_method': 'model.getStorageRef()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.SentimentDLModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLTestSpec.scala,,,,,,
vivekn_sentiment,ViveknSentimentApproach,ViveknSentimentModel,Scores a sentence for a sentiment,"sentence, sentiment_label, token",sentiment,open source,,,"sentiment classification, sentiment, classification, vivekn sentiment, vivekn sentiment, classification","[{'param_name': 'featureLimit', 'param_description': 'content feature limit, to boost performance in very dirt text. Default disabled with -1', 'param_default_value': '-1', 'param_setter_method': 'model.setFeatureLimit(-1)', 'param_getter_method': 'model.getFeatureLimit()'}, {'param_name': 'importantFeatureRatio', 'param_description': 'proportion of feature content to be considered relevant. Defaults to 0.5', 'param_default_value': '0.5', 'param_setter_method': 'model.setImportantFeatureRatio(0.5)', 'param_getter_method': 'model.getImportantFeatureRatio()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence', 'token']"", 'param_setter_method': ""model.setInputCols(['sentence', 'token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'negative_totals', 'param_description': 'count of negative words', 'param_default_value': '149804', 'param_setter_method': 'model.setNegative_totals(149804)', 'param_getter_method': 'model.getNegative_totals()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'sentiment', 'param_setter_method': ""model.setOutputCol('sentiment')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'positive_totals', 'param_description': 'count of positive words', 'param_default_value': '149804', 'param_setter_method': 'model.setPositive_totals(149804)', 'param_getter_method': 'model.getPositive_totals()'}, {'param_name': 'unimportantFeatureStep', 'param_description': 'proportion to lookahead in unimportant features. Defaults to 0.025', 'param_default_value': '0.025', 'param_setter_method': 'model.setUnimportantFeatureStep(0.025)', 'param_getter_method': 'model.getUnimportantFeatureStep()'}]",https://github.com/vivekn/sentiment/,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentApproach,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel.scala,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/sda/vivekn,,,,,,
yake,,YakeModel,"Yake is an Unsupervised, Corpus-Independent, Domain and Language-Independent and Single-Document keyword extraction algorithm.",token,keywords,open source,,,"Keyword Extraction, Unsupervised, Corpus-Independent, Domain and Language-Independent keyword extraction algorithm. , ","[{'param_name': 'minNGrams', 'param_description': 'Minimum N-grams a keyword should have', 'param_default_value': '1', 'param_setter_method': 'model.setMinNGrams(1)', 'param_getter_method': 'model.getMinNGrams()'}, {'param_name': 'maxNGrams', 'param_description': 'Maximum N-grams a keyword should have', 'param_default_value': '3', 'param_setter_method': 'model.setMaxNGrams(3)', 'param_getter_method': 'model.getMaxNGrams()'}, {'param_name': 'nKeywords', 'param_description': 'Number of Keywords to extract', 'param_default_value': '3', 'param_setter_method': 'model.setNKeywords(3)', 'param_getter_method': 'model.getNKeywords()'}, {'param_name': 'windowSize', 'param_description': 'Window size for Co-Occurrence', 'param_default_value': '3', 'param_setter_method': 'model.setWindowSize(3)', 'param_getter_method': 'model.getWindowSize()'}, {'param_name': 'stopWords', 'param_description': ""the words to be filtered out. by default it's english stop words from Spark ML"", 'param_default_value': '[\'i\', \'me\', \'my\', \'myself\', \'we\', \'our\', \'ours\', \'ourselves\', \'you\', \'your\', \'yours\', \'yourself\', \'yourselves\', \'he\', \'him\', \'his\', \'himself\', \'she\', \'her\', \'hers\', \'herself\', \'it\', \'its\', \'itself\', \'they\', \'them\', \'their\', \'theirs\', \'themselves\', \'what\', \'which\', \'who\', \'whom\', \'this\', \'that\', \'these\', \'those\', \'am\', \'is\', \'are\', \'was\', \'were\', \'be\', \'been\', \'being\', \'have\', \'has\', \'had\', \'having\', \'do\', \'does\', \'did\', \'doing\', \'a\', \'an\', \'the\', \'and\', \'but\', \'if\', \'or\', \'because\', \'as\', \'until\', \'while\', \'of\', \'at\', \'by\', \'for\', \'with\', \'about\', \'against\', \'between\', \'into\', \'through\', \'during\', \'before\', \'after\', \'above\', \'below\', \'to\', \'from\', \'up\', \'down\', \'in\', \'out\', \'on\', \'off\', \'over\', \'under\', \'again\', \'further\', \'then\', \'once\', \'here\', \'there\', \'when\', \'where\', \'why\', \'how\', \'all\', \'any\', \'both\', \'each\', \'few\', \'more\', \'most\', \'other\', \'some\', \'such\', \'no\', \'nor\', \'not\', \'only\', \'own\', \'same\', \'so\', \'than\', \'too\', \'very\', \'s\', \'t\', \'can\', \'will\', \'just\', \'don\', \'should\', \'now\', ""i\'ll"", ""you\'ll"", ""he\'ll"", ""she\'ll"", ""we\'ll"", ""they\'ll"", ""i\'d"", ""you\'d"", ""he\'d"", ""she\'d"", ""we\'d"", ""they\'d"", ""i\'m"", ""you\'re"", ""he\'s"", ""she\'s"", ""it\'s"", ""we\'re"", ""they\'re"", ""i\'ve"", ""we\'ve"", ""you\'ve"", ""they\'ve"", ""isn\'t"", ""aren\'t"", ""wasn\'t"", ""weren\'t"", ""haven\'t"", ""hasn\'t"", ""hadn\'t"", ""don\'t"", ""doesn\'t"", ""didn\'t"", ""won\'t"", ""wouldn\'t"", ""shan\'t"", ""shouldn\'t"", ""mustn\'t"", ""can\'t"", ""couldn\'t"", \'cannot\', \'could\', ""here\'s"", ""how\'s"", ""let\'s"", \'ought\', ""that\'s"", ""there\'s"", ""what\'s"", ""when\'s"", ""where\'s"", ""who\'s"", ""why\'s"", \'would\']', 'param_setter_method': 'model.setStopWords([\'i\', \'me\', \'my\', \'myself\', \'we\', \'our\', \'ours\', \'ourselves\', \'you\', \'your\', \'yours\', \'yourself\', \'yourselves\', \'he\', \'him\', \'his\', \'himself\', \'she\', \'her\', \'hers\', \'herself\', \'it\', \'its\', \'itself\', \'they\', \'them\', \'their\', \'theirs\', \'themselves\', \'what\', \'which\', \'who\', \'whom\', \'this\', \'that\', \'these\', \'those\', \'am\', \'is\', \'are\', \'was\', \'were\', \'be\', \'been\', \'being\', \'have\', \'has\', \'had\', \'having\', \'do\', \'does\', \'did\', \'doing\', \'a\', \'an\', \'the\', \'and\', \'but\', \'if\', \'or\', \'because\', \'as\', \'until\', \'while\', \'of\', \'at\', \'by\', \'for\', \'with\', \'about\', \'against\', \'between\', \'into\', \'through\', \'during\', \'before\', \'after\', \'above\', \'below\', \'to\', \'from\', \'up\', \'down\', \'in\', \'out\', \'on\', \'off\', \'over\', \'under\', \'again\', \'further\', \'then\', \'once\', \'here\', \'there\', \'when\', \'where\', \'why\', \'how\', \'all\', \'any\', \'both\', \'each\', \'few\', \'more\', \'most\', \'other\', \'some\', \'such\', \'no\', \'nor\', \'not\', \'only\', \'own\', \'same\', \'so\', \'than\', \'too\', \'very\', \'s\', \'t\', \'can\', \'will\', \'just\', \'don\', \'should\', \'now\', ""i\'ll"", ""you\'ll"", ""he\'ll"", ""she\'ll"", ""we\'ll"", ""they\'ll"", ""i\'d"", ""you\'d"", ""he\'d"", ""she\'d"", ""we\'d"", ""they\'d"", ""i\'m"", ""you\'re"", ""he\'s"", ""she\'s"", ""it\'s"", ""we\'re"", ""they\'re"", ""i\'ve"", ""we\'ve"", ""you\'ve"", ""they\'ve"", ""isn\'t"", ""aren\'t"", ""wasn\'t"", ""weren\'t"", ""haven\'t"", ""hasn\'t"", ""hadn\'t"", ""don\'t"", ""doesn\'t"", ""didn\'t"", ""won\'t"", ""wouldn\'t"", ""shan\'t"", ""shouldn\'t"", ""mustn\'t"", ""can\'t"", ""couldn\'t"", \'cannot\', \'could\', ""here\'s"", ""how\'s"", ""let\'s"", \'ought\', ""that\'s"", ""there\'s"", ""what\'s"", ""when\'s"", ""where\'s"", ""who\'s"", ""why\'s"", \'would\'])', 'param_getter_method': 'model.getStopWords()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token']"", 'param_setter_method': ""model.setInputCols(['token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'keywords', 'param_setter_method': ""model.setOutputCol('keywords')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.keyword.yake.YakeModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/keyword.yake/YakeModel.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeTestSpec.scala,,,,,,
language_detector,,LanguageDetectorDL,LanguageDetectorDL is a state-of-the-art language detection and identification annotator trained by using TensorFlow/keras neural networks.,document,language,open source,,,"classification, deep learning,language classification,deep learning","[{'param_name': 'thresholdLabel', 'param_description': 'In case the score is less than threshold, what should be the label. Default is neutral.', 'param_default_value': 'Unknown', 'param_setter_method': ""model.setThresholdLabel('Unknown')"", 'param_getter_method': 'model.getThresholdLabel()'}, {'param_name': 'threshold', 'param_description': 'The minimum threshold for the final result otheriwse it will be either neutral or the value set in thresholdLabel.', 'param_default_value': '0.5', 'param_setter_method': 'model.setThreshold(0.5)', 'param_getter_method': 'model.getThreshold()'}, {'param_name': 'coalesceSentences', 'param_description': 'If sets to true the output of all sentences will be averaged to one output instead of one output per sentence. Default to false.', 'param_default_value': 'True', 'param_setter_method': 'model.setCoalesceSentences(True)', 'param_getter_method': 'model.getCoalesceSentences()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['document']"", 'param_setter_method': ""model.setInputCols(['document'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'language', 'param_setter_method': ""model.setOutputCol('language')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ld.dl.LanguageDetectorDL,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL.scala,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/ld/dl,,,,,,
named_entity_recognizer_dl,NerDLApproach,NerDLModel,"Named Entity recognition annotator allows for a generic model to be trained by utilizing a deep learning algorithm (Char CNNs - BiLSTM - CRF - word embeddings) inspired on a former state of the art model for NER: Chiu & Nicols, Named Entity Recognition with Bidirectional LSTM,CNN.","sentence, token, word_embeddings",ner,open source,,,"ner,named entity recognition, named entity classification, deep learning, Char CNN - BiLSTM – CRF, named entity, entity-extraction ","[{'param_name': 'includeConfidence', 'param_description': 'whether to include confidence scores in annotation metadata', 'param_default_value': 'False', 'param_setter_method': 'model.setIncludeConfidence(False)', 'param_getter_method': 'model.getIncludeConfidence()'}, {'param_name': 'batchSize', 'param_description': 'Size of every batch.', 'param_default_value': '32', 'param_setter_method': 'model.setBatchSize(32)', 'param_getter_method': 'model.getBatchSize()'}, {'param_name': 'classes', 'param_description': 'get the tags used to trained this NerDLModel', 'param_default_value': ""['O', 'I-PER', 'I-MISC', 'I-ORG', 'I-LOC', 'B-MISC', 'B-LOC', 'B-ORG']"", 'param_setter_method': ""model.setClasses(['O', 'I-PER', 'I-MISC', 'I-ORG', 'I-LOC', 'B-MISC', 'B-LOC', 'B-ORG'])"", 'param_getter_method': 'model.getClasses()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence', 'token', 'word_embeddings']"", 'param_setter_method': ""model.setInputCols(['sentence', 'token', 'word_embeddings'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'ner', 'param_setter_method': ""model.setOutputCol('ner')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'bert_base_cased', 'param_setter_method': ""model.setStorageRef('bert_base_cased')"", 'param_getter_method': 'model.getStorageRef()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/ner/dl,,,,,,
named_entity_recognizer_crf,NerCrfApproach,NerCrfModel,Named Entity recognition annotator allows for a generic model to be trained by CRF model,"sentence, token, pos, word_embeddings",ner,open source,,,"ner,named entity recognition, named entity classification, entity-extraction ","[{'param_name': 'includeConfidence', 'param_description': 'whether to include confidence scores in annotation metadata', 'param_default_value': 'False', 'param_setter_method': 'model.setIncludeConfidence(False)', 'param_getter_method': 'model.getIncludeConfidence()'}, {'param_name': 'batchSize', 'param_description': 'Size of every batch.', 'param_default_value': '32', 'param_setter_method': 'model.setBatchSize(32)', 'param_getter_method': 'model.getBatchSize()'}, {'param_name': 'classes', 'param_description': 'get the tags used to trained this NerDLModel', 'param_default_value': ""['O', 'I-PER', 'I-MISC', 'I-ORG', 'I-LOC', 'B-MISC', 'B-LOC', 'B-ORG']"", 'param_setter_method': ""model.setClasses(['O', 'I-PER', 'I-MISC', 'I-ORG', 'I-LOC', 'B-MISC', 'B-LOC', 'B-ORG'])"", 'param_getter_method': 'model.getClasses()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence', 'token', 'word_embeddings']"", 'param_setter_method': ""model.setInputCols(['sentence', 'token', 'word_embeddings'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'ner', 'param_setter_method': ""model.setOutputCol('ner')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'bert_base_cased', 'param_setter_method': ""model.setStorageRef('bert_base_cased')"", 'param_getter_method': 'model.getStorageRef()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/ner/dl,,,,,,
pos,PerceptronApproach,PerceptronModel,Sets a Part-Of-Speech tag to each word within a sentence.,"token, sentence",pos,open source,,,"pos, part of speech, part of speech classification,deep learning, part-of-speech-tagger","[{'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token', 'sentence']"", 'param_setter_method': ""model.setInputCols(['token', 'sentence'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'pos', 'param_setter_method': ""model.setOutputCol('pos')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron,,,,,,
unlabeled_dependency_parser,DependencyParserApproach,DependencyParserModel,Unlabeled parser that finds a grammatical relation between two words in a sentence,"document, pos, token",unlabeled_dependency,open source,,,"Untyped Dependency Parser, Unlabeled grammatical relation, Unlabeled Dependency Parser, Dependency Tree, Unlabeled Dependency Tree, Untyped Dependency Tree , Unlabeled Dependency Tree Parser, Untyped Dependency Tree Parser","[{'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['document', 'pos', 'token']"", 'param_setter_method': ""model.setInputCols(['document', 'pos', 'token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'dependency', 'param_setter_method': ""model.setOutputCol('dependency')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel.scala,,,,,,
labeled_dependency_parser,TypedDependencyParserApproach,TypedDependencyParserModel,Labeled parser that finds a grammatical relation between two words in a sentence,"unlabeled_dependency, pos, token",labled_dependency,open source,,,"Typed Dependency Parser, Labeled grammatical relation, Labeled Dependency Parser, Dependency Tree, Labeled Dependency Tree, Typed Dependency Tree , Labeled Dependency Tree Parser, Typed Dependency Tree Parser ,Typed Dependency Tree Classification,  Labeled Dependency Tree Classification ","[{'param_name': 'conllFormat', 'param_description': 'CoNLL Format', 'param_default_value': 'U', 'param_setter_method': ""model.setConllFormat('U')"", 'param_getter_method': 'model.getConllFormat()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token', 'pos', 'dependency']"", 'param_setter_method': ""model.setInputCols(['token', 'pos', 'dependency'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'labled_dependency', 'param_setter_method': ""model.setOutputCol('labled_dependency')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.parser.typdep.TypedDependencyParserModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel.scala,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/parser/typdep,,,,,,
bert,,BertEmbeddings,"BERT (Bidirectional Encoder Representations from Transformers) provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture","document, sentence, token",word_embeddings,open source,,,"Deep learning, BERT, BERT Embeddings, BERT Word Embeddings, Transformer, Bidirectional Encoder Representations from Transformers, Word Embeddings, Embeddings ","[{'param_name': 'batchSize', 'param_description': 'Batch size. Large values allows faster processing but requires more memory.', 'param_default_value': '32', 'param_setter_method': 'model.setBatchSize(32)', 'param_getter_method': 'model.getBatchSize()'}, {'param_name': 'maxSentenceLength', 'param_description': 'Max sentence length to process', 'param_default_value': '128', 'param_setter_method': 'model.setMaxSentenceLength(128)', 'param_getter_method': 'model.getMaxSentenceLength()'}, {'param_name': 'dimension', 'param_description': 'Number of embedding dimensions', 'param_default_value': '768', 'param_setter_method': 'model.setDimension(768)', 'param_getter_method': 'model.getDimension()'}, {'param_name': 'caseSensitive', 'param_description': 'whether to ignore case in tokens for embeddings matching', 'param_default_value': 'False', 'param_setter_method': 'model.setCaseSensitive(False)', 'param_getter_method': 'model.getCaseSensitive()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence', 'token']"", 'param_setter_method': ""model.setInputCols(['sentence', 'token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'bert', 'param_setter_method': ""model.setOutputCol('bert')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'small_bert_L2_768', 'param_setter_method': ""model.setStorageRef('small_bert_L2_768')"", 'param_getter_method': 'model.getStorageRef()'}]",,https://arxiv.org/abs/1810.04805,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddingsTestSpec.scala,,,,,,
albert,,AlbertEmbeddings,Computes contextualized word representations using “A Lite” implementation of BERT algorithm by applying parameter-reduction techniques,"document, sentence, token",word_embeddings,open source,,,"Deep learning, ALBERT, ALBERT Embeddings, ALBERT Word Embeddings, Transformer, Bidirectional Encoder Representations from Transformers, Word Embeddings, Embeddings ","[{'param_name': 'batchSize', 'param_description': 'Batch size. Large values allows faster processing but requires more memory.', 'param_default_value': '32', 'param_setter_method': 'model.setBatchSize(32)', 'param_getter_method': 'model.getBatchSize()'}, {'param_name': 'dimension', 'param_description': 'Number of embedding dimensions', 'param_default_value': '768', 'param_setter_method': 'model.setDimension(768)', 'param_getter_method': 'model.getDimension()'}, {'param_name': 'maxSentenceLength', 'param_description': 'Max sentence length to process', 'param_default_value': '128', 'param_setter_method': 'model.setMaxSentenceLength(128)', 'param_getter_method': 'model.getMaxSentenceLength()'}, {'param_name': 'caseSensitive', 'param_description': 'whether to ignore case in tokens for embeddings matching', 'param_default_value': 'False', 'param_setter_method': 'model.setCaseSensitive(False)', 'param_getter_method': 'model.getCaseSensitive()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence', 'token']"", 'param_setter_method': ""model.setInputCols(['sentence', 'token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'albert', 'param_setter_method': ""model.setOutputCol('albert')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'albert_base_uncased', 'param_setter_method': ""model.setStorageRef('albert_base_uncased')"", 'param_getter_method': 'model.getStorageRef()'}]",https://github.com/google-research/ALBERT,https://arxiv.org/pdf/1909.11942.pdf,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.AlbertEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddingsTestSpec.scala,,,,,,
glove,WordEmbeddings,WordEmbeddingsModel,Word Embeddings lookup annotator that maps tokens to vectors,"document, token",word_embeddings,open source,,,"Word Embeddings, Glove Embeddings, Word2Vec Embeddings","[{'param_name': 'includeStorage', 'param_description': 'whether to include indexed storage in trained model', 'param_default_value': 'True', 'param_setter_method': 'model.setIncludeStorage(True)', 'param_getter_method': 'model.getIncludeStorage()'}, {'param_name': 'caseSensitive', 'param_description': 'whether to ignore case in tokens for embeddings matching', 'param_default_value': 'False', 'param_setter_method': 'model.setCaseSensitive(False)', 'param_getter_method': 'model.getCaseSensitive()'}, {'param_name': 'dimension', 'param_description': 'Number of embedding dimensions', 'param_default_value': '100', 'param_setter_method': 'model.setDimension(100)', 'param_getter_method': 'model.getDimension()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['document', 'token']"", 'param_setter_method': ""model.setInputCols(['document', 'token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'glove_embeddings', 'param_setter_method': ""model.setOutputCol('glove_embeddings')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'glove_100d', 'param_setter_method': ""model.setStorageRef('glove_100d')"", 'param_getter_method': 'model.getStorageRef()'}]",,https://nlp.stanford.edu/pubs/glove.pdf,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.WordEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsTestSpec.scala,,,,,,
use,,UniversalSentenceEncoder,"Encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.","document, sentence",sentence_embeddings,open source,,,"Deep learning, Universal Sentence Encoder, Universal Sentence Encoder Embeddings, Universal Sentence Encoder Sentence Embeddings, Sentence Embeddings, Embeddings ","[{'param_name': 'dimension', 'param_description': 'Number of embedding dimensions', 'param_default_value': '512', 'param_setter_method': 'model.setDimension(512)', 'param_getter_method': 'model.getDimension()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence']"", 'param_setter_method': ""model.setInputCols(['sentence'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'use_embeddings', 'param_setter_method': ""model.setOutputCol('use_embeddings')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'tfhub_use', 'param_setter_method': ""model.setStorageRef('tfhub_use')"", 'param_getter_method': 'model.getStorageRef()'}]",https://tfhub.dev/google/universal-sentence-encoder/2,https://arxiv.org/abs/1803.11175,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoderTestSpec.scala,,,,,,
bert_sentence,,BertSentenceEmbeddings,This annotator generates sentence embeddings from all BERT models,document,bert_sentence_embeddings,open source,,,"Deep learning, BERT Sentence Encoder, BERT Sentence Encoder Embeddings, BERT Sentence Embeddings, Sentence Embeddings, Embeddings, BERT "," [{'param_name': 'batchSize', 'param_description': 'Batch size. Large values allows faster processing but requires more memory.', 'param_default_value': '32', 'param_setter_method': 'model.setBatchSize(32)', 'param_getter_method': 'model.getBatchSize()'}, {'param_name': 'maxSentenceLength', 'param_description': 'Max sentence length to process', 'param_default_value': '128', 'param_setter_method': 'model.setMaxSentenceLength(128)', 'param_getter_method': 'model.getMaxSentenceLength()'}, {'param_name': 'dimension', 'param_description': 'Number of embedding dimensions', 'param_default_value': '768', 'param_setter_method': 'model.setDimension(768)', 'param_getter_method': 'model.getDimension()'}, {'param_name': 'caseSensitive', 'param_description': 'whether to ignore case in tokens for embeddings matching', 'param_default_value': 'False', 'param_setter_method': 'model.setCaseSensitive(False)', 'param_getter_method': 'model.getCaseSensitive()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': """"['document']"""", 'param_setter_method': """"model.setInputCols(['document'])"""", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'bert_sentence', 'param_setter_method': """"model.setOutputCol('bert_sentence')"""", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'sent_small_bert_L2_768', 'param_setter_method': """"model.setStorageRef('sent_small_bert_L2_768')"""", 'param_getter_method': 'model.getStorageRef()'}]",https://github.com/google-research/bert,https://arxiv.org/abs/1810.04805,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddingsTestSpec.scala,,,,,,
elmo,,ElmoEmbeddings,Computes contextualized word representations using character-based word representations and bidirectional LSTMs,"document, sentence, token",word_embeddings,open source,,,"Deep learning, ELMO, ELMO Embeddings, ELMO Word Embeddings, Transformer,  Word Embeddings, Embeddings","[{'param_name': 'batchSize', 'param_description': 'Batch size. Large values allows faster processing but requires more memory.', 'param_default_value': '32', 'param_setter_method': 'model.setBatchSize(32)', 'param_getter_method': 'model.getBatchSize()'}, {'param_name': 'caseSensitive', 'param_description': 'whether to ignore case in tokens for embeddings matching', 'param_default_value': 'False', 'param_setter_method': 'model.setCaseSensitive(False)', 'param_getter_method': 'model.getCaseSensitive()'}, {'param_name': 'dimension', 'param_description': 'Number of embedding dimensions', 'param_default_value': '512', 'param_setter_method': 'model.setDimension(512)', 'param_getter_method': 'model.getDimension()'}, {'param_name': 'poolingLayer', 'param_description': 'Set ELMO pooling layer to: word_emb, lstm_outputs1, lstm_outputs2, or elmo', 'param_default_value': 'word_emb', 'param_setter_method': ""model.setPoolingLayer('word_emb')"", 'param_getter_method': 'model.getPoolingLayer()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence', 'token']"", 'param_setter_method': ""model.setInputCols(['sentence', 'token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'elmo', 'param_setter_method': ""model.setOutputCol('elmo')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'elmo', 'param_setter_method': ""model.setStorageRef('elmo')"", 'param_getter_method': 'model.getStorageRef()'}]",https://tfhub.dev/google/elmo/3,https://arxiv.org/abs/1802.05365,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.ElmoEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddingsTestSpec.scala,,,,,,
xlnet,,XlnetEmbeddings,Computes contextualized word representations using combination of Autoregressive Language Model and Permutation Language Model,"document, sentence, token",word_embeddings,open source,,,"Deep learning, XLNET, XLNET Embeddings, XLNET Word Embeddings, Transformer,  Word Embeddings, Embeddings ","[{'param_name': 'batchSize', 'param_description': 'Batch size. Large values allows faster processing but requires more memory.', 'param_default_value': '32', 'param_setter_method': 'model.setBatchSize(32)', 'param_getter_method': 'model.getBatchSize()'}, {'param_name': 'dimension', 'param_description': 'Number of embedding dimensions', 'param_default_value': '768', 'param_setter_method': 'model.setDimension(768)', 'param_getter_method': 'model.getDimension()'}, {'param_name': 'maxSentenceLength', 'param_description': 'Max sentence length to process', 'param_default_value': '128', 'param_setter_method': 'model.setMaxSentenceLength(128)', 'param_getter_method': 'model.getMaxSentenceLength()'}, {'param_name': 'caseSensitive', 'param_description': 'whether to ignore case in tokens for embeddings matching', 'param_default_value': 'True', 'param_setter_method': 'model.setCaseSensitive(True)', 'param_getter_method': 'model.getCaseSensitive()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['sentence', 'token']"", 'param_setter_method': ""model.setInputCols(['sentence', 'token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'xlnet_embeddings', 'param_setter_method': ""model.setOutputCol('xlnet_embeddings')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'storageRef', 'param_description': 'unique reference name for identification', 'param_default_value': 'xlnet_base_cased', 'param_setter_method': ""model.setStorageRef('xlnet_base_cased')"", 'param_getter_method': 'model.getStorageRef()'}]",https://github.com/zihangdai/xlnet,https://arxiv.org/abs/1906.08237,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.XlnetEmbeddings,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddingsTestSpec.scala,,,,,,
text_matcher,TextMatcher,TextMatcherModel,Annotator to match entire phrases (by token) provided in a file against a Document,"document, token",entity,open source,,,"text matcher, entity matcher, matcher, phrase matcher , string matcher , text filtering ","[{'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['document', 'token']"", 'param_setter_method': ""model.setInputCols(['document', 'token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'entity', 'param_setter_method': ""model.setOutputCol('entity')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.TextMatcherModel,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/TextMatcherModel.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/TextMatcherTestSpec.scala,,,,,,
date_matcher,,DateMatcher,Reads from different forms of date and time expressions and converts them to a provided date format. Extracts only ONE date per sentence. Use with sentence detector for more matches.,document,date,open source,,,"date matcher, date text matcher, matcher, date phrase matcher , date string matcher, text filtering  ","[{'param_name': 'dateFormat', 'param_description': 'desired format for dates extracted', 'param_default_value': 'yyyyMM', 'param_setter_method': ""model.setDateFormat('yyyyMM')"", 'param_getter_method': 'model.getDateFormat()'}, {'param_name': 'readMonthFirst', 'param_description': 'Whether to parse july 07/05/2015 or as 05/07/2015', 'param_default_value': 'True', 'param_setter_method': 'model.setReadMonthFirst(True)', 'param_getter_method': 'model.getReadMonthFirst()'}, {'param_name': 'defaultDayWhenMissing', 'param_description': 'which day to set when it is missing from parsed input', 'param_default_value': '1', 'param_setter_method': 'model.setDefaultDayWhenMissing(1)', 'param_getter_method': 'model.getDefaultDayWhenMissing()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['document']"", 'param_setter_method': ""model.setInputCols(['document'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'date', 'param_setter_method': ""model.setOutputCol('date')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.DateMatcher,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/DateMatcher.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/DateMatcherTestSpec.scala,,,,,,
regex_matcher,RegexMatcher,RegexMatcherModel,Uses a reference file to match a set of regular expressions and put them inside a provided key. File must be comma separated.,"document, token",regex_entity,open source,,,"regex matcher, regex text matcher, matcher, regex phrase matcher , regex string matcher , text filtering ","[{'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['document', 'token']"", 'param_setter_method': ""model.setInputCols(['document', 'token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'regex_entity', 'param_setter_method': ""model.setOutputCol('regex_entity')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.RegexMatcher,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/RegexMatcherModel.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/RegexMatcherTestSpec.scala,,,,,,
normalizer,Normalizer,NormalizerModel,Removes all dirty characters from text following a regex pattern and transforms words based on a provided dictionary,token,normalized,open source,,,"text cleaning , text preprocessing, dirty char removal, normalizing, text preprocessing","[{'param_name': 'cleanupPatterns', 'param_description': 'normalization regex patterns which match will be removed from token', 'param_default_value': ""['[^\\\\pL+]']"", 'param_setter_method': ""model.setCleanupPatterns(['[^\\\\pL+]'])"", 'param_getter_method': 'model.getCleanupPatterns()'}, {'param_name': 'lowercase', 'param_description': 'whether to convert strings to lowercase', 'param_default_value': 'False', 'param_setter_method': 'model.setLowercase(False)', 'param_getter_method': 'model.getLowercase()'}, {'param_name': 'slangMatchCase', 'param_description': 'whether or not to be case sensitive to match slangs. Defaults to false.', 'param_default_value': 'False', 'param_setter_method': 'model.setSlangMatchCase(False)', 'param_getter_method': 'model.getSlangMatchCase()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token']"", 'param_setter_method': ""model.setInputCols(['token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'normalized', 'param_setter_method': ""model.setOutputCol('normalized')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Normalizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/NormalizerModel.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/NormalizerTestSpec.scala,,,,,,
deep_sentence_detector,,DeepSentenceDetector,Finds sentence bounds in raw text using deep learning.,document,sentence,open source,,,"detector Deep Learning,sentence detector, sentence boundary detector, deep sentence detector, deep sentence boundary detector","[{'param_name': 'includesPragmaticSegmenter', 'param_description': 'Whether to include rule-based sentence detector as first filter', 'param_default_value': 'True', 'param_setter_method': 'model.setIncludesPragmaticSegmenter(True)', 'param_getter_method': 'model.getIncludesPragmaticSegmenter()'}, {'param_name': 'endPunctuation', 'param_description': 'An array of symbols that deep sentence detector will consider as end of sentence punctuation', 'param_default_value': ""['.', '?']"", 'param_setter_method': ""model.setEndPunctuation(['.', '?'])"", 'param_getter_method': 'model.getEndPunctuation()'}, {'param_name': 'explodeSentences', 'param_description': 'whether to explode each sentence into a different row, for better parallelization. Defaults to false.', 'param_default_value': 'False', 'param_setter_method': 'model.setExplodeSentences(False)', 'param_getter_method': 'model.getExplodeSentences()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['document', 'token', 'ner_chunk']"", 'param_setter_method': ""model.setInputCols(['document', 'token', 'ner_chunk'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'sentence', 'param_setter_method': ""model.setOutputCol('sentence')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.sbd.deep.DeepSentenceDetector,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sbd/deep/DeepSentenceDetector.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sbd/deep/DeepSentenceDetector.scala,,,,,,
sentence_detector,,SentenceDetector,Finds sentence bounds in raw text. Applies rules from Pragmatic Segmenter.,"document, token",sentence,open source,,,"detector ,sentence detector, sentence boundary detector","[{'param_name': 'useAbbreviations', 'param_description': 'whether to apply abbreviations at sentence detection', 'param_default_value': 'True', 'param_setter_method': 'model.setUseAbbreviations(True)', 'param_getter_method': 'model.getUseAbbreviations()'}, {'param_name': 'detectLists', 'param_description': 'whether detect lists during sentence detection', 'param_default_value': 'True', 'param_setter_method': 'model.setDetectLists(True)', 'param_getter_method': 'model.getDetectLists()'}, {'param_name': 'useCustomBoundsOnly', 'param_description': 'Only utilize custom bounds in sentence detection', 'param_default_value': 'False', 'param_setter_method': 'model.setUseCustomBoundsOnly(False)', 'param_getter_method': 'model.getUseCustomBoundsOnly()'}, {'param_name': 'customBounds', 'param_description': 'characters used to explicitly mark sentence bounds', 'param_default_value': '[]', 'param_setter_method': 'model.setCustomBounds([])', 'param_getter_method': 'model.getCustomBounds()'}, {'param_name': 'explodeSentences', 'param_description': 'whether to explode each sentence into a different row, for better parallelization. Defaults to false.', 'param_default_value': 'False', 'param_setter_method': 'model.setExplodeSentences(False)', 'param_getter_method': 'model.getExplodeSentences()'}, {'param_name': 'minLength', 'param_description': 'Set the minimum allowed length for each sentence.', 'param_default_value': '0', 'param_setter_method': 'model.setMinLength(0)', 'param_getter_method': 'model.getMinLength()'}, {'param_name': 'maxLength', 'param_description': 'Set the maximum allowed length for each sentence', 'param_default_value': '99999', 'param_setter_method': 'model.setMaxLength(99999)', 'param_getter_method': 'model.getMaxLength()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['document']"", 'param_setter_method': ""model.setInputCols(['document'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'sentence', 'param_setter_method': ""model.setOutputCol('sentence')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector.scala,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/sbd/pragmatic,,,,,,
context_spell,ContextSpellCheckerApproach,ContextSpellCheckerModel,Implements Noisy Channel Model Spell Algorithm. Correction candidates are extracted combining context information and word information,token,spell,open source,,,"context spell checker, Noisy Channel Model Algorithm, spell checker spell check ,spell checking , text preprocessing","[{'param_name': 'caseStrategy', 'param_description': 'What case combinations to try when generating candidates.', 'param_default_value': '2', 'param_setter_method': 'model.setCaseStrategy(2)', 'param_getter_method': 'model.getCaseStrategy()'}, {'param_name': 'compareLowcase', 'param_description': 'If true will compare tokens in low case with vocabulary', 'param_default_value': 'False', 'param_setter_method': 'model.setCompareLowcase(False)', 'param_getter_method': 'model.getCompareLowcase()'}, {'param_name': 'correctSymbols', 'param_description': 'Whether to correct special symbols or skip spell checking for them', 'param_default_value': 'False', 'param_setter_method': 'model.setCorrectSymbols(False)', 'param_getter_method': 'model.getCorrectSymbols()'}, {'param_name': 'gamma', 'param_description': 'Controls the influence of individual word frequency in the decision.', 'param_default_value': '120.0', 'param_setter_method': 'model.setGamma(120.0)', 'param_getter_method': 'model.getGamma()'}, {'param_name': 'maxCandidates', 'param_description': 'Maximum number of candidates for every word.', 'param_default_value': '6', 'param_setter_method': 'model.setMaxCandidates(6)', 'param_getter_method': 'model.getMaxCandidates()'}, {'param_name': 'maxWindowLen', 'param_description': 'Maximum size for the window used to remember history prior to every correction.', 'param_default_value': '5', 'param_setter_method': 'model.setMaxWindowLen(5)', 'param_getter_method': 'model.getMaxWindowLen()'}, {'param_name': 'trim', 'param_description': 'When set to true new lines will be treated as any other character, when set to false correction is applied on paragraphs as defined by newline characters.', 'param_default_value': 'False', 'param_setter_method': 'model.setTrim(False)', 'param_getter_method': 'model.getTrim()'}, {'param_name': 'errorThreshold', 'param_description': 'Threshold perplexity for a word to be considered as an error.', 'param_default_value': '7.0', 'param_setter_method': 'model.setErrorThreshold(7.0)', 'param_getter_method': 'model.getErrorThreshold()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token']"", 'param_setter_method': ""model.setInputCols(['token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'spell', 'param_setter_method': ""model.setOutputCol('spell')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'tradeoff', 'param_description': 'Tradeoff between the cost of a word error and a transition in the language model.', 'param_default_value': '8.0', 'param_setter_method': 'model.setTradeoff(8.0)', 'param_getter_method': 'model.getTradeoff()'}, {'param_name': 'wordMaxDistance', 'param_description': 'Maximum distance for the generated candidates for every word.', 'param_default_value': '3', 'param_setter_method': 'model.setWordMaxDistance(3)', 'param_getter_method': 'model.getWordMaxDistance()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.spell.context.ContextSpellCheckerModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/context,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/spell/context,,,,,,
norvig_spell,NorvigSweetingApproach,NorvigSweetingModel,This annotator retrieves tokens and makes corrections automatically if not found in an English dictionary,token,token,open source,,,"norvig spell,norvig spell checker, spell check, spell checking, text preprocessing","[{'param_name': 'caseSensitive', 'param_description': 'sensitivity on spell checking', 'param_default_value': 'True', 'param_setter_method': 'model.setCaseSensitive(True)', 'param_getter_method': 'model.getCaseSensitive()'}, {'param_name': 'doubleVariants', 'param_description': 'increase search at cost of performance', 'param_default_value': 'False', 'param_setter_method': 'model.setDoubleVariants(False)', 'param_getter_method': 'model.getDoubleVariants()'}, {'param_name': 'dupsLimit', 'param_description': 'maximum duplicate of characters in a word to consider. Defaults to 2', 'param_default_value': '2', 'param_setter_method': 'model.setDupsLimit(2)', 'param_getter_method': 'model.getDupsLimit()'}, {'param_name': 'frequencyPriority', 'param_description': 'applies frequency over hamming in intersections. When false hamming takes priority', 'param_default_value': 'True', 'param_setter_method': 'model.setFrequencyPriority(True)', 'param_getter_method': 'model.getFrequencyPriority()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token']"", 'param_setter_method': ""model.setInputCols(['token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'intersections', 'param_description': 'hamming intersections to attempt. Defaults to 10', 'param_default_value': '10', 'param_setter_method': 'model.setIntersections(10)', 'param_getter_method': 'model.getIntersections()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'checked', 'param_setter_method': ""model.setOutputCol('checked')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'reductLimit', 'param_description': 'word reductions limit. Defaults to 3', 'param_default_value': '3', 'param_setter_method': 'model.setReductLimit(3)', 'param_getter_method': 'model.getReductLimit()'}, {'param_name': 'shortCircuit', 'param_description': 'increase performance at cost of accuracy', 'param_default_value': 'False', 'param_setter_method': 'model.setShortCircuit(False)', 'param_getter_method': 'model.getShortCircuit()'}, {'param_name': 'vowelSwapLimit', 'param_description': 'vowel swap attempts. Defaults to 6', 'param_default_value': '6', 'param_setter_method': 'model.setVowelSwapLimit(6)', 'param_getter_method': 'model.getVowelSwapLimit()'}, {'param_name': 'wordSizeIgnore', 'param_description': 'minimum size of word before ignoring. Defaults to 3', 'param_default_value': '3', 'param_setter_method': 'model.setWordSizeIgnore(3)', 'param_getter_method': 'model.getWordSizeIgnore()'}]",https://github.com/wolfgarbe/SymSpell,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/norvig,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingTestSpec.scala,,,,,,
symmetric_spell,SymmetricDeleteApproach,SymmetricDeleteModel,This spell checker is inspired on Symmetric Delete algorithm. It retrieves tokens and utilizes distance metrics to compute possible derived words,token,spell,open source,,,"symmetric spell,symmetric spell checker, spell check, spell checking, text preprocessing ","[{'param_name': 'caseStrategy', 'param_description': 'What case combinations to try when generating candidates.', 'param_default_value': '2', 'param_setter_method': 'model.setCaseStrategy(2)', 'param_getter_method': 'model.getCaseStrategy()'}, {'param_name': 'compareLowcase', 'param_description': 'If true will compare tokens in low case with vocabulary', 'param_default_value': 'False', 'param_setter_method': 'model.setCompareLowcase(False)', 'param_getter_method': 'model.getCompareLowcase()'}, {'param_name': 'correctSymbols', 'param_description': 'Whether to correct special symbols or skip spell checking for them', 'param_default_value': 'False', 'param_setter_method': 'model.setCorrectSymbols(False)', 'param_getter_method': 'model.getCorrectSymbols()'}, {'param_name': 'gamma', 'param_description': 'Controls the influence of individual word frequency in the decision.', 'param_default_value': '120.0', 'param_setter_method': 'model.setGamma(120.0)', 'param_getter_method': 'model.getGamma()'}, {'param_name': 'maxCandidates', 'param_description': 'Maximum number of candidates for every word.', 'param_default_value': '6', 'param_setter_method': 'model.setMaxCandidates(6)', 'param_getter_method': 'model.getMaxCandidates()'}, {'param_name': 'maxWindowLen', 'param_description': 'Maximum size for the window used to remember history prior to every correction.', 'param_default_value': '5', 'param_setter_method': 'model.setMaxWindowLen(5)', 'param_getter_method': 'model.getMaxWindowLen()'}, {'param_name': 'trim', 'param_description': 'When set to true new lines will be treated as any other character, when set to false correction is applied on paragraphs as defined by newline characters.', 'param_default_value': 'False', 'param_setter_method': 'model.setTrim(False)', 'param_getter_method': 'model.getTrim()'}, {'param_name': 'errorThreshold', 'param_description': 'Threshold perplexity for a word to be considered as an error.', 'param_default_value': '7.0', 'param_setter_method': 'model.setErrorThreshold(7.0)', 'param_getter_method': 'model.getErrorThreshold()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token']"", 'param_setter_method': ""model.setInputCols(['token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'context_spell@auto_generated', 'param_setter_method': ""model.setOutputCol('context_spell@auto_generated')"", 'param_getter_method': 'model.getOutputCol()'}, {'param_name': 'tradeoff', 'param_description': 'Tradeoff between the cost of a word error and a transition in the language model.', 'param_default_value': '8.0', 'param_setter_method': 'model.setTradeoff(8.0)', 'param_getter_method': 'model.getTradeoff()'}, {'param_name': 'wordMaxDistance', 'param_description': 'Maximum distance for the generated candidates for every word.', 'param_default_value': '3', 'param_setter_method': 'model.setWordMaxDistance(3)', 'param_getter_method': 'model.getWordMaxDistance()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.spell.symmetric.SymmetricDeleteModel,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/symmetric,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/spell/symmetric,,,,,,
stemmer,,Stemmer,Returns hard-stems out of words with the objective of retrieving the meaningful part of the word,token,stem,open source,,,"stemmer, stemming, stemmwords, hard-stems, text preprocessing","[{'param_name': 'language', 'param_description': 'stemmer algorithm', 'param_default_value': 'english', 'param_setter_method': ""model.setLanguage('english')"", 'param_getter_method': 'model.getLanguage()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token']"", 'param_setter_method': ""model.setInputCols(['token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'stem', 'param_setter_method': ""model.setOutputCol('stem')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Stemmer,https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Stemmer.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/StemmerTestSpec.scala,,,,,,
stopwordcleaner,,StopWordsCleaner,"This annotator excludes from a sequence of strings (e.g. the output of a Tokenizer, Normalizer, Lemmatizer, and Stemmer) and drops all the stop words from the input sequences.",token,cleanTokens,open source,,,"stop words, stop words removal, stop words cleaning, text preprocessing, text cleaning","[{'param_name': 'locale', 'param_description': 'locale of the input. ignored when case sensitive is true', 'param_default_value': 'en_US', 'param_setter_method': ""model.setLocale('en_US')"", 'param_getter_method': 'model.getLocale()'}, {'param_name': 'stopWords', 'param_description': 'The words to be filtered out', 'param_default_value': '[\'a\', ""a\'s"", \'able\', \'about\', \'above\', \'according\', \'accordingly\', \'across\', \'actually\', \'after\', \'afterwards\', \'again\', \'against\', ""ain\'t"", \'all\', \'allow\', \'allows\', \'almost\', \'alone\', \'along\', \'already\', \'also\', \'although\', \'always\', \'am\', \'among\', \'amongst\', \'an\', \'and\', \'another\', \'any\', \'anybody\', \'anyhow\', \'anyone\', \'anything\', \'anyway\', \'anyways\', \'anywhere\', \'apart\', \'appear\', \'appreciate\', \'appropriate\', \'are\', ""aren\'t"", \'around\', \'as\', \'aside\', \'ask\', \'asking\', \'associated\', \'at\', \'available\', \'away\', \'awfully\', \'b\', \'be\', \'became\', \'because\', \'become\', \'becomes\', \'becoming\', \'been\', \'before\', \'beforehand\', \'behind\', \'being\', \'believe\', \'below\', \'beside\', \'besides\', \'best\', \'better\', \'between\', \'beyond\', \'both\', \'brief\', \'but\', \'by\', \'c\', ""c\'mon"", ""c\'s"", \'came\', \'can\', ""can\'t"", \'cannot\', \'cant\', \'cause\', \'causes\', \'certain\', \'certainly\', \'changes\', \'clearly\', \'co\', \'com\', \'come\', \'comes\', \'concerning\', \'consequently\', \'consider\', \'considering\', \'contain\', \'containing\', \'contains\', \'corresponding\', \'could\', ""couldn\'t"", \'course\', \'currently\', \'d\', \'definitely\', \'described\', \'despite\', \'did\', ""didn\'t"", \'different\', \'do\', \'does\', ""doesn\'t"", \'doing\', ""don\'t"", \'done\', \'down\', \'downwards\', \'during\', \'e\', \'each\', \'edu\', \'eg\', \'eight\', \'either\', \'else\', \'elsewhere\', \'enough\', \'entirely\', \'especially\', \'et\', \'etc\', \'even\', \'ever\', \'every\', \'everybody\', \'everyone\', \'everything\', \'everywhere\', \'ex\', \'exactly\', \'example\', \'except\', \'f\', \'far\', \'few\', \'fifth\', \'first\', \'five\', \'followed\', \'following\', \'follows\', \'for\', \'former\', \'formerly\', \'forth\', \'four\', \'from\', \'further\', \'furthermore\', \'g\', \'get\', \'gets\', \'getting\', \'given\', \'gives\', \'go\', \'goes\', \'going\', \'gone\', \'got\', \'gotten\', \'greetings\', \'h\', \'had\', ""hadn\'t"", \'happens\', \'hardly\', \'has\', ""hasn\'t"", \'have\', ""haven\'t"", \'having\', \'he\', ""he\'s"", \'hello\', \'help\', \'hence\', \'her\', \'here\', ""here\'s"", \'hereafter\', \'hereby\', \'herein\', \'hereupon\', \'hers\', \'herself\', \'hi\', \'him\', \'himself\', \'his\', \'hither\', \'hopefully\', \'how\', \'howbeit\', \'however\', \'i\', ""i\'d"", ""i\'ll"", ""i\'m"", ""i\'ve"", \'ie\', \'if\', \'ignored\', \'immediate\', \'in\', \'inasmuch\', \'inc\', \'indeed\', \'indicate\', \'indicated\', \'indicates\', \'inner\', \'insofar\', \'instead\', \'into\', \'inward\', \'is\', ""isn\'t"", \'it\', ""it\'d"", ""it\'ll"", ""it\'s"", \'its\', \'itself\', \'j\', \'just\', \'k\', \'keep\', \'keeps\', \'kept\', \'know\', \'knows\', \'known\', \'l\', \'last\', \'lately\', \'later\', \'latter\', \'latterly\', \'least\', \'less\', \'lest\', \'let\', ""let\'s"", \'like\', \'liked\', \'likely\', \'little\', \'look\', \'looking\', \'looks\', \'ltd\', \'m\', \'mainly\', \'many\', \'may\', \'maybe\', \'me\', \'mean\', \'meanwhile\', \'merely\', \'might\', \'more\', \'moreover\', \'most\', \'mostly\', \'much\', \'must\', \'my\', \'myself\', \'n\', \'name\', \'namely\', \'nd\', \'near\', \'nearly\', \'necessary\', \'need\', \'needs\', \'neither\', \'never\', \'nevertheless\', \'new\', \'next\', \'nine\', \'no\', \'nobody\', \'non\', \'none\', \'noone\', \'nor\', \'normally\', \'not\', \'nothing\', \'novel\', \'now\', \'nowhere\', \'o\', \'obviously\', \'of\', \'off\', \'often\', \'oh\', \'ok\', \'okay\', \'old\', \'on\', \'once\', \'one\', \'ones\', \'only\', \'onto\', \'or\', \'other\', \'others\', \'otherwise\', \'ought\', \'our\', \'ours\', \'ourselves\', \'out\', \'outside\', \'over\', \'overall\', \'own\', \'p\', \'particular\', \'particularly\', \'per\', \'perhaps\', \'placed\', \'please\', \'plus\', \'possible\', \'presumably\', \'probably\', \'provides\', \'q\', \'que\', \'quite\', \'qv\', \'r\', \'rather\', \'rd\', \'re\', \'really\', \'reasonably\', \'regarding\', \'regardless\', \'regards\', \'relatively\', \'respectively\', \'right\', \'s\', \'said\', \'same\', \'saw\', \'say\', \'saying\', \'says\', \'second\', \'secondly\', \'see\', \'seeing\', \'seem\', \'seemed\', \'seeming\', \'seems\', \'seen\', \'self\', \'selves\', \'sensible\', \'sent\', \'serious\', \'seriously\', \'seven\', \'several\', \'shall\', \'she\', \'should\', ""shouldn\'t"", \'since\', \'six\', \'so\', \'some\', \'somebody\', \'somehow\', \'someone\', \'something\', \'sometime\', \'sometimes\', \'somewhat\', \'somewhere\', \'soon\', \'sorry\', \'specified\', \'specify\', \'specifying\', \'still\', \'sub\', \'such\', \'sup\', \'sure\', \'t\', ""t\'s"", \'take\', \'taken\', \'tell\', \'tends\', \'th\', \'than\', \'thank\', \'thanks\', \'thanx\', \'that\', ""that\'s"", \'thats\', \'the\', \'their\', \'theirs\', \'them\', \'themselves\', \'then\', \'thence\', \'there\', ""there\'s"", \'thereafter\', \'thereby\', \'therefore\', \'therein\', \'theres\', \'thereupon\', \'these\', \'they\', ""they\'d"", ""they\'ll"", ""they\'re"", ""they\'ve"", \'think\', \'third\', \'this\', \'thorough\', \'thoroughly\', \'those\', \'though\', \'three\', \'through\', \'throughout\', \'thru\', \'thus\', \'to\', \'together\', \'too\', \'took\', \'toward\', \'towards\', \'tried\', \'tries\', \'truly\', \'try\', \'trying\', \'twice\', \'two\', \'u\', \'un\', \'under\', \'unfortunately\', \'unless\', \'unlikely\', \'until\', \'unto\', \'up\', \'upon\', \'us\', \'use\', \'used\', \'useful\', \'uses\', \'using\', \'usually\', \'uucp\', \'v\', \'value\', \'various\', \'very\', \'via\', \'viz\', \'vs\', \'w\', \'want\', \'wants\', \'was\', ""wasn\'t"", \'way\', \'we\', ""we\'d"", ""we\'ll"", ""we\'re"", ""we\'ve"", \'welcome\', \'well\', \'went\', \'were\', ""weren\'t"", \'what\', ""what\'s"", \'whatever\', \'when\', \'whence\', \'whenever\', \'where\', ""where\'s"", \'whereafter\', \'whereas\', \'whereby\', \'wherein\', \'whereupon\', \'wherever\', \'whether\', \'which\', \'while\', \'whither\', \'who\', ""who\'s"", \'whoever\', \'whole\', \'whom\', \'whose\', \'why\', \'will\', \'willing\', \'wish\', \'with\', \'within\', \'without\', ""won\'t"", \'wonder\', \'would\', \'would\', ""wouldn\'t"", \'x\', \'y\', \'yes\', \'yet\', \'you\', ""you\'d"", ""you\'ll"", ""you\'re"", ""you\'ve"", \'your\', \'yours\', \'yourself\', \'yourselves\', \'z\', \'zero\']', 'param_setter_method': 'model.setStopWords([\'a\', ""a\'s"", \'able\', \'about\', \'above\', \'according\', \'accordingly\', \'across\', \'actually\', \'after\', \'afterwards\', \'again\', \'against\', ""ain\'t"", \'all\', \'allow\', \'allows\', \'almost\', \'alone\', \'along\', \'already\', \'also\', \'although\', \'always\', \'am\', \'among\', \'amongst\', \'an\', \'and\', \'another\', \'any\', \'anybody\', \'anyhow\', \'anyone\', \'anything\', \'anyway\', \'anyways\', \'anywhere\', \'apart\', \'appear\', \'appreciate\', \'appropriate\', \'are\', ""aren\'t"", \'around\', \'as\', \'aside\', \'ask\', \'asking\', \'associated\', \'at\', \'available\', \'away\', \'awfully\', \'b\', \'be\', \'became\', \'because\', \'become\', \'becomes\', \'becoming\', \'been\', \'before\', \'beforehand\', \'behind\', \'being\', \'believe\', \'below\', \'beside\', \'besides\', \'best\', \'better\', \'between\', \'beyond\', \'both\', \'brief\', \'but\', \'by\', \'c\', ""c\'mon"", ""c\'s"", \'came\', \'can\', ""can\'t"", \'cannot\', \'cant\', \'cause\', \'causes\', \'certain\', \'certainly\', \'changes\', \'clearly\', \'co\', \'com\', \'come\', \'comes\', \'concerning\', \'consequently\', \'consider\', \'considering\', \'contain\', \'containing\', \'contains\', \'corresponding\', \'could\', ""couldn\'t"", \'course\', \'currently\', \'d\', \'definitely\', \'described\', \'despite\', \'did\', ""didn\'t"", \'different\', \'do\', \'does\', ""doesn\'t"", \'doing\', ""don\'t"", \'done\', \'down\', \'downwards\', \'during\', \'e\', \'each\', \'edu\', \'eg\', \'eight\', \'either\', \'else\', \'elsewhere\', \'enough\', \'entirely\', \'especially\', \'et\', \'etc\', \'even\', \'ever\', \'every\', \'everybody\', \'everyone\', \'everything\', \'everywhere\', \'ex\', \'exactly\', \'example\', \'except\', \'f\', \'far\', \'few\', \'fifth\', \'first\', \'five\', \'followed\', \'following\', \'follows\', \'for\', \'former\', \'formerly\', \'forth\', \'four\', \'from\', \'further\', \'furthermore\', \'g\', \'get\', \'gets\', \'getting\', \'given\', \'gives\', \'go\', \'goes\', \'going\', \'gone\', \'got\', \'gotten\', \'greetings\', \'h\', \'had\', ""hadn\'t"", \'happens\', \'hardly\', \'has\', ""hasn\'t"", \'have\', ""haven\'t"", \'having\', \'he\', ""he\'s"", \'hello\', \'help\', \'hence\', \'her\', \'here\', ""here\'s"", \'hereafter\', \'hereby\', \'herein\', \'hereupon\', \'hers\', \'herself\', \'hi\', \'him\', \'himself\', \'his\', \'hither\', \'hopefully\', \'how\', \'howbeit\', \'however\', \'i\', ""i\'d"", ""i\'ll"", ""i\'m"", ""i\'ve"", \'ie\', \'if\', \'ignored\', \'immediate\', \'in\', \'inasmuch\', \'inc\', \'indeed\', \'indicate\', \'indicated\', \'indicates\', \'inner\', \'insofar\', \'instead\', \'into\', \'inward\', \'is\', ""isn\'t"", \'it\', ""it\'d"", ""it\'ll"", ""it\'s"", \'its\', \'itself\', \'j\', \'just\', \'k\', \'keep\', \'keeps\', \'kept\', \'know\', \'knows\', \'known\', \'l\', \'last\', \'lately\', \'later\', \'latter\', \'latterly\', \'least\', \'less\', \'lest\', \'let\', ""let\'s"", \'like\', \'liked\', \'likely\', \'little\', \'look\', \'looking\', \'looks\', \'ltd\', \'m\', \'mainly\', \'many\', \'may\', \'maybe\', \'me\', \'mean\', \'meanwhile\', \'merely\', \'might\', \'more\', \'moreover\', \'most\', \'mostly\', \'much\', \'must\', \'my\', \'myself\', \'n\', \'name\', \'namely\', \'nd\', \'near\', \'nearly\', \'necessary\', \'need\', \'needs\', \'neither\', \'never\', \'nevertheless\', \'new\', \'next\', \'nine\', \'no\', \'nobody\', \'non\', \'none\', \'noone\', \'nor\', \'normally\', \'not\', \'nothing\', \'novel\', \'now\', \'nowhere\', \'o\', \'obviously\', \'of\', \'off\', \'often\', \'oh\', \'ok\', \'okay\', \'old\', \'on\', \'once\', \'one\', \'ones\', \'only\', \'onto\', \'or\', \'other\', \'others\', \'otherwise\', \'ought\', \'our\', \'ours\', \'ourselves\', \'out\', \'outside\', \'over\', \'overall\', \'own\', \'p\', \'particular\', \'particularly\', \'per\', \'perhaps\', \'placed\', \'please\', \'plus\', \'possible\', \'presumably\', \'probably\', \'provides\', \'q\', \'que\', \'quite\', \'qv\', \'r\', \'rather\', \'rd\', \'re\', \'really\', \'reasonably\', \'regarding\', \'regardless\', \'regards\', \'relatively\', \'respectively\', \'right\', \'s\', \'said\', \'same\', \'saw\', \'say\', \'saying\', \'says\', \'second\', \'secondly\', \'see\', \'seeing\', \'seem\', \'seemed\', \'seeming\', \'seems\', \'seen\', \'self\', \'selves\', \'sensible\', \'sent\', \'serious\', \'seriously\', \'seven\', \'several\', \'shall\', \'she\', \'should\', ""shouldn\'t"", \'since\', \'six\', \'so\', \'some\', \'somebody\', \'somehow\', \'someone\', \'something\', \'sometime\', \'sometimes\', \'somewhat\', \'somewhere\', \'soon\', \'sorry\', \'specified\', \'specify\', \'specifying\', \'still\', \'sub\', \'such\', \'sup\', \'sure\', \'t\', ""t\'s"", \'take\', \'taken\', \'tell\', \'tends\', \'th\', \'than\', \'thank\', \'thanks\', \'thanx\', \'that\', ""that\'s"", \'thats\', \'the\', \'their\', \'theirs\', \'them\', \'themselves\', \'then\', \'thence\', \'there\', ""there\'s"", \'thereafter\', \'thereby\', \'therefore\', \'therein\', \'theres\', \'thereupon\', \'these\', \'they\', ""they\'d"", ""they\'ll"", ""they\'re"", ""they\'ve"", \'think\', \'third\', \'this\', \'thorough\', \'thoroughly\', \'those\', \'though\', \'three\', \'through\', \'throughout\', \'thru\', \'thus\', \'to\', \'together\', \'too\', \'took\', \'toward\', \'towards\', \'tried\', \'tries\', \'truly\', \'try\', \'trying\', \'twice\', \'two\', \'u\', \'un\', \'under\', \'unfortunately\', \'unless\', \'unlikely\', \'until\', \'unto\', \'up\', \'upon\', \'us\', \'use\', \'used\', \'useful\', \'uses\', \'using\', \'usually\', \'uucp\', \'v\', \'value\', \'various\', \'very\', \'via\', \'viz\', \'vs\', \'w\', \'want\', \'wants\', \'was\', ""wasn\'t"", \'way\', \'we\', ""we\'d"", ""we\'ll"", ""we\'re"", ""we\'ve"", \'welcome\', \'well\', \'went\', \'were\', ""weren\'t"", \'what\', ""what\'s"", \'whatever\', \'when\', \'whence\', \'whenever\', \'where\', ""where\'s"", \'whereafter\', \'whereas\', \'whereby\', \'wherein\', \'whereupon\', \'wherever\', \'whether\', \'which\', \'while\', \'whither\', \'who\', ""who\'s"", \'whoever\', \'whole\', \'whom\', \'whose\', \'why\', \'will\', \'willing\', \'wish\', \'with\', \'within\', \'without\', ""won\'t"", \'wonder\', \'would\', \'would\', ""wouldn\'t"", \'x\', \'y\', \'yes\', \'yet\', \'you\', ""you\'d"", ""you\'ll"", ""you\'re"", ""you\'ve"", \'your\', \'yours\', \'yourself\', \'yourselves\', \'z\', \'zero\'])', 'param_getter_method': 'model.getStopWords()'}, {'param_name': 'caseSensitive', 'param_description': 'whether to do a case sensitive comparison over the stop words', 'param_default_value': 'False', 'param_setter_method': 'model.setCaseSensitive(False)', 'param_getter_method': 'model.getCaseSensitive()'}, {'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token']"", 'param_setter_method': ""model.setInputCols(['token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'cleanTokens', 'param_setter_method': ""model.setOutputCol('cleanTokens')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleanerTestSpec.scala,,,,,,
lemmatizer,Lemmatizer,LemmatizerModel,Class to find standardized lemmas from words. Uses a user-provided or default dictionary.  Retrieves lemmas out of words with the objective of returning a base dictionary word. Retrieves the significant part of a word.  ,token,lemma,open source,,,"lemmatizer, lemmatizing, lemma, word lemma, text preprocessing","[{'param_name': 'inputCols', 'param_description': 'previous annotations columns, if renamed', 'param_default_value': ""['token']"", 'param_setter_method': ""model.setInputCols(['token'])"", 'param_getter_method': 'model.getInputCols()'}, {'param_name': 'outputCol', 'param_description': 'output annotation column. can be left default.', 'param_default_value': 'lemma', 'param_setter_method': ""model.setOutputCol('lemma')"", 'param_getter_method': 'model.getOutputCol()'}]",,,https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala,https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/LemmatizerTestSpec.scala,,,,,,
