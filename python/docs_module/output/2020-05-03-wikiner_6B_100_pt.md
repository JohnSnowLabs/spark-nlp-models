---
layout: model
title: WikiNER 6B 100
author: John Snow Labs
name: wikiner_6B_100
class: NerDLModel
language: pt
repository: public/models
date: 03/05/2020
tags: [ner]
article_header:
   type: cover
use_language_switcher: "Python-Scala-Java"
---

{:.h2_title}
## Description 
WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 100 is trained with GloVe 6B 100 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/public/NER_PT){:.button.button-orange}<br/>[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}<br/>[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_100_pt_2.5.0_2.4_1588495233192.zip){:.button.button-orange.button-orange-trans.arr.button-icon}<br/>

## How to use 
<div class="tabs-box" markdown="1">

{% include programmingLanguageSelectScalaPython.html %}

```python

    embeddings = WordEmbeddingsModel.pretrained(glove_100d, lang=en)
    embeddings.setInputCols(["sentence", 'token'])
    embeddings.setOutputCol("embeddings")

    ner = NerDLModel.pretrained(wikiner_6B_100, lang=pt)
    ner.setInputCols(["sentence", "token", "embeddings"])
    ner.setOutputCol("ner")

    ner_converter = NerConverter()
    ner_converter.setInputCols(["sentence", "token", "ner"])
    ner_converter.setOutputCol("ner_chunk")
                      
    pipeline = Pipeline(stages=[ documentAssembler, 
                                    sentenceDetector,
                                    tokenizer,
                                    embeddings,
                                    ner,
                                    ner_converter
                                     ])
    
    pipeline_model = pipeline.fit(spark.createDataFrame([['']]).toDF("text"))
    lmodel = LightPipeline(pipeline_model)
    
    result = lmodel.fullAnnotate("A Mona Lisa é uma pintura a óleo do século 16 criada por Leonardo. É realizado no Louvre, em Paris.")[0]
    
```

```scala

```
</div>

{:.h2_title}
## Results
```bash
+-------------+---------+-------+----------+
| ner_chunk   |   begin |   end | entity   |
+=============+=========+=======+==========+
| Mona Lisa   |       2 |    10 | PER      |
+-------------+---------+-------+----------+
| Leonardo    |      57 |    64 | PER      |
+-------------+---------+-------+----------+
| Louvre      |      82 |    87 | LOC      |
+-------------+---------+-------+----------+
| Paris       |      93 |    97 | LOC      |
+-------------+---------+-------+----------+
```

{:.model-param}
## Model Information

{:.table-model}
|-------------------------|----------------|
| Model Name              | wikiner_6B_100 |
| Model Class             | NerDLModel     |
| Spark Compatibility     | 2.5.0          |
| Spark NLP Compatibility | 2.4            |
| License                 | open source    |
| Edition                 | public         |
| Input Labels            |                |
| Output Labels           |                |
| Language                | pt             |
| Dimension               |                |
| Case Sensitive          | 0.0            |
| Upstream Dependencies   | glove_100d     |




{:.h2_title}
## Data Source

The model was trained based on data from [https://pt.wikipedia.org](https://pt.wikipedia.org)

