---
layout: model
title: WikiNER 6B 300
author: John Snow Labs
name: wikiner_6B_300
class: NerDLModel
language: es
repository: public/models
date: 17/02/2020
tags: [ner]
article_header:
   type: cover
use_language_switcher: "Python-Scala-Java"
---

{:.h2_title}
## Description 
WikiNER is a Named Entity Recognition (or NER) model, meaning it annotates text to find features like the names of people, places, and organizations. This NER model does not read words directly but instead reads word embeddings, which represent words as points such that more semantically similar words are closer together. WikiNER 6B 300 is trained with GloVe 6B 300 word embeddings, so be sure to use the same embeddings in the pipeline.



{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/public/NER_ES){:.button.button-orange}<br/>[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_ES.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}<br/>[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/wikiner_6B_300_es_2.4.0_2.4_1581971942090.zip){:.button.button-orange.button-orange-trans.arr.button-icon}<br/>

## How to use 
<div class="tabs-box" markdown="1">

{% include programmingLanguageSelectScalaPython.html %}

```python

    embeddings = WordEmbeddingsModel.pretrained(glove_6B_300, lang=xx)
    embeddings.setInputCols(["sentence", 'token'])
    embeddings.setOutputCol("embeddings")

    ner = NerDLModel.pretrained(wikiner_6B_300, lang=es)
    ner.setInputCols(["sentence", "token", "embeddings"])
    ner.setOutputCol("ner")

    ner_converter = NerConverter()
    ner_converter.setInputCols(["sentence", "token", "ner"])
    ner_converter.setOutputCol("ner_chunk")
                      
    pipeline = Pipeline(stages=[ documentAssembler, 
                                    sentenceDetector,
                                    tokenizer,
                                    embeddings,
                                    ner,
                                    ner_converter
                                     ])
    
    pipeline_model = pipeline.fit(spark.createDataFrame([['']]).toDF("text"))
    lmodel = LightPipeline(pipeline_model)
    
    result = lmodel.fullAnnotate("La Mona Lisa es una pintura al óleo del siglo XVI creada por Leonardo. Se lleva a cabo en el Louvre de París.")[0]
    
```

```scala

```
</div>

{:.h2_title}
## Results
```bash
+-----------------+---------+-------+----------+
| ner_chunk       |   begin |   end | entity   |
+=================+=========+=======+==========+
| La Mona Lisa    |       0 |    11 | PER      |
+-----------------+---------+-------+----------+
| Leonardo        |      61 |    68 | PER      |
+-----------------+---------+-------+----------+
| Louvre de París |      93 |   107 | LOC      |
+-----------------+---------+-------+----------+
```

{:.model-param}
## Model Information

{:.table-model}
|-------------------------|----------------|
| Model Name              | wikiner_6B_300 |
| Model Class             | NerDLModel     |
| Spark Compatibility     | 2.4.0          |
| Spark NLP Compatibility | 2.4            |
| License                 | open source    |
| Edition                 | public         |
| Input Labels            |                |
| Output Labels           |                |
| Language                | es             |
| Dimension               |                |
| Case Sensitive          | 0.0            |
| Upstream Dependencies   | glove_6B_300   |




{:.h2_title}
## Data Source

The model is trained based on data from [https://es.wikipedia.org](https://es.wikipedia.org)

