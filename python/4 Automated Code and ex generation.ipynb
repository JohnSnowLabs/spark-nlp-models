{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from jinja2 import Environment, PackageLoader, select_autoescape, meta\n",
    "import pandas as pd, boto3, re, pytz, numpy as np\n",
    "from datetime import datetime\n",
    "from tabulate import tabulate\n",
    "from sparknlp.base import *\n",
    "from sparknlp.pretrained import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "pd.set_option(\"display.max_rows\",1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_models_meta = pd.read_csv(\"docs_module/metadata/models_metadata_all.csv\")\n",
    "all_classes_meta = pd.read_csv(\"docs_module/metadata/class_metadata_all.csv\")\n",
    "#full_meta = pd.merge(all_models_meta[all_models_meta.include==1], all_classes_meta, on=\"Model Class\", how=(\"left\"), suffixes=(\"\",\"class\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>approach_class</th>\n",
       "      <th>Model Class</th>\n",
       "      <th>class_description</th>\n",
       "      <th>Input Labels</th>\n",
       "      <th>Output Labels</th>\n",
       "      <th>class_license</th>\n",
       "      <th>dataset_schema</th>\n",
       "      <th>class_annotation_sample</th>\n",
       "      <th>tags</th>\n",
       "      <th>class_parameters</th>\n",
       "      <th>reference_url</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>scala_docs</th>\n",
       "      <th>scala_source</th>\n",
       "      <th>scala_source_tests</th>\n",
       "      <th>evaluator_class</th>\n",
       "      <th>paper_abstract</th>\n",
       "      <th>scala_nlp_code</th>\n",
       "      <th>python_nlp_code</th>\n",
       "      <th>python_nlu_code</th>\n",
       "      <th>wikipedia_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assertion_dl</td>\n",
       "      <td>AssertionDLApproach</td>\n",
       "      <td>AssertionDLModel</td>\n",
       "      <td>Assertion of Clinical Entities based on Deep L...</td>\n",
       "      <td>document, chunk, word_embeddings</td>\n",
       "      <td>assertion</td>\n",
       "      <td>licensed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clinical,assertion,dl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assertion_logreg</td>\n",
       "      <td>AssertionLogRegApproach</td>\n",
       "      <td>AssertionLogRegModel</td>\n",
       "      <td>Assertion of Clinical Entities based on Logist...</td>\n",
       "      <td>document, chunk, word_embeddings</td>\n",
       "      <td>assertion</td>\n",
       "      <td>licensed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clinical,assertion,ml,logreg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chunk_entity_resolver</td>\n",
       "      <td>ChunkEntityResolverApproach</td>\n",
       "      <td>ChunkEntityResolverModel</td>\n",
       "      <td>Entity Resolution model Based on KNN using Wor...</td>\n",
       "      <td>token, chunk_embeddings</td>\n",
       "      <td>entity</td>\n",
       "      <td>licensed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clinical,entity,resolution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deidentification</td>\n",
       "      <td>DeIdentification</td>\n",
       "      <td>DeIdentificationModel</td>\n",
       "      <td>Anonymization and DeIdentification model based...</td>\n",
       "      <td>document, token, chunk</td>\n",
       "      <td>document</td>\n",
       "      <td>licensed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clinical,deidentification,rule based</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relation_extraction</td>\n",
       "      <td>RelationExtractionApproach</td>\n",
       "      <td>RelationExtractionModel</td>\n",
       "      <td>Relation Extraction model based on syntactic f...</td>\n",
       "      <td>word_embeddings, chunk, pos, dependency</td>\n",
       "      <td>category</td>\n",
       "      <td>licensed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clinical,relation,extraction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>default_chunker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chunker</td>\n",
       "      <td>This annotator matches a pattern of part-of-sp...</td>\n",
       "      <td>document, pos</td>\n",
       "      <td>chunk</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ner,named entity recognition, chunking</td>\n",
       "      <td>[{'param_name': 'inputCols', 'param_descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ngram</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NGramGenerator</td>\n",
       "      <td>Integrates Spark ML NGram function into Spark ...</td>\n",
       "      <td>token, pos</td>\n",
       "      <td>ngrams</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ngram, n-gramm, chunking,  shingel,</td>\n",
       "      <td>[{'param_name': 'n', 'param_description': 'num...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/N-gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>classifier_dl</td>\n",
       "      <td>ClassifierDLApproach</td>\n",
       "      <td>ClassifierDLModel</td>\n",
       "      <td>Multi-class Text Classification. ClassifierDL ...</td>\n",
       "      <td>sentence_embeddings, label</td>\n",
       "      <td>category</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classification, deep learning</td>\n",
       "      <td>[{'param_name': 'classes', 'param_description'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multi_classifier</td>\n",
       "      <td>MultiClassifierDLApproach</td>\n",
       "      <td>MultiClassifierDLModel</td>\n",
       "      <td>Multi-label Text Classification. MultiClassifi...</td>\n",
       "      <td>sentence_embeddings, label</td>\n",
       "      <td>category</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classification,multi class classification</td>\n",
       "      <td>[{'param_name': 'threshold', 'param_descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sentiment_dl</td>\n",
       "      <td>SentimentDLApproach</td>\n",
       "      <td>SentimentDLModel</td>\n",
       "      <td>Multi-class Sentiment Analysis Annotator. Sent...</td>\n",
       "      <td>sentence, label, sentence_embeddings</td>\n",
       "      <td>category</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentiment classification, sentiment, classific...</td>\n",
       "      <td>[{'param_name': 'threshold', 'param_descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vivekn_sentiment</td>\n",
       "      <td>ViveknSentimentApproach</td>\n",
       "      <td>ViveknSentimentModel</td>\n",
       "      <td>Scores a sentence for a sentiment</td>\n",
       "      <td>sentence, sentiment_label, token</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sentiment classification, sentiment, classific...</td>\n",
       "      <td>[{'param_name': 'featureLimit', 'param_descrip...</td>\n",
       "      <td>https://github.com/vivekn/sentiment/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YakeModel</td>\n",
       "      <td>Yake is an Unsupervised, Corpus-Independent, D...</td>\n",
       "      <td>token</td>\n",
       "      <td>keywords</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keyword Extraction, Unsupervised, Corpus-Indep...</td>\n",
       "      <td>[{'param_name': 'minNGrams', 'param_descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>language_detector</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LanguageDetectorDL</td>\n",
       "      <td>LanguageDetectorDL is a state-of-the-art langu...</td>\n",
       "      <td>document</td>\n",
       "      <td>language</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classification, deep learning,language classif...</td>\n",
       "      <td>[{'param_name': 'thresholdLabel', 'param_descr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>named_entity_recognizer_dl</td>\n",
       "      <td>NerDLApproach</td>\n",
       "      <td>NerDLModel</td>\n",
       "      <td>Named Entity recognition annotator allows for ...</td>\n",
       "      <td>sentence, token, word_embeddings</td>\n",
       "      <td>ner</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ner,named entity recognition, named entity cla...</td>\n",
       "      <td>[{'param_name': 'includeConfidence', 'param_de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>named_entity_recognizer_crf</td>\n",
       "      <td>NerCrfApproach</td>\n",
       "      <td>NerCrfModel</td>\n",
       "      <td>Named Entity recognition annotator allows for ...</td>\n",
       "      <td>sentence, token, pos, word_embeddings</td>\n",
       "      <td>ner</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ner,named entity recognition, named entity cla...</td>\n",
       "      <td>[{'param_name': 'includeConfidence', 'param_de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pos</td>\n",
       "      <td>PerceptronApproach</td>\n",
       "      <td>PerceptronModel</td>\n",
       "      <td>Sets a Part-Of-Speech tag to each word within ...</td>\n",
       "      <td>token, sentence</td>\n",
       "      <td>pos</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos, part of speech, part of speech classifica...</td>\n",
       "      <td>[{'param_name': 'inputCols', 'param_descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unlabeled_dependency_parser</td>\n",
       "      <td>DependencyParserApproach</td>\n",
       "      <td>DependencyParserModel</td>\n",
       "      <td>Unlabeled parser that finds a grammatical rela...</td>\n",
       "      <td>document, pos, token</td>\n",
       "      <td>unlabeled_dependency</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Untyped Dependency Parser, Unlabeled grammatic...</td>\n",
       "      <td>[{'param_name': 'inputCols', 'param_descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>labeled_dependency_parser</td>\n",
       "      <td>TypedDependencyParserApproach</td>\n",
       "      <td>TypedDependencyParserModel</td>\n",
       "      <td>Labeled parser that finds a grammatical relati...</td>\n",
       "      <td>unlabeled_dependency, pos, token</td>\n",
       "      <td>labled_dependency</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typed Dependency Parser, Labeled grammatical r...</td>\n",
       "      <td>[{'param_name': 'conllFormat', 'param_descript...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BertEmbeddings</td>\n",
       "      <td>BERT (Bidirectional Encoder Representations fr...</td>\n",
       "      <td>document, sentence, token</td>\n",
       "      <td>word_embeddings</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep learning, BERT, BERT Embeddings, BERT Wor...</td>\n",
       "      <td>[{'param_name': 'batchSize', 'param_descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arxiv.org/abs/1810.04805</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>albert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AlbertEmbeddings</td>\n",
       "      <td>Computes contextualized word representations u...</td>\n",
       "      <td>document, sentence, token</td>\n",
       "      <td>word_embeddings</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep learning, ALBERT, ALBERT Embeddings, ALBE...</td>\n",
       "      <td>[{'param_name': 'batchSize', 'param_descriptio...</td>\n",
       "      <td>https://github.com/google-research/ALBERT</td>\n",
       "      <td>https://arxiv.org/pdf/1909.11942.pdf</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>glove</td>\n",
       "      <td>WordEmbeddings</td>\n",
       "      <td>WordEmbeddingsModel</td>\n",
       "      <td>Word Embeddings lookup annotator that maps tok...</td>\n",
       "      <td>document, token</td>\n",
       "      <td>word_embeddings</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Word Embeddings, Glove Embeddings, Word2Vec Em...</td>\n",
       "      <td>[{'param_name': 'includeStorage', 'param_descr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.stanford.edu/pubs/glove.pdf</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UniversalSentenceEncoder</td>\n",
       "      <td>Encodes text into high dimensional vectors tha...</td>\n",
       "      <td>document, sentence</td>\n",
       "      <td>sentence_embeddings</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep learning, Universal Sentence Encoder, Uni...</td>\n",
       "      <td>[{'param_name': 'dimension', 'param_descriptio...</td>\n",
       "      <td>https://tfhub.dev/google/universal-sentence-en...</td>\n",
       "      <td>https://arxiv.org/abs/1803.11175</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bert_sentence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BertSentenceEmbeddings</td>\n",
       "      <td>This annotator generates sentence embeddings f...</td>\n",
       "      <td>document</td>\n",
       "      <td>bert_sentence_embeddings</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep learning, BERT Sentence Encoder, BERT Sen...</td>\n",
       "      <td>[{'param_name': 'batchSize', 'param_descripti...</td>\n",
       "      <td>https://github.com/google-research/bert</td>\n",
       "      <td>https://arxiv.org/abs/1810.04805</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>elmo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ElmoEmbeddings</td>\n",
       "      <td>Computes contextualized word representations u...</td>\n",
       "      <td>document, sentence, token</td>\n",
       "      <td>word_embeddings</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep learning, ELMO, ELMO Embeddings, ELMO Wor...</td>\n",
       "      <td>[{'param_name': 'batchSize', 'param_descriptio...</td>\n",
       "      <td>https://tfhub.dev/google/elmo/3</td>\n",
       "      <td>https://arxiv.org/abs/1802.05365</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XlnetEmbeddings</td>\n",
       "      <td>Computes contextualized word representations u...</td>\n",
       "      <td>document, sentence, token</td>\n",
       "      <td>word_embeddings</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep learning, XLNET, XLNET Embeddings, XLNET ...</td>\n",
       "      <td>[{'param_name': 'batchSize', 'param_descriptio...</td>\n",
       "      <td>https://github.com/zihangdai/xlnet</td>\n",
       "      <td>https://arxiv.org/abs/1906.08237</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>text_matcher</td>\n",
       "      <td>TextMatcher</td>\n",
       "      <td>TextMatcherModel</td>\n",
       "      <td>Annotator to match entire phrases (by token) p...</td>\n",
       "      <td>document, token</td>\n",
       "      <td>entity</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text matcher, entity matcher, matcher, phrase ...</td>\n",
       "      <td>[{'param_name': 'inputCols', 'param_descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>date_matcher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DateMatcher</td>\n",
       "      <td>Reads from different forms of date and time ex...</td>\n",
       "      <td>document</td>\n",
       "      <td>date</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>date matcher, date text matcher, matcher, date...</td>\n",
       "      <td>[{'param_name': 'dateFormat', 'param_descripti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>regex_matcher</td>\n",
       "      <td>RegexMatcher</td>\n",
       "      <td>RegexMatcherModel</td>\n",
       "      <td>Uses a reference file to match a set of regula...</td>\n",
       "      <td>document, token</td>\n",
       "      <td>regex_entity</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>regex matcher, regex text matcher, matcher, re...</td>\n",
       "      <td>[{'param_name': 'inputCols', 'param_descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>normalizer</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>NormalizerModel</td>\n",
       "      <td>Removes all dirty characters from text followi...</td>\n",
       "      <td>token</td>\n",
       "      <td>normalized</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text cleaning , text preprocessing, dirty char...</td>\n",
       "      <td>[{'param_name': 'cleanupPatterns', 'param_desc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>deep_sentence_detector</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeepSentenceDetector</td>\n",
       "      <td>Finds sentence bounds in raw text using deep l...</td>\n",
       "      <td>document</td>\n",
       "      <td>sentence</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>detector Deep Learning,sentence detector, sent...</td>\n",
       "      <td>[{'param_name': 'includesPragmaticSegmenter', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sentence_detector</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SentenceDetector</td>\n",
       "      <td>Finds sentence bounds in raw text. Applies rul...</td>\n",
       "      <td>document, token</td>\n",
       "      <td>sentence</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>detector ,sentence detector, sentence boundary...</td>\n",
       "      <td>[{'param_name': 'useAbbreviations', 'param_des...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>context_spell</td>\n",
       "      <td>ContextSpellCheckerApproach</td>\n",
       "      <td>ContextSpellCheckerModel</td>\n",
       "      <td>Implements Noisy Channel Model Spell Algorithm...</td>\n",
       "      <td>token</td>\n",
       "      <td>spell</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>context spell checker, Noisy Channel Model Alg...</td>\n",
       "      <td>[{'param_name': 'caseStrategy', 'param_descrip...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>norvig_spell</td>\n",
       "      <td>NorvigSweetingApproach</td>\n",
       "      <td>NorvigSweetingModel</td>\n",
       "      <td>This annotator retrieves tokens and makes corr...</td>\n",
       "      <td>token</td>\n",
       "      <td>token</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>norvig spell,norvig spell checker, spell check...</td>\n",
       "      <td>[{'param_name': 'caseSensitive', 'param_descri...</td>\n",
       "      <td>https://github.com/wolfgarbe/SymSpell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>symmetric_spell</td>\n",
       "      <td>SymmetricDeleteApproach</td>\n",
       "      <td>SymmetricDeleteModel</td>\n",
       "      <td>This spell checker is inspired on Symmetric De...</td>\n",
       "      <td>token</td>\n",
       "      <td>spell</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symmetric spell,symmetric spell checker, spell...</td>\n",
       "      <td>[{'param_name': 'caseStrategy', 'param_descrip...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>stemmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stemmer</td>\n",
       "      <td>Returns hard-stems out of words with the objec...</td>\n",
       "      <td>token</td>\n",
       "      <td>stem</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stemmer, stemming, stemmwords, hard-stems, tex...</td>\n",
       "      <td>[{'param_name': 'language', 'param_description...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/tree...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>stopwordcleaner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>StopWordsCleaner</td>\n",
       "      <td>This annotator excludes from a sequence of str...</td>\n",
       "      <td>token</td>\n",
       "      <td>cleanTokens</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop words, stop words removal, stop words cle...</td>\n",
       "      <td>[{'param_name': 'locale', 'param_description':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lemmatizer</td>\n",
       "      <td>Lemmatizer</td>\n",
       "      <td>LemmatizerModel</td>\n",
       "      <td>Class to find standardized lemmas from words. ...</td>\n",
       "      <td>token</td>\n",
       "      <td>lemma</td>\n",
       "      <td>open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lemmatizer, lemmatizing, lemma, word lemma, te...</td>\n",
       "      <td>[{'param_name': 'inputCols', 'param_descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nlp.johnsnowlabs.com/api/index#com.joh...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>https://github.com/JohnSnowLabs/spark-nlp/blob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sentence_entity_resolver</td>\n",
       "      <td>SentenceEntityResolverApproach</td>\n",
       "      <td>SentenceEntityResolverModel</td>\n",
       "      <td>Entity Resolution model Based on KNN using Sen...</td>\n",
       "      <td>sentence_embeddings</td>\n",
       "      <td>entity</td>\n",
       "      <td>licensed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clinical,entity,resolution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           type                  approach_class  \\\n",
       "0                  assertion_dl             AssertionDLApproach   \n",
       "1              assertion_logreg         AssertionLogRegApproach   \n",
       "2         chunk_entity_resolver     ChunkEntityResolverApproach   \n",
       "3              deidentification                DeIdentification   \n",
       "4           relation_extraction      RelationExtractionApproach   \n",
       "5               default_chunker                             NaN   \n",
       "6                         ngram                             NaN   \n",
       "7                 classifier_dl            ClassifierDLApproach   \n",
       "8              multi_classifier       MultiClassifierDLApproach   \n",
       "9                  sentiment_dl             SentimentDLApproach   \n",
       "10             vivekn_sentiment         ViveknSentimentApproach   \n",
       "11                         yake                             NaN   \n",
       "12            language_detector                             NaN   \n",
       "13   named_entity_recognizer_dl                   NerDLApproach   \n",
       "14  named_entity_recognizer_crf                  NerCrfApproach   \n",
       "15                          pos              PerceptronApproach   \n",
       "16  unlabeled_dependency_parser        DependencyParserApproach   \n",
       "17    labeled_dependency_parser   TypedDependencyParserApproach   \n",
       "18                         bert                             NaN   \n",
       "19                       albert                             NaN   \n",
       "20                        glove                  WordEmbeddings   \n",
       "21                          use                             NaN   \n",
       "22                bert_sentence                             NaN   \n",
       "23                         elmo                             NaN   \n",
       "24                        xlnet                             NaN   \n",
       "25                 text_matcher                     TextMatcher   \n",
       "26                 date_matcher                             NaN   \n",
       "27                regex_matcher                    RegexMatcher   \n",
       "28                   normalizer                      Normalizer   \n",
       "29       deep_sentence_detector                             NaN   \n",
       "30            sentence_detector                             NaN   \n",
       "31                context_spell     ContextSpellCheckerApproach   \n",
       "32                 norvig_spell          NorvigSweetingApproach   \n",
       "33              symmetric_spell         SymmetricDeleteApproach   \n",
       "34                      stemmer                             NaN   \n",
       "35              stopwordcleaner                             NaN   \n",
       "36                   lemmatizer                      Lemmatizer   \n",
       "37     sentence_entity_resolver  SentenceEntityResolverApproach   \n",
       "\n",
       "                    Model Class  \\\n",
       "0              AssertionDLModel   \n",
       "1          AssertionLogRegModel   \n",
       "2      ChunkEntityResolverModel   \n",
       "3         DeIdentificationModel   \n",
       "4       RelationExtractionModel   \n",
       "5                       Chunker   \n",
       "6                NGramGenerator   \n",
       "7             ClassifierDLModel   \n",
       "8        MultiClassifierDLModel   \n",
       "9              SentimentDLModel   \n",
       "10         ViveknSentimentModel   \n",
       "11                    YakeModel   \n",
       "12           LanguageDetectorDL   \n",
       "13                   NerDLModel   \n",
       "14                  NerCrfModel   \n",
       "15              PerceptronModel   \n",
       "16        DependencyParserModel   \n",
       "17   TypedDependencyParserModel   \n",
       "18               BertEmbeddings   \n",
       "19             AlbertEmbeddings   \n",
       "20          WordEmbeddingsModel   \n",
       "21     UniversalSentenceEncoder   \n",
       "22       BertSentenceEmbeddings   \n",
       "23               ElmoEmbeddings   \n",
       "24              XlnetEmbeddings   \n",
       "25             TextMatcherModel   \n",
       "26                  DateMatcher   \n",
       "27            RegexMatcherModel   \n",
       "28              NormalizerModel   \n",
       "29         DeepSentenceDetector   \n",
       "30             SentenceDetector   \n",
       "31     ContextSpellCheckerModel   \n",
       "32          NorvigSweetingModel   \n",
       "33         SymmetricDeleteModel   \n",
       "34                      Stemmer   \n",
       "35             StopWordsCleaner   \n",
       "36              LemmatizerModel   \n",
       "37  SentenceEntityResolverModel   \n",
       "\n",
       "                                    class_description  \\\n",
       "0   Assertion of Clinical Entities based on Deep L...   \n",
       "1   Assertion of Clinical Entities based on Logist...   \n",
       "2   Entity Resolution model Based on KNN using Wor...   \n",
       "3   Anonymization and DeIdentification model based...   \n",
       "4   Relation Extraction model based on syntactic f...   \n",
       "5   This annotator matches a pattern of part-of-sp...   \n",
       "6   Integrates Spark ML NGram function into Spark ...   \n",
       "7   Multi-class Text Classification. ClassifierDL ...   \n",
       "8   Multi-label Text Classification. MultiClassifi...   \n",
       "9   Multi-class Sentiment Analysis Annotator. Sent...   \n",
       "10                  Scores a sentence for a sentiment   \n",
       "11  Yake is an Unsupervised, Corpus-Independent, D...   \n",
       "12  LanguageDetectorDL is a state-of-the-art langu...   \n",
       "13  Named Entity recognition annotator allows for ...   \n",
       "14  Named Entity recognition annotator allows for ...   \n",
       "15  Sets a Part-Of-Speech tag to each word within ...   \n",
       "16  Unlabeled parser that finds a grammatical rela...   \n",
       "17  Labeled parser that finds a grammatical relati...   \n",
       "18  BERT (Bidirectional Encoder Representations fr...   \n",
       "19  Computes contextualized word representations u...   \n",
       "20  Word Embeddings lookup annotator that maps tok...   \n",
       "21  Encodes text into high dimensional vectors tha...   \n",
       "22  This annotator generates sentence embeddings f...   \n",
       "23  Computes contextualized word representations u...   \n",
       "24  Computes contextualized word representations u...   \n",
       "25  Annotator to match entire phrases (by token) p...   \n",
       "26  Reads from different forms of date and time ex...   \n",
       "27  Uses a reference file to match a set of regula...   \n",
       "28  Removes all dirty characters from text followi...   \n",
       "29  Finds sentence bounds in raw text using deep l...   \n",
       "30  Finds sentence bounds in raw text. Applies rul...   \n",
       "31  Implements Noisy Channel Model Spell Algorithm...   \n",
       "32  This annotator retrieves tokens and makes corr...   \n",
       "33  This spell checker is inspired on Symmetric De...   \n",
       "34  Returns hard-stems out of words with the objec...   \n",
       "35  This annotator excludes from a sequence of str...   \n",
       "36  Class to find standardized lemmas from words. ...   \n",
       "37  Entity Resolution model Based on KNN using Sen...   \n",
       "\n",
       "                               Input Labels             Output Labels  \\\n",
       "0          document, chunk, word_embeddings                 assertion   \n",
       "1          document, chunk, word_embeddings                 assertion   \n",
       "2                   token, chunk_embeddings                    entity   \n",
       "3                    document, token, chunk                  document   \n",
       "4   word_embeddings, chunk, pos, dependency                  category   \n",
       "5                             document, pos                     chunk   \n",
       "6                                token, pos                    ngrams   \n",
       "7                sentence_embeddings, label                  category   \n",
       "8                sentence_embeddings, label                  category   \n",
       "9      sentence, label, sentence_embeddings                  category   \n",
       "10         sentence, sentiment_label, token                 sentiment   \n",
       "11                                    token                  keywords   \n",
       "12                                 document                  language   \n",
       "13         sentence, token, word_embeddings                       ner   \n",
       "14    sentence, token, pos, word_embeddings                       ner   \n",
       "15                          token, sentence                       pos   \n",
       "16                     document, pos, token      unlabeled_dependency   \n",
       "17         unlabeled_dependency, pos, token         labled_dependency   \n",
       "18                document, sentence, token           word_embeddings   \n",
       "19                document, sentence, token           word_embeddings   \n",
       "20                          document, token           word_embeddings   \n",
       "21                       document, sentence       sentence_embeddings   \n",
       "22                                 document  bert_sentence_embeddings   \n",
       "23                document, sentence, token           word_embeddings   \n",
       "24                document, sentence, token           word_embeddings   \n",
       "25                          document, token                    entity   \n",
       "26                                 document                      date   \n",
       "27                          document, token              regex_entity   \n",
       "28                                    token                normalized   \n",
       "29                                 document                  sentence   \n",
       "30                          document, token                  sentence   \n",
       "31                                    token                     spell   \n",
       "32                                    token                     token   \n",
       "33                                    token                     spell   \n",
       "34                                    token                      stem   \n",
       "35                                    token               cleanTokens   \n",
       "36                                    token                     lemma   \n",
       "37                      sentence_embeddings                    entity   \n",
       "\n",
       "   class_license  dataset_schema  class_annotation_sample  \\\n",
       "0       licensed             NaN                      NaN   \n",
       "1       licensed             NaN                      NaN   \n",
       "2       licensed             NaN                      NaN   \n",
       "3       licensed             NaN                      NaN   \n",
       "4       licensed             NaN                      NaN   \n",
       "5    open source             NaN                      NaN   \n",
       "6    open source             NaN                      NaN   \n",
       "7    open source             NaN                      NaN   \n",
       "8    open source             NaN                      NaN   \n",
       "9    open source             NaN                      NaN   \n",
       "10   open source             NaN                      NaN   \n",
       "11   open source             NaN                      NaN   \n",
       "12   open source             NaN                      NaN   \n",
       "13   open source             NaN                      NaN   \n",
       "14   open source             NaN                      NaN   \n",
       "15   open source             NaN                      NaN   \n",
       "16   open source             NaN                      NaN   \n",
       "17   open source             NaN                      NaN   \n",
       "18   open source             NaN                      NaN   \n",
       "19   open source             NaN                      NaN   \n",
       "20   open source             NaN                      NaN   \n",
       "21   open source             NaN                      NaN   \n",
       "22   open source             NaN                      NaN   \n",
       "23   open source             NaN                      NaN   \n",
       "24   open source             NaN                      NaN   \n",
       "25   open source             NaN                      NaN   \n",
       "26   open source             NaN                      NaN   \n",
       "27   open source             NaN                      NaN   \n",
       "28   open source             NaN                      NaN   \n",
       "29   open source             NaN                      NaN   \n",
       "30   open source             NaN                      NaN   \n",
       "31   open source             NaN                      NaN   \n",
       "32   open source             NaN                      NaN   \n",
       "33   open source             NaN                      NaN   \n",
       "34   open source             NaN                      NaN   \n",
       "35   open source             NaN                      NaN   \n",
       "36   open source             NaN                      NaN   \n",
       "37      licensed             NaN                      NaN   \n",
       "\n",
       "                                                 tags  \\\n",
       "0                               clinical,assertion,dl   \n",
       "1                        clinical,assertion,ml,logreg   \n",
       "2                          clinical,entity,resolution   \n",
       "3                clinical,deidentification,rule based   \n",
       "4                        clinical,relation,extraction   \n",
       "5             ner,named entity recognition, chunking    \n",
       "6                ngram, n-gramm, chunking,  shingel,    \n",
       "7                       classification, deep learning   \n",
       "8           classification,multi class classification   \n",
       "9   sentiment classification, sentiment, classific...   \n",
       "10  sentiment classification, sentiment, classific...   \n",
       "11  Keyword Extraction, Unsupervised, Corpus-Indep...   \n",
       "12  classification, deep learning,language classif...   \n",
       "13  ner,named entity recognition, named entity cla...   \n",
       "14  ner,named entity recognition, named entity cla...   \n",
       "15  pos, part of speech, part of speech classifica...   \n",
       "16  Untyped Dependency Parser, Unlabeled grammatic...   \n",
       "17  Typed Dependency Parser, Labeled grammatical r...   \n",
       "18  Deep learning, BERT, BERT Embeddings, BERT Wor...   \n",
       "19  Deep learning, ALBERT, ALBERT Embeddings, ALBE...   \n",
       "20  Word Embeddings, Glove Embeddings, Word2Vec Em...   \n",
       "21  Deep learning, Universal Sentence Encoder, Uni...   \n",
       "22  Deep learning, BERT Sentence Encoder, BERT Sen...   \n",
       "23  Deep learning, ELMO, ELMO Embeddings, ELMO Wor...   \n",
       "24  Deep learning, XLNET, XLNET Embeddings, XLNET ...   \n",
       "25  text matcher, entity matcher, matcher, phrase ...   \n",
       "26  date matcher, date text matcher, matcher, date...   \n",
       "27  regex matcher, regex text matcher, matcher, re...   \n",
       "28  text cleaning , text preprocessing, dirty char...   \n",
       "29  detector Deep Learning,sentence detector, sent...   \n",
       "30  detector ,sentence detector, sentence boundary...   \n",
       "31  context spell checker, Noisy Channel Model Alg...   \n",
       "32  norvig spell,norvig spell checker, spell check...   \n",
       "33  symmetric spell,symmetric spell checker, spell...   \n",
       "34  stemmer, stemming, stemmwords, hard-stems, tex...   \n",
       "35  stop words, stop words removal, stop words cle...   \n",
       "36  lemmatizer, lemmatizing, lemma, word lemma, te...   \n",
       "37                         clinical,entity,resolution   \n",
       "\n",
       "                                     class_parameters  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5   [{'param_name': 'inputCols', 'param_descriptio...   \n",
       "6   [{'param_name': 'n', 'param_description': 'num...   \n",
       "7   [{'param_name': 'classes', 'param_description'...   \n",
       "8   [{'param_name': 'threshold', 'param_descriptio...   \n",
       "9   [{'param_name': 'threshold', 'param_descriptio...   \n",
       "10  [{'param_name': 'featureLimit', 'param_descrip...   \n",
       "11  [{'param_name': 'minNGrams', 'param_descriptio...   \n",
       "12  [{'param_name': 'thresholdLabel', 'param_descr...   \n",
       "13  [{'param_name': 'includeConfidence', 'param_de...   \n",
       "14  [{'param_name': 'includeConfidence', 'param_de...   \n",
       "15  [{'param_name': 'inputCols', 'param_descriptio...   \n",
       "16  [{'param_name': 'inputCols', 'param_descriptio...   \n",
       "17  [{'param_name': 'conllFormat', 'param_descript...   \n",
       "18  [{'param_name': 'batchSize', 'param_descriptio...   \n",
       "19  [{'param_name': 'batchSize', 'param_descriptio...   \n",
       "20  [{'param_name': 'includeStorage', 'param_descr...   \n",
       "21  [{'param_name': 'dimension', 'param_descriptio...   \n",
       "22   [{'param_name': 'batchSize', 'param_descripti...   \n",
       "23  [{'param_name': 'batchSize', 'param_descriptio...   \n",
       "24  [{'param_name': 'batchSize', 'param_descriptio...   \n",
       "25  [{'param_name': 'inputCols', 'param_descriptio...   \n",
       "26  [{'param_name': 'dateFormat', 'param_descripti...   \n",
       "27  [{'param_name': 'inputCols', 'param_descriptio...   \n",
       "28  [{'param_name': 'cleanupPatterns', 'param_desc...   \n",
       "29  [{'param_name': 'includesPragmaticSegmenter', ...   \n",
       "30  [{'param_name': 'useAbbreviations', 'param_des...   \n",
       "31  [{'param_name': 'caseStrategy', 'param_descrip...   \n",
       "32  [{'param_name': 'caseSensitive', 'param_descri...   \n",
       "33  [{'param_name': 'caseStrategy', 'param_descrip...   \n",
       "34  [{'param_name': 'language', 'param_description...   \n",
       "35  [{'param_name': 'locale', 'param_description':...   \n",
       "36  [{'param_name': 'inputCols', 'param_descriptio...   \n",
       "37                                                NaN   \n",
       "\n",
       "                                        reference_url  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10               https://github.com/vivekn/sentiment/   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19          https://github.com/google-research/ALBERT   \n",
       "20                                                NaN   \n",
       "21  https://tfhub.dev/google/universal-sentence-en...   \n",
       "22            https://github.com/google-research/bert   \n",
       "23                    https://tfhub.dev/google/elmo/3   \n",
       "24                 https://github.com/zihangdai/xlnet   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32              https://github.com/wolfgarbe/SymSpell   \n",
       "33                                                NaN   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "36                                                NaN   \n",
       "37                                                NaN   \n",
       "\n",
       "                                  paper_url  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "5                                       NaN   \n",
       "6                                       NaN   \n",
       "7                                       NaN   \n",
       "8                                       NaN   \n",
       "9                                       NaN   \n",
       "10                                      NaN   \n",
       "11                                      NaN   \n",
       "12                                      NaN   \n",
       "13                                      NaN   \n",
       "14                                      NaN   \n",
       "15                                      NaN   \n",
       "16                                      NaN   \n",
       "17                                      NaN   \n",
       "18         https://arxiv.org/abs/1810.04805   \n",
       "19     https://arxiv.org/pdf/1909.11942.pdf   \n",
       "20  https://nlp.stanford.edu/pubs/glove.pdf   \n",
       "21         https://arxiv.org/abs/1803.11175   \n",
       "22         https://arxiv.org/abs/1810.04805   \n",
       "23         https://arxiv.org/abs/1802.05365   \n",
       "24         https://arxiv.org/abs/1906.08237   \n",
       "25                                      NaN   \n",
       "26                                      NaN   \n",
       "27                                      NaN   \n",
       "28                                      NaN   \n",
       "29                                      NaN   \n",
       "30                                      NaN   \n",
       "31                                      NaN   \n",
       "32                                      NaN   \n",
       "33                                      NaN   \n",
       "34                                      NaN   \n",
       "35                                      NaN   \n",
       "36                                      NaN   \n",
       "37                                      NaN   \n",
       "\n",
       "                                           scala_docs  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5   https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "6   https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "7   https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "8   https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "9   https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "10  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "11  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "12  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "13  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "14  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "15  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "16  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "17  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "18  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "19  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "20  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "21  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "22  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "23  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "24  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "25  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "26  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "27  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "28  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "29  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "30  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "31  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "32  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "33  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "34  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "35  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "36  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "37                                                NaN   \n",
       "\n",
       "                                         scala_source  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5   https://github.com/JohnSnowLabs/spark-nlp/tree...   \n",
       "6   https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "7   https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "8   https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "9   https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "10  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "11  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "12  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "13  https://github.com/JohnSnowLabs/spark-nlp/tree...   \n",
       "14  https://github.com/JohnSnowLabs/spark-nlp/tree...   \n",
       "15  https://github.com/JohnSnowLabs/spark-nlp/tree...   \n",
       "16  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "17  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "18  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "19  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "20  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "21  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "22  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "23  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "24  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "25  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "26  https://github.com/JohnSnowLabs/spark-nlp/tree...   \n",
       "27  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "28  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "29  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "30  https://nlp.johnsnowlabs.com/api/index#com.joh...   \n",
       "31  https://github.com/JohnSnowLabs/spark-nlp/tree...   \n",
       "32  https://github.com/JohnSnowLabs/spark-nlp/tree...   \n",
       "33  https://github.com/JohnSnowLabs/spark-nlp/tree...   \n",
       "34  https://github.com/JohnSnowLabs/spark-nlp/tree...   \n",
       "35  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "36  https://github.com/JohnSnowLabs/spark-nlp/blob...   \n",
       "37                                                NaN   \n",
       "\n",
       "                                   scala_source_tests  evaluator_class  \\\n",
       "0                                                 NaN              NaN   \n",
       "1                                                 NaN              NaN   \n",
       "2                                                 NaN              NaN   \n",
       "3                                                 NaN              NaN   \n",
       "4                                                 NaN              NaN   \n",
       "5   https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "6   https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "7   https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "8   https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "9   https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "10  https://github.com/JohnSnowLabs/spark-nlp/tree...              NaN   \n",
       "11  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "12  https://github.com/JohnSnowLabs/spark-nlp/tree...              NaN   \n",
       "13  https://github.com/JohnSnowLabs/spark-nlp/tree...              NaN   \n",
       "14  https://github.com/JohnSnowLabs/spark-nlp/tree...              NaN   \n",
       "15  https://github.com/JohnSnowLabs/spark-nlp/tree...              NaN   \n",
       "16  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "17  https://github.com/JohnSnowLabs/spark-nlp/tree...              NaN   \n",
       "18  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "19  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "20  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "21  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "22  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "23  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "24  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "25  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "26  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "27  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "28  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "29  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "30  https://github.com/JohnSnowLabs/spark-nlp/tree...              NaN   \n",
       "31  https://github.com/JohnSnowLabs/spark-nlp/tree...              NaN   \n",
       "32  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "33  https://github.com/JohnSnowLabs/spark-nlp/tree...              NaN   \n",
       "34  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "35  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "36  https://github.com/JohnSnowLabs/spark-nlp/blob...              NaN   \n",
       "37                                                NaN              NaN   \n",
       "\n",
       "    paper_abstract  scala_nlp_code  python_nlp_code  python_nlu_code  \\\n",
       "0              NaN             NaN              NaN              NaN   \n",
       "1              NaN             NaN              NaN              NaN   \n",
       "2              NaN             NaN              NaN              NaN   \n",
       "3              NaN             NaN              NaN              NaN   \n",
       "4              NaN             NaN              NaN              NaN   \n",
       "5              NaN             NaN              NaN              NaN   \n",
       "6              NaN             NaN              NaN              NaN   \n",
       "7              NaN             NaN              NaN              NaN   \n",
       "8              NaN             NaN              NaN              NaN   \n",
       "9              NaN             NaN              NaN              NaN   \n",
       "10             NaN             NaN              NaN              NaN   \n",
       "11             NaN             NaN              NaN              NaN   \n",
       "12             NaN             NaN              NaN              NaN   \n",
       "13             NaN             NaN              NaN              NaN   \n",
       "14             NaN             NaN              NaN              NaN   \n",
       "15             NaN             NaN              NaN              NaN   \n",
       "16             NaN             NaN              NaN              NaN   \n",
       "17             NaN             NaN              NaN              NaN   \n",
       "18             NaN             NaN              NaN              NaN   \n",
       "19             NaN             NaN              NaN              NaN   \n",
       "20             NaN             NaN              NaN              NaN   \n",
       "21             NaN             NaN              NaN              NaN   \n",
       "22             NaN             NaN              NaN              NaN   \n",
       "23             NaN             NaN              NaN              NaN   \n",
       "24             NaN             NaN              NaN              NaN   \n",
       "25             NaN             NaN              NaN              NaN   \n",
       "26             NaN             NaN              NaN              NaN   \n",
       "27             NaN             NaN              NaN              NaN   \n",
       "28             NaN             NaN              NaN              NaN   \n",
       "29             NaN             NaN              NaN              NaN   \n",
       "30             NaN             NaN              NaN              NaN   \n",
       "31             NaN             NaN              NaN              NaN   \n",
       "32             NaN             NaN              NaN              NaN   \n",
       "33             NaN             NaN              NaN              NaN   \n",
       "34             NaN             NaN              NaN              NaN   \n",
       "35             NaN             NaN              NaN              NaN   \n",
       "36             NaN             NaN              NaN              NaN   \n",
       "37             NaN             NaN              NaN              NaN   \n",
       "\n",
       "                          wikipedia_link  \n",
       "0                                    NaN  \n",
       "1                                    NaN  \n",
       "2                                    NaN  \n",
       "3                                    NaN  \n",
       "4                                    NaN  \n",
       "5                                    NaN  \n",
       "6   https://en.wikipedia.org/wiki/N-gram  \n",
       "7                                    NaN  \n",
       "8                                    NaN  \n",
       "9                                    NaN  \n",
       "10                                   NaN  \n",
       "11                                   NaN  \n",
       "12                                   NaN  \n",
       "13                                   NaN  \n",
       "14                                   NaN  \n",
       "15                                   NaN  \n",
       "16                                   NaN  \n",
       "17                                   NaN  \n",
       "18                                   NaN  \n",
       "19                                   NaN  \n",
       "20                                   NaN  \n",
       "21                                   NaN  \n",
       "22                                   NaN  \n",
       "23                                   NaN  \n",
       "24                                   NaN  \n",
       "25                                   NaN  \n",
       "26                                   NaN  \n",
       "27                                   NaN  \n",
       "28                                   NaN  \n",
       "29                                   NaN  \n",
       "30                                   NaN  \n",
       "31                                   NaN  \n",
       "32                                   NaN  \n",
       "33                                   NaN  \n",
       "34                                   NaN  \n",
       "35                                   NaN  \n",
       "36                                   NaN  \n",
       "37                                   NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466, 29)\n"
     ]
    }
   ],
   "source": [
    "full_meta = pd.read_csv(\"docs_module/metadata/all_models_metadata.csv\")\n",
    "print (full_meta.shape)\n",
    "#full_meta['input_labels'] = ''\n",
    "#full_meta = full_meta[(full_meta['include']==1) & (full_meta['model_class']=='NerDLModel')]\n",
    "#full_meta['automated_output_generation'] = full_meta['Automated_Output_generation']\n",
    "full_meta = full_meta[(full_meta['include']==1)]\n",
    "full_meta = full_meta.rename(columns={'model_class':'Model Class'})\n",
    "\n",
    "full_meta = pd.merge(full_meta, all_classes_meta, on=\"Model Class\", how=(\"left\"), suffixes=(\"\",\"class\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if 'Ner' in x:\n",
    "        return 'ner'\n",
    "    elif 'Perceptron' in x:\n",
    "        return 'Part of Speech tagging'\n",
    "    elif 'Lemmatizer'.lower() in x.lower():\n",
    "        return 'lemmatizer'\n",
    "    elif 'Embeddings'.lower() in x.lower():\n",
    "        return 'embeddings'\n",
    "    elif 'StopWordsCleaner'.lower() in x.lower():\n",
    "        return 'Stop Words Cleaner'\n",
    "    elif 'sentiment' in x.lower():\n",
    "        return 'sentiment'\n",
    "    elif 'Classifier'.lower() in x.lower():\n",
    "        return 'Classify <<tweets etc>>'\n",
    "    elif 'assertion'.lower() in x.lower():\n",
    "        return 'assertion'\n",
    "    elif 'EntityResolver'.lower() in x.lower():\n",
    "        return 'entity_resolver'\n",
    "    elif 'RelationExtraction'.lower() in x.lower():\n",
    "        return 'relation_extraction'\n",
    "    elif 'ContextSpellCheckerModel'.lower() in x.lower():\n",
    "        return 'spell_checker'\n",
    "    elif 'PipelineModel'.lower() in x.lower():\n",
    "        return 'pipeline'\n",
    "    elif 'DeIdentification'.lower() in x.lower():\n",
    "        return 'deidentification'\n",
    "    elif \"SentenceDetector\".lower() in x.lower():\n",
    "        return 'sentence_detector'\n",
    "    return ''\n",
    "#df['tags'] = df['model_class'].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(\n",
    "    loader=PackageLoader('docs_module', 'templates'),\n",
    "    autoescape=select_autoescape(['html', 'xml'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdsrc = env.loader.get_source(env, 'model.md')[0]\n",
    "parsed_content = env.parse(mdsrc)\n",
    "#meta.find_undeclared_variables(parsed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdmd = env.get_template(\"model.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_meta.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_code(x, scala=False):\n",
    "    ins = \",\".join([f'\"{y.strip()}\"' for y in x['Input Labels'].split(\",\")])\n",
    "    is_pl = x['Model Class'] in [\"PipelineModel\"]\n",
    "    class_to_call = x['Model Class'] if not is_pl else \"PretrainedPipeline\"\n",
    "    meth_to_call = \"pretrained\" if not is_pl else \"downloadPipeline\"\n",
    "    fun = f\"{class_to_call}\"\n",
    "    if not is_pl:\n",
    "        fun = fun+f\".{meth_to_call}\"\n",
    "    language = f\"Some({x.language})\" if scala and is_pl else x.language\n",
    "    language = x.language\n",
    "    c = f'model = {fun}(\"{x[\"name\"]}\",\"{language}\",\"{x.repo}\")'\n",
    "    if not is_pl:\n",
    "        output_labels = x['Output Labels']\n",
    "        c += f'\\\\\\n\\t.setInputCols({ins})\\\\\\n\\t.setOutputCol(\"{output_labels}\")'\n",
    "    else:\n",
    "        c+='\\n\\nmodel.annotate(\"Include a healthcare document here. Can be a prescription, medical note, anything...\")'\n",
    "    return \"val \"+c.replace(\"\\\\\",\"\") if scala else c\n",
    "\n",
    "def generate_buttons(x):\n",
    "    ret = \"{:.btn-box}\\n\"\n",
    "    if x.demo_url:\n",
    "        ret = ret + f\"[Live Demo]({x.demo_url})\"+\"{:.button.button-orange}<br/>\"\n",
    "    else:\n",
    "        ret = ret + \"<button class=\\\"button button-orange\\\" disabled>Live Demo</button><br/>\"\n",
    "    if x.colab_url:\n",
    "        ret = ret + f\"[Open in Colab]({x.colab_url})\"+\"{:.button.button-orange.button-orange-trans.co.button-icon}<br/>\"\n",
    "    else:\n",
    "        ret = ret + \"<button class=\\\"button button-orange\\\" disabled>Open in Colab</button><br/>\"\n",
    "    if x.download_url:\n",
    "        ret = ret + f\"[Download]({x.download_url})\"+\"{:.button.button-orange.button-orange-trans.arr.button-icon}<br/>\"\n",
    "    else:\n",
    "        ret = ret + \"<button class=\\\"button button-orange\\\" disabled>Download</button><br/>\"\n",
    "    return ret\n",
    "                                   \n",
    "full_meta[\"python_sample\"] = full_meta.apply(generate_code, axis=1)\n",
    "#full_meta[\"python_sample\"] =\"\"\n",
    "# full_meta[\"scala_sample\"] = full_meta.apply(lambda x: generate_code(x, True), axis=1)\n",
    "#full_meta[\"scala_sample\"]=\"\"\n",
    "full_meta[\"buttons\"] = full_meta.apply(generate_buttons, axis=1)\n",
    "#full_meta[\"buttons\"] = full_meta.apply(generate_buttons, axis=1)\n",
    "# full_meta[\"real_labels\"] = full_meta.apply(lambda r: None if r.model_class!=\"NerDLModel\" else NerDLModel.pretrained(r[\"name\"],r.language,r.repo).getClasses(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "full_meta_tbl = full_meta.rename(columns={'name': 'Model Name', \n",
    "                                         'compatibility': 'Spark Compatibility',\n",
    "                                         'spark_version': 'Spark NLP Compatibility',\n",
    "                                         'license':'License',\n",
    "                                         'edition':'Edition',\n",
    "                                         'language': 'Language',\n",
    "                                         'dimension': 'Dimension',\n",
    "                                         'case_sensitive':'Case Sensitive',\n",
    "                                         'upstream_deps':'Upstream Dependencies'})\n",
    "def tabulate_row(x):\n",
    "    if \"dimension\" in x.index:\n",
    "        x[\"dimension\"] = None if not x[\"dimension\"] or pd.isna(x[\"dimension\"]) else str(int(x[\"dimension\"]))\n",
    "    df = pd.DataFrame(x).dropna(how='any')\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    df = df.dropna(how='any')\n",
    "    if  'Case Sensitive' in df:\n",
    "        df['Case Sensitive'] = df['Case Sensitive'].astype(int)\n",
    "        df[df['Case Sensitive'] >= 1] = 'True'\n",
    "        df[df['Case Sensitive'] < 1] = 'False'\n",
    "    return tabulate(df,tablefmt=\"github\")\n",
    "\n",
    "\n",
    "\n",
    "full_meta[\"table\"] = \\\n",
    "    full_meta_tbl[[\"Model Name\",\"Model Class\",\"Spark Compatibility\",\n",
    "               \"Spark NLP Compatibility\",\"License\",\"Edition\",\"Input Labels\",\n",
    "               \"Output Labels\",\"Language\",\"Dimension\",\"Case Sensitive\",\n",
    "               \"Upstream Dependencies\"]]\\\n",
    "    .apply(tabulate_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "for i, r in full_meta.iterrows():\n",
    "    #print (r)\n",
    "    with open(f\"./temp_mds/{datetime.datetime.strptime(r.latest_date, '%d/%m/%Y').strftime( '%Y-%m-%d')}-{r['name']}_{r['language']}.md\",\"w\") as f:\n",
    "        f.write(mdmd.render(**r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "import json\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(text, model, lang):\n",
    "    from googletrans import Translator\n",
    "    translator = Translator()\n",
    "    text = translator.translate(text, \n",
    "                     dest=lang).text\n",
    "\n",
    "    documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "    sentenceDetector = SentenceDetector()\\\n",
    "      .setInputCols([\"document\"])\\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "    tokenizer = Tokenizer()\\\n",
    "      .setInputCols([\"sentence\"])\\\n",
    "      .setOutputCol(\"token\")\n",
    "\n",
    "    if '840B_300' in model:\n",
    "        embedding = 'glove_840B_300'\n",
    "        lng = 'xx'\n",
    "    elif '6B_300' in model:\n",
    "        embedding = 'glove_6B_300'\n",
    "        lng = 'xx'\n",
    "    else:\n",
    "        embedding = 'glove_100d'\n",
    "        lng = 'en'\n",
    "    embeddings = WordEmbeddingsModel.pretrained(embedding, lang=lng).\\\n",
    "                        setInputCols([\"sentence\", 'token']).\\\n",
    "                        setOutputCol(\"embeddings\")\n",
    "\n",
    "    public_ner = NerDLModel.pretrained(model, lang=lang) \\\n",
    "              .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "              .setOutputCol(\"ner\")\n",
    "\n",
    "    ner_converter = NerConverter() \\\n",
    "                    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "                      .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "    nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector,\n",
    "                                     tokenizer,\n",
    "                                     embeddings,\n",
    "                                     public_ner,\n",
    "                                     ner_converter\n",
    "                                     ])\n",
    "\n",
    "    empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "\n",
    "    pipelineModel = nlpPipeline.fit(empty_df)\n",
    "    lmodel = LightPipeline(pipelineModel)\n",
    "    \n",
    "    \n",
    "    t_res = lmodel.fullAnnotate(text)[0]\n",
    "    single_arr = []\n",
    "    for r in t_res['ner_chunk']:\n",
    "        single_arr.append({'ner_chunk':r.result,\n",
    "                          'begin': r.begin,\n",
    "                          'end':r.end,\n",
    "                          'entity':r.metadata['entity']})\n",
    "        \n",
    "        \n",
    "    code_sample = f\"\"\"\n",
    "    embeddings = WordEmbeddingsModel.pretrained({embedding}, lang={lng})\n",
    "    embeddings.setInputCols([\"sentence\", 'token'])\n",
    "    embeddings.setOutputCol(\"embeddings\")\n",
    "\n",
    "    ner = NerDLModel.pretrained({model}, lang={lang})\n",
    "    ner.setInputCols([\"sentence\", \"token\", \"embeddings\"])\n",
    "    ner.setOutputCol(\"ner\")\n",
    "\n",
    "    ner_converter = NerConverter()\n",
    "    ner_converter.setInputCols([\"sentence\", \"token\", \"ner\"])\n",
    "    ner_converter.setOutputCol(\"ner_chunk\")\n",
    "                      \n",
    "    pipeline = Pipeline(stages=[ documentAssembler, \n",
    "                                    sentenceDetector,\n",
    "                                    tokenizer,\n",
    "                                    embeddings,\n",
    "                                    ner,\n",
    "                                    ner_converter\n",
    "                                     ])\n",
    "    \n",
    "    pipeline_model = pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\"))\n",
    "    lmodel = LightPipeline(pipeline_model)\n",
    "    \n",
    "    result = lmodel.fullAnnotate(\"{text}\")[0]\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(single_arr).to_markdown(tablefmt=\"grid\", index=False), code_sample\n",
    "\n",
    "#ex = \"\"\"The Mona Lisa is a 16th century oil painting created by Leonardo. It's held at the Louvre in Paris.\"\"\"\n",
    "#lmodel = run(ex, 'dane_ner_840B_300','da')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resses = []\n",
    "code_resses = []\n",
    "errrors = []\n",
    "txt = u\"\"\"The Mona Lisa is a 16th century oil painting created by Leonardo. It's held at the Louvre in Paris.\"\"\"\n",
    "for i, row in full_meta_f.iterrows():\n",
    "    try:\n",
    "        re, co = run(txt, row['name'], row['language'])\n",
    "        resses.append(re)\n",
    "        code_resses.append(co)\n",
    "    except:\n",
    "        resses.append('')\n",
    "        code_resses.append('')\n",
    "        errrors.append(row['name']+'_'+row['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = bc = 0\n",
    "for r_ in resses:\n",
    "    if r_ =='':\n",
    "        bc += 1\n",
    "    else:\n",
    "        gc += 1\n",
    "print (bc, gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_meta['automated_output_generation'] = ''\n",
    "full_meta['python_sample'] = ''\n",
    "full_meta.loc[(full_meta['include']==1) & (full_meta['model_class']=='NerDLModel'), 'automated_output_generation'] = resses\n",
    "full_meta.loc[(full_meta['include']==1) & (full_meta['model_class']=='NerDLModel'), 'python_sample'] = code_resses\n",
    "\n",
    "full_meta.to_csv('docs_module/metadata/all_models_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errrors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
